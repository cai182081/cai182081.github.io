<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[函数、存储过程和试图定义者变更脚本]]></title>
    <url>%2F2018%2F04%2F22%2FMySQL%2FMySQL_Change_Definder%2F</url>
    <content type="text"><![CDATA[在 MySQL 数据库日常迁移过程中，由于操作的不规范性，常常因为函数、存储过程和视图定义者的缺失，导致存储过程、函数和视图失效，或者mysqldump逻辑备份无法备份和恢复。如果涉及的存储过程、函数和视图较多，一个一个的修改可能耗时和人为错误，所以特别设计函数批量修改存储过程、函数和视图的定义者，以减少运维维护量。这里默认将所有的定义者修改为‘root‘@’localhost’。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970DELIMITER // CREATE DEFINER = CURRENT_USER () PROCEDURE p_change_definer ( `pr_database_name` VARCHAR (500), -- 数据库名称 `pr_definer_name` VARCHAR (500), -- 定义者名称，默认 root `pr_definer_ip_name` VARCHAR (500) -- 定义者绑定ip，默认为 localhost)BEGINDECLARE drop_view_ varchar(500);DECLARE create_view_ varchar(15500);DECLARE DATABASE_NAME VARCHAR(500);DECLARE DEFINER_NAME VARCHAR(500) DEFAULT 'root';DECLARE DEFINER_IP_NAME VARCHAR (500) DEFAULT 'localhost';DECLARE flag boolean DEFAULT 1;DECLARE cur CURSOR FOR SELECT drop_view,create_view FROM sql_value;DECLARE CONTINUE HANDLER FOR NOT FOUND SET flag = 0;DROP TEMPORARY TABLE IF EXISTS sql_value; CREATE TEMPORARY TABLE sql_value(drop_view varchar(500),create_view varchar(15500));SET DATABASE_NAME = TRIM(pr_database_name);IF pr_definer_name IS NOT NULL AND LENGTH(pr_definer_name) &gt; 0 THENSET DEFINER_NAME = TRIM(pr_definer_name);END IF;IF pr_definer_ip_name IS NOT NULL AND LENGTH(pr_definer_ip_name) &gt; 0 THENSET DEFINER_IP_NAME = pr_definer_ip_name;END IF;-- 组装修改视图定义者语句IF DATABASE_NAME IS NOT NULL AND LENGTH(DATABASE_NAME) &gt;0 THEN INSERT INTO sql_value (drop_view, create_view) SELECT GROUP_CONCAT('DROP VIEW IF EXISTS ', TABLE_SCHEMA, '.', TABLE_NAME, ';'), GROUP_CONCAT('CREATE ALGORITHM = UNDEFINED DEFINER = `', DEFINER_NAME, '`@`', DEFINER_IP_NAME, '` SQL SECURITY DEFINER VIEW `', TABLE_SCHEMA, '`.`', TABLE_NAME, '` as ', VIEW_DEFINITION, ';' SEPARATOR '') FROM information_schema.VIEWS WHERE TABLE_SCHEMA = DATABASE_NAME GROUP BY TABLE_NAME;-- 执行修改视图定义者OPEN cur;rep:LOOP FETCH cur INTO drop_view_,create_view_; set @drop_view_ = drop_view_; set @create_view_ = create_view_; IF flag = 0 THEN LEAVE rep; END IF; PREPARE stmt FROM @drop_view_; EXECUTE stmt; DEALLOCATE PREPARE stmt; PREPARE stmt FROM @create_view_; EXECUTE stmt; DEALLOCATE PREPARE stmt;END LOOP;CLOSE cur;-- 修改存储过程定义者UPDATE mysql.proc set DEFINER = CONCAT(DEFINER_NAME,'@',DEFINER_IP_NAME) WHERE db = DATABASE_NAME;ELSE SELECT '数据库名称不允许为空';END IF;END;// 修改执行命令为 ：call p_change_definer(‘database’,’user’,’ip’);database –需要修改的库名user –数据库的用户IP –数据库的绑定ip]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL 日常维护</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 优化之美：对一条简单 SQL 优化的理解、分析]]></title>
    <url>%2F2018%2F04%2F21%2FSQL%2FDB_SQL_5%2F</url>
    <content type="text"><![CDATA[问题 SQLSQL执行时间0.8s,SQL文本如下：123456789101112SELECT old_user_id, nick_name, channel, status FROM user_relation WHERE old_user_id IN (SELECT old_user_id FROM user_relation WHERE old_user_id = '1601474800051044' OR new_user_id = '1601474800051044') OR new_user_id IN (SELECT new_user_id FROM user_relation WHERE old_user_id = '1601474800051044' OR new_user_id = '1601474800051044'); 表结构如下：1234567891011CREATE TABLE "user_relation" ( "pay_organ_id" varchar(50) NOT NULL, "old_user_id" varchar(32) DEFAULT NULL, "new_user_id" varchar(32) NOT NULL, "nick_name" varchar(15) DEFAULT NULL, "channel" char(1) DEFAULT NULL, "status" char(1) DEFAULT NULL, PRIMARY KEY ("pay_organ_id","new_user_id"), UNIQUE KEY "uniq_new_user_id" ("new_user_id"), UNIQUE KEY "uniq_old_user_id" ("old_user_id")) ENGINE=InnoDB DEFAULT CHARSET=utf8; 执行计划如下：12345 id select_type table partitions type possible_keys key key_len ref rows filtered Extra ------ ----------- ------------- ---------- ----------- --------------------------------- --------------------------------- ------- ------ ------- -------- ------------------------------------------------------------- 1 PRIMARY user_relation (NULL) ALL (NULL) (NULL) (NULL) (NULL) 1124585 100.00 Using where 3 SUBQUERY user_relation (NULL) index_merge uniq_new_user_id,uniq_old_user_id uniq_old_user_id,uniq_new_user_id 99,98 (NULL) 2 100.00 Using union(uniq_old_user_id,uniq_new_user_id); Using where 2 SUBQUERY user_relation (NULL) index_merge uniq_new_user_id,uniq_old_user_id uniq_old_user_id,uniq_new_user_id 99,98 (NULL) 2 100.00 Using union(uniq_old_user_id,uniq_new_user_id); Using where SQL 性能瓶颈分析从执行计划中可得知，MySQL优化器先后分别运算两个子查询后，再执行主查询，而主查询是经全表扫描后得到数据，主查询无法将谓词下推到子查询，通过索引检索，分析]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库优化</tag>
        <tag>SQL 优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pt-online-schema-change 实现原理及其用法]]></title>
    <url>%2F2018%2F04%2F18%2FMySQL%2FMySQL_PT_OSC%2F</url>
    <content type="text"><![CDATA[pt-online-schema-change 背景pt-online-schema-change 用于MySQL的在线DDL操作 pt-online-schema-change 使用限制1、原表必须存在主键 PRIMARY KEY 或者 UNIQUE KEY2、原表不能存在触发器3、外键的处理需要指定 alter-foreign-keys-method 参数4、剩余的数据盘空间至少为原表大小的一倍 pt-online-schema-change 实现原理pt-online-schema-change 修改表结构过程 general_log 日志内容：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283Connect root@localhost on test using SocketQuery SHOW VARIABLES LIKE 'innodb\_lock_wait_timeout'Query SET SESSION innodb_lock_wait_timeout=1Query SHOW VARIABLES LIKE 'lock\_wait_timeout'Query SET SESSION lock_wait_timeout=60Query SHOW VARIABLES LIKE 'wait\_timeout'Query SET SESSION wait_timeout=10000Query SELECT @@SQL_MODEQuery SET @@SQL_QUOTE_SHOW_CREATE = 1/*!40101, @@SQL_MODE='NO_AUTO_VALUE_ON_ZERO,PIPES_AS_CONCAT,ANSI_QUOTES,NO_AUTO_VALUE_ON_ZERO,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'*/Query SELECT @@server_id /*!50038 , @@hostname*/Query SHOW VARIABLES LIKE 'wsrep_on'Query SHOW VARIABLES LIKE 'version%'Query SHOW ENGINESQuery SHOW VARIABLES LIKE 'innodb_version'Query SHOW VARIABLES LIKE 'innodb_stats_persistent'Query SELECT @@SERVER_IDQuery SHOW SLAVE HOSTSQuery SHOW GLOBAL STATUS LIKE 'Threads_running'Query SHOW GLOBAL STATUS LIKE 'Threads_running'Query SELECT CONCAT(@@hostname, @@port)Query SHOW TABLES FROM `test` LIKE 'p\_test'Query SELECT VERSION()Query SHOW TRIGGERS FROM `test` LIKE 'p\_test'Query /*!40101 SET @OLD_SQL_MODE := @@SQL_MODE, @@SQL_MODE := '', @OLD_QUOTE := @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE := 1 */Query USE `test`Query SHOW CREATE TABLE `test`.`p_test`Query /*!40101 SET @@SQL_MODE := @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE := @OLD_QUOTE */Query EXPLAIN SELECT * FROM `test`.`p_test` WHERE 1=1Query SELECT table_schema, table_name FROM information_schema.key_column_usage WHERE referenced_table_schema='test' AND referenced_table_name='p_test'Query /*!40101 SET @OLD_SQL_MODE := @@SQL_MODE, @@SQL_MODE := '', @OLD_QUOTE := @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE := 1 */Query USE `test`Query SHOW CREATE TABLE `test`.`p_test`Query /*!40101 SET @@SQL_MODE := @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE := @OLD_QUOTE */Query CREATE TABLE `test`.`_p_test_new` ( `user_id` varchar(20) NOT NULL, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY (`user_id`), KEY `idx_create_time` (`create_time`)) ENGINE=InnoDB DEFAULT CHARSET=utf8Query ALTER TABLE `test`.`_p_test_new` ADD COLUMN id bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '自增主键ID' FIRST, DROP PRIMARY KEY, ADD PRIMARY KEY (id, create_time), ADD UNIQUE INDEX uniq_ui_ct(user_id, create_time)Query /*!40101 SET @OLD_SQL_MODE := @@SQL_MODE, @@SQL_MODE := '', @OLD_QUOTE := @@SQL_QUOTE_SHOW_CREATE, @@SQL_QUOTE_SHOW_CREATE := 1 */Query USE `test`Query SHOW CREATE TABLE `test`.`_p_test_new`Query /*!40101 SET @@SQL_MODE := @OLD_SQL_MODE, @@SQL_QUOTE_SHOW_CREATE := @OLD_QUOTE */Query SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE, CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING FROM INFORMATION_SCHEMA.TRIGGERS WHERE EVENT_MANIPULATION = 'DELETE' AND ACTION_TIMING = 'AFTER' AND TRIGGER_SCHEMA = 'test' AND EVENT_OBJECT_TABLE = 'p_test'Query SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE, CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING FROM INFORMATION_SCHEMA.TRIGGERS WHERE EVENT_MANIPULATION = 'UPDATE' AND ACTION_TIMING = 'AFTER' AND TRIGGER_SCHEMA = 'test' AND EVENT_OBJECT_TABLE = 'p_test'Query SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE, CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING FROM INFORMATION_SCHEMA.TRIGGERS WHERE EVENT_MANIPULATION = 'INSERT' AND ACTION_TIMING = 'AFTER' AND TRIGGER_SCHEMA = 'test' AND EVENT_OBJECT_TABLE = 'p_test'Query SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE, CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING FROM INFORMATION_SCHEMA.TRIGGERS WHERE EVENT_MANIPULATION = 'DELETE' AND ACTION_TIMING = 'BEFORE' AND TRIGGER_SCHEMA = 'test' AND EVENT_OBJECT_TABLE = 'p_test'Query SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE, CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING FROM INFORMATION_SCHEMA.TRIGGERS WHERE EVENT_MANIPULATION = 'UPDATE' AND ACTION_TIMING = 'BEFORE' AND TRIGGER_SCHEMA = 'test' AND EVENT_OBJECT_TABLE = 'p_test'Query SELECT TRIGGER_SCHEMA, TRIGGER_NAME, DEFINER, ACTION_STATEMENT, SQL_MODE, CHARACTER_SET_CLIENT, COLLATION_CONNECTION, EVENT_MANIPULATION, ACTION_TIMING FROM INFORMATION_SCHEMA.TRIGGERS WHERE EVENT_MANIPULATION = 'INSERT' AND ACTION_TIMING = 'BEFORE' AND TRIGGER_SCHEMA = 'test' AND EVENT_OBJECT_TABLE = 'p_test'Query CREATE TRIGGER `pt_osc_test_p_test_del` AFTER DELETE ON `test`.`p_test` FOR EACH ROW DELETE IGNORE FROM `test`.`_p_test_new` WHERE `test`.`_p_test_new`.`user_id` &lt;=&gt; OLD.`user_id`Query CREATE TRIGGER `pt_osc_test_p_test_upd` AFTER UPDATE ON `test`.`p_test` FOR EACH ROW BEGIN DELETE IGNORE FROM `test`.`_p_test_new` WHERE !(OLD.`user_id` &lt;=&gt; NEW.`user_id`) AND `test`.`_p_test_new`.`user_id` &lt;=&gt; OLD.`user_id`;REPLACE INTO `test`.`_p_test_new` (`user_id`, `create_time`) VALUES (NEW.`user_id`, NEW.`create_time`);ENDQuery CREATE TRIGGER `pt_osc_test_p_test_ins` AFTER INSERT ON `test`.`p_test` FOR EACH ROW REPLACE INTO `test`.`_p_test_new` (`user_id`, `create_time`) VALUES (NEW.`user_id`, NEW.`create_time`)Query EXPLAIN SELECT * FROM `test`.`p_test` WHERE 1=1Query SELECT /*!40001 SQL_NO_CACHE */ `user_id` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) ORDER BY `user_id` LIMIT 1 /*first lower boundary*/Query SELECT /*!40001 SQL_NO_CACHE */ `user_id` FROM `test`.`p_test` FORCE INDEX (`PRIMARY`) WHERE `user_id` IS NOT NULL ORDER BY `user_id` LIMIT 1 /*key_len*/Query EXPLAIN SELECT /*!40001 SQL_NO_CACHE */ * FROM `test`.`p_test` FORCE INDEX (`PRIMARY`) WHERE `user_id` &gt;= '00R7TVLSWXKJgVHzA4' /*key_len*/Query EXPLAIN SELECT /*!40001 SQL_NO_CACHE */ `user_id` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= '00R7TVLSWXKJgVHzA4')) ORDER BY `user_id` LIMIT 999, 2 /*next chunk boundary*/Query SELECT /*!40001 SQL_NO_CACHE */ `user_id` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= '00R7TVLSWXKJgVHzA4')) ORDER BY `user_id` LIMIT 999, 2 /*next chunk boundary*/Query EXPLAIN SELECT `user_id`, `create_time` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= '00R7TVLSWXKJgVHzA4')) AND ((`user_id` &lt;= 'bdn57bnaz9UXTpdFzH')) LOCK IN SHARE MODE /*explain pt-online-schema-change 31941 copy nibble*/Query INSERT LOW_PRIORITY IGNORE INTO `test`.`_p_test_new` (`user_id`, `create_time`) SELECT `user_id`, `create_time` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= '00R7TVLSWXKJgVHzA4')) AND ((`user_id` &lt;= 'bdn57bnaz9UXTpdFzH')) LOCK IN SHARE MODE /*pt-online-schema-change 31941 copy nibble*/Query SHOW WARNINGSQuery SHOW GLOBAL STATUS LIKE 'Threads_running'Query EXPLAIN SELECT /*!40001 SQL_NO_CACHE */ `user_id` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= 'bdo8j11Q2whGrZujWB')) ORDER BY `user_id` LIMIT 2237, 2 /*next chunk boundary*/Query SELECT /*!40001 SQL_NO_CACHE */ `user_id` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= 'bdo8j11Q2whGrZujWB')) ORDER BY `user_id` LIMIT 2237, 2 /*next chunk boundary*/Query EXPLAIN SELECT `user_id`, `create_time` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= 'bdo8j11Q2whGrZujWB')) AND ((`user_id` &lt;= 'Ox7PCp52KsU1fYXJAB')) LOCK IN SHARE MODE /*explain pt-online-schema-change 31941 copy nibble*/Query INSERT LOW_PRIORITY IGNORE INTO `test`.`_p_test_new` (`user_id`, `create_time`) SELECT `user_id`, `create_time` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= 'bdo8j11Q2whGrZujWB')) AND ((`user_id` &lt;= 'Ox7PCp52KsU1fYXJAB')) LOCK IN SHARE MODE /*pt-online-schema-change 31941 copy nibble*/Query SHOW WARNINGSQuery SHOW GLOBAL STATUS LIKE 'Threads_running'Query EXPLAIN SELECT /*!40001 SQL_NO_CACHE */ `user_id` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= 'OXcX149l9zca2yuCrc')) ORDER BY `user_id` LIMIT 2076, 2 /*next chunk boundary*/Query SELECT /*!40001 SQL_NO_CACHE */ `user_id` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= 'OXcX149l9zca2yuCrc')) ORDER BY `user_id` LIMIT 2076, 2 /*next chunk boundary*/Query SELECT /*!40001 SQL_NO_CACHE */ `user_id` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) ORDER BY `user_id` DESC LIMIT 1 /*last upper boundary*/Query EXPLAIN SELECT `user_id`, `create_time` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= 'OXcX149l9zca2yuCrc')) AND ((`user_id` &lt;= 'zzY2454Vegqcz6CC3i')) LOCK IN SHARE MODE /*explain pt-online-schema-change 31941 copy nibble*/Query INSERT LOW_PRIORITY IGNORE INTO `test`.`_p_test_new` (`user_id`, `create_time`) SELECT `user_id`, `create_time` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= 'OXcX149l9zca2yuCrc')) AND ((`user_id` &lt;= 'zzY2454Vegqcz6CC3i')) LOCK IN SHARE MODE /*pt-online-schema-change 31941 copy nibble*/Query SHOW WARNINGSQuery SHOW GLOBAL STATUS LIKE 'Threads_running'Query ANALYZE TABLE `test`.`_p_test_new` /* pt-online-schema-change */Query RENAME TABLE `test`.`p_test` TO `test`.`_p_test_old`, `test`.`_p_test_new` TO `test`.`p_test`Query DROP TABLE IF EXISTS `test`.`_p_test_old`Query DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_del`Query DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_upd`Query DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_ins`Query SHOW TABLES FROM `test` LIKE '\_p\_test\_new' 连接数据库，获取指定表的状态信息、触发器信息、权限信息和主键信息1234root@localhost on test using SocketSHOW TRIGGERS FROM `test` LIKE 'p\_test'SELECT table_schema, table_name FROM information_schema.key_column_usage WHERE referenced_table_schema='test' AND referenced_table_name='p_test'SHOW CREATE TABLE `test`.`p_test` 新建_*_new，表结构与原表相同。123456CREATE TABLE `test`.`_p_test_new` ( `user_id` varchar(20) NOT NULL, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY (`user_id`), KEY `idx_create_time` (`create_time`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 在新表上执行DDL操作表结构，更改表结构1ALTER TABLE `test`.`_p_test_new` ADD COLUMN id bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '自增主键ID' FIRST, DROP PRIMARY KEY,ADD PRIMARY KEY (id); 在原表上分别针对insert、update、delete操作三个触发器分别，以便后续对原表上的操作同步到新表Creating triggers ……创建触发器，用于记录从拷贝数据开始之后，对源数据表继续进行数据修改的操作记录下来，用于数据拷贝结束后，执行这些操作，保证数据不会丢失。如果表中已经定义了触发器这个工具就不能工作了。我们可以看到这三个触发器分别对应于INSERT、UPDATE、DELETE三种操作： a、CREATE TRIGGER pt_osc_test_p_test_del AFTER DELETE ON test.p_test FOR EACH ROW DELETE IGNORE FROM test._p_test_new WHERE test._p_test_new.user_id &lt;=&gt; OLD.user_id pt_osc_test_online_table_del，DELETE操作，我们注意到DELETE IGNORE，当新有数据时，我们才进行操作，也就是说，当在后续导入过程中，如果删除的这个数据还未导入到新表，那么我们可以不在新表执行操作，因为在以后的导入过程中，原表中改行数据已经被删除，已经没有数据，那么他也就不会导入到新表中。 b、CREATE TRIGGER pt_osc_test_p_test_upd AFTER UPDATE ON test.p_test FOR EACH ROW BEGIN DELETE IGNORE FROM test._p_test_new WHERE !(OLD.user_id &lt;=&gt; NEW.user_id) AND test._p_test_new.user_id &lt;=&gt; OLD.user_id;REPLACE INTO test._p_test_new (user_id, create_time) VALUES (NEW.user_id, NEW.create_time);END pt_osc_test_online_table_ins，INSERT操作，所有的INSERT INTO全部转换为REPLACE INTO，为了确保数据的一致性，当有新数据插入到原表时，如果触发器还未把原表数据未同步到新表，这条数据已经被导入到新表了，那么我们就可以利用replace into进行覆盖，这样数据也是一致的。 c、 CREATE TRIGGER pt_osc_test_p_test_ins AFTER INSERT ON test.p_test FOR EACH ROW REPLACE INTO test._p_test_new (user_id, create_time) VALUES (NEW.user_id, NEW.create_time) pt_osc_test_online_table_upd，UPDATE操作，所有的UPDATE也转换为REPLACE INTO，因为当新的数据的行还未同步到新表时，新表是不存在这条记录的，那么我们就只能插入该条数据，如果已经同步到新表了，那么也可以进行覆盖插入，所有数据与原表也是一致的。 拷贝原表数据到新表，数据量大时根据主键进行分 chunk 段插入。1INSERT LOW_PRIORITY IGNORE INTO `test`.`_p_test_new` (`user_id`, `create_time`) SELECT `user_id`, `create_time` FROM `test`.`p_test` FORCE INDEX(`PRIMARY`) WHERE ((`user_id` &gt;= '00R7TVLSWXKJgVHzA4')) AND ((`user_id` &lt;= 'bdn57bnaz9UXTpdFzH')) LOCK IN SHARE MODE /*pt-online-schema-change 31941 copy nibble*/ 数据的拷贝是基于chunk指定的大小块(根据chunk-time参数指定)进行的，而且根据主键或者唯一索引索引进行选择，所以对整体服务器性能影响较小。它是通过一些查询（基本为主键、唯一键值）分批把数据导入到新的表中。在拷贝过程中，数据库通过对主键加S锁，拷贝数据。 ANALYZE重新收集新表统计信息1ANALYZE TABLE `test`.`_p_test_new` 交换表，其通过一个RENAME TABLE同时处理两个表，实现原子操作。1RENAME TABLE `test`.`p_test` TO `test`.`_p_test_old`, `test`.`_p_test_new` TO `test`.`p_test` 在这个过程中，会持有锁。 如果没有定义–no-drop-old-table，清理以上过程中的old表、创建的触发器。1234DROP TABLE IF EXISTS `test`.`_p_test_old`DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_del`DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_upd`DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_ins` pt-online-schema-change 用法及核心参数–alter-foreign-keys-method如何把外键引用到新表？需要特殊处理带有外键约束的表，以保证它们可以应用到新表。当重命名表的时候，外键关系会带到重命名后的表上。该工具有两种方法，可以自动找到子表，并修改约束关系。 –[no]check-replication-filters默认yes，如果工具检测到服务器选项中有任何复制相关的筛选，如指定binlog_ignore_db和replicate_do_db此类。发现有这样的筛选，工具会报错且退出。因为如果更新的表Master上存在，而Slave上不存在，会导致复制的失败。使用 –no-check-replication-filters选项来禁用该检查。 –max-load默认为Threads_running=25。每个chunk拷贝完后，会检查SHOW GLOBAL STATUS的内容，检查指标是否超过了指定的阈值。如果超过，则先暂停。这里可以用逗号分隔，指定多个条件，每个条件格式：status指标=MAX_VALUE或者status指标:MAX_VALUE。如果不指定MAX_VALUE，那么工具会这只其为当前值的120%。 –max-lag默认1s。每个chunk拷贝完成后，会查看所有复制Slave的延迟情况（Seconds_Behind_Master）。要是延迟大于该值，则暂停复制数据，直到所有从的滞后小于这个值。–check-interval 配合使用，指定出现从库滞后超过 max-lag，则该工具将睡眠多长时间，默认1s，再检查。如–max-lag=5 –check-interval=2 –chunk-time在chunk-time执行的时间内，动态调整chunk-size的大小，以适应服务器性能的变化，该参数设置为0。或者指定chunk-size，都可以禁止动态调整。 –chunk-size指定块的大小，默认是1000行，可以添加k,M,G后缀。这个块的大小要尽量与 –chunk-time匹配，如果明确指定这个选项，那么每个块就会指定行数的大小。 –dry-run创建和修改新表，但不会创建触发器、复制数据、和替换原表。并不真正执行，可以看到生成的执行语句，了解其执行步骤与细节。 –dry-run 与 –execute 必须指定一个，二者相互排斥。和–print配合最佳。 pt-online-schema-change 实战简单的修改字段和增删索引123pt-online-schema-change -uroot -poRcl_123 -hlocalhost -P3307 D=test,t=p_test \--alter "ADD COLUMN channal tinyint(4) UNSIGNED NOT NULL;" \--max-lag=1 --print --execute 修改主键或唯一索引操作1234pt-online-schema-change -uroot -poRcl_123 -hlocalhost -P3307 D=test,t=p_test \--alter "ADD COLUMN id bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '自增主键ID' FIRST, DROP PRIMARY KEY, ADD PRIMARY KEY (id), ADD UNIQUE INDEX uniq_ui_ct(user_id);" \--no-check-unique-key-change --no-check-alter --max-lag=1 --print --execute 重定义分区表操作12345678pt-online-schema-change -uroot -poRcl_123 -hlocalhost -P3307 D=test,t=p_test \--alter "PARTITION BY RANGE COLUMNS(create_time)( PARTITION p01 VALUES LESS THAN ('2017-01-01 00:00:00'), PARTITION p02 VALUES LESS THAN ('2017-02-01 00:00:00'), PARTITION p03 VALUES LESS THAN ('2017-03-01 00:00:00'), PARTITION p04 VALUES LESS THAN ('2017-04-01 00:00:00'), PARTITION p00 VALUES LESS THAN (MAXVALUE));" \--max-lag=1 --print --execute 存在主外键关联表字段操作123pt-online-schema-change -uroot -poRcl_123 -hlocalhost -P3307 D=test,t=p_test \--alter "" \--alter-foreign-keys-method=rebuild_constraints --max-lag=1 --print --execute 主从环境下的字段操作123pt-online-schema-change -uroot -poRcl_123 -hlocalhost -P3307 D=test,t=p_test \--alter "" \--no-check-replication-filters --max-lag=1 --max-lag=2 --print --execute 参考文档：pt-online-schema-change在线修改表结构：http://www.ywnds.com/?p=4442]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>pt-tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pt-online-schema-change 实现 MySQL 在线重定义普通表转分区表]]></title>
    <url>%2F2018%2F04%2F18%2FMySQL%2FMySQL_Partition%2F</url>
    <content type="text"><![CDATA[MySQL 分区表是由多个相关的底层表实现，这些底层表也是由句柄对象表示，所以我们也可以直接访问各个分区，存储引擎管理分区的各个底层表和管理普通表一样（所有的底层表都必须使用相同的存储引擎），分区表的索引只是在各个底层表上各自加上一个相同的索引，从存储引擎的角度来看，底层表和一个普通表没有任何不同，存储引擎也无须知道这是一个普通表还是一个分区表的一部分。 表分区缘由1、表非常大以至于无法全部都放在内存中，或者只在表的最后部分有热点数据，其他都是历史数据2、分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备3、优化查询，在where字句中包含分区列时，可以只使用必要的分区来提高查询效率，同时在涉及sum()和count()这类聚合函数的查询时，可以在每个分区上面并行处理，最终只需要汇总所有分区得到的结果。4、如果需要，还可以备份和恢复独立的分区，这在非常大的数据集的场景下效果非常好5、分区表的数据更容易维护，如：想批量删除大量数据可以使用清除整个分区的方式。另外，还可以对一个独立分区进行优化、检查、修复等操作 分区表设计对于生产中一个普通字符串主键的大表，我们该如何在不影响前端业务的情况下，将其改造成分区表。例如普通表：123456CREATE TABLE "p_test" ( "user_id" varchar(20) NOT NULL, "create_time" datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY ("user_id"), KEY "idx_create_time" ("create_time")) ENGINE=InnoDB DEFAULT CHARSET=utf8; 我们该如何设计这种表的分区表，来隔离冷热数据，MySQL 5.7 版本后COLUMNS分区支持对整形、字符串、日期和时间撮等各类型数据分区，分区跨度可随数据规模定义，可设计为按月、按日分区或者按小时分区。具体分区表设计如下：1234567891011121314CREATE TABLE "p_test" ( "id" int(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键ID', "user_id" varchar(32) NOT NULL, "create_time" datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY ("id","create_time"), UNIQUE KEY "uniq_ui_ct" ("user_id","create_time"), KEY "idx_create_time" ("create_time")) ENGINE=InnoDB DEFAULT CHARSET=utf8/*!50500 PARTITION BY RANGE COLUMNS(create_time)(PARTITION p01 VALUES LESS THAN ('2018-01-01 00:00:00') ENGINE = InnoDB, PARTITION p02 VALUES LESS THAN ('2018-02-01 00:00:00') ENGINE = InnoDB, PARTITION p03 VALUES LESS THAN ('2018-03-01 00:00:00') ENGINE = InnoDB, PARTITION p04 VALUES LESS THAN ('2018-04-01 00:00:00') ENGINE = InnoDB, PARTITION p00 VALUES LESS THAN (MAXVALUE) ENGINE = InnoDB) */; 看到 PRIMARY KEY (“id”,”create_time”),UNIQUE KEY “uniq_ui_ct” (“user_id”,”create_time”)也许会疑惑，为什么要对自增主键和唯一索引添加create_time的复合主键和联合唯一索引，这是因为range的分区要求唯一索引类必须和分区键搭配构成分区表的唯一索引，不然会报错误：1503 - A PRIMARY KEY/UNIQUE INDEX must include all columns in the table’s partitioning function。还有一个原因，就是修改主键影响最大的就是 DELETE 触发器，新表上的主键字段在旧表上不存在，无法根据主键条件触发删除新表数据。而对于INSERT,UPDATE的触发器，依然是 REPLACE INTO语法，因为它采用的是先插入，如果违反主键或唯一约束，则根据主键或意义约束删除这条数据，再执行插入。所以如果使用pt-osc去修改删除主键，务必同时添加原主键为 UNIQUE KEY，否则很有可能导致性能问题。 pt-osc 实现在线重定义分区表原理在实现过程中，我也试图只通过一次 pt-osc 过程来实现在线重定义分区表的过程，但是 MySQL DDL语法并不支持同时对分区和普通DDL操作，实现过程如下：123456789101112131415161718192021222324252627282930root@localhost:test&gt;ALTER TABLE "p_test" -&gt; ADD COLUMN "id" bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '自增主键ID' FIRST, -&gt; DROP PRIMARY KEY, -&gt; ADD PRIMARY KEY ("id", "create_time"), -&gt; ADD UNIQUE INDEX "uniq_ui_ct"("user_id", "create_time");Query OK, 0 rows affected (0.33 sec)Records: 0 Duplicates: 0 Warnings: 0root@localhost:test&gt;Alter table "p_test" PARTITION BY RANGE COLUMNS(create_time) -&gt; (PARTITION p01 VALUES LESS THAN ('2017-01-01 00:00:00'), -&gt; PARTITION p02 VALUES LESS THAN ('2017-02-01 00:00:00'), -&gt; PARTITION p03 VALUES LESS THAN ('2017-03-01 00:00:00'), -&gt; PARTITION p04 VALUES LESS THAN ('2017-04-01 00:00:00'), -&gt; PARTITION p00 VALUES LESS THAN (MAXVALUE));Query OK, 0 rows affected (1.49 sec)Records: 0 Duplicates: 0 Warnings: 0root@localhost:test&gt;ALTER TABLE "p_test" -&gt; ADD COLUMN "id" bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '自增主键ID' FIRST, -&gt; DROP PRIMARY KEY, -&gt; ADD PRIMARY KEY ("id", "create_time"), -&gt; ADD UNIQUE INDEX "uniq_ui_ct"("user_id", "create_time"), -&gt; PARTITION BY RANGE COLUMNS(create_time) -&gt; (PARTITION p01 VALUES LESS THAN ('2017-01-01 00:00:00'), -&gt; PARTITION p02 VALUES LESS THAN ('2017-02-01 00:00:00'), -&gt; PARTITION p03 VALUES LESS THAN ('2017-03-01 00:00:00'), -&gt; PARTITION p04 VALUES LESS THAN ('2017-04-01 00:00:00'), -&gt; PARTITION p00 VALUES LESS THAN (MAXVALUE));ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'PARTITION BY RANGE COLUMNS(create_time)(PARTITION p01 VALUES LESS THAN ('2017-0' at line 6 为了便于观察和理解 pt-osc 实现过程在线重定义过程，我们通过 –no-drop-old-table 保留原普通表结构和数据 pt-osc 修改表主键pt-osc 实现修改主键过程和原理：123456789101112131415161718192021222324252627282930313233343536373839pt-online-schema-change -uroot -poRcl_123 -hlocalhost -P3307 D=test,t=p_test \--alter "ADD COLUMN id bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '自增主键ID' FIRST, DROP PRIMARY KEY, ADD PRIMARY KEY (id, create_time), ADD UNIQUE INDEX uniq_ui_ct(user_id, create_time);" \--no-check-unique-key-change --no-check-alter --no-drop-old-table --print --dry-runOperation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Starting a dry run. `test`.`p_test` will not be altered. Specify --execute instead of --dry-run to alter the table.Creating new table...CREATE TABLE `test`.`_p_test_new` ( `user_id` varchar(20) NOT NULL, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY (`user_id`), KEY `idx_create_time` (`create_time`)) ENGINE=InnoDB DEFAULT CHARSET=utf8Created new table test._p_test_new OK.Altering new table...ALTER TABLE `test`.`_p_test_new` ADD COLUMN id bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '自增主键ID' FIRST, DROP PRIMARY KEY, ADD PRIMARY KEY (id, create_time), ADD UNIQUE INDEX uniq_ui_ct(user_id, create_time);Altered `test`.`_p_test_new` OK.Using original table index PRIMARY for the DELETE trigger instead of new table index PRIMARY because the new table index uses column id which does not exist in the original table.Not creating triggers because this is a dry run.Not copying rows because this is a dry run.INSERT LOW_PRIORITY IGNORE INTO `test`.`_p_test_new` (`user_id`, `create_time`) SELECT `user_id`, `create_time` FROM `test`.`p_test` LOCK IN SHARE MODE /*pt-online-schema-change 10134 copy table*/Not swapping tables because this is a dry run.Not dropping old table because this is a dry run.Not dropping triggers because this is a dry run.DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_del`DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_upd`DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_ins`2018-04-18T15:10:26 Dropping new table...DROP TABLE IF EXISTS `test`.`_p_test_new`;2018-04-18T15:10:26 Dropped new table OK.Dry run complete. `test`.`p_test` was not altered. 操作、实现过程修改主键如下：1234pt-online-schema-change -uroot -poRcl_123 -hlocalhost -P3307 D=test,t=p_test \--alter "ADD COLUMN id bigint(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '自增主键ID' FIRST, DROP PRIMARY KEY, ADD PRIMARY KEY (id, create_time), ADD UNIQUE INDEX uniq_ui_ct(user_id, create_time);" \--no-check-unique-key-change --no-check-alter --no-drop-old-table --max-lag=1 --execute 对比 _p_test_new 和 p_test 表结构，符合预期，表主键已经由 varchar 字符串主键修改为自增和 datetime 类型联合主键类型123456789101112131415CREATE TABLE "_p_test_old" ( "user_id" varchar(20) NOT NULL, "create_time" datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY ("user_id"), KEY "idx_create_time" ("create_time")) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE "p_test" ( "id" bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键ID', "user_id" varchar(20) NOT NULL, "create_time" datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY ("id","create_time"), UNIQUE KEY "uniq_ui_ct" ("user_id","create_time"), KEY "idx_create_time" ("create_time")) ENGINE=InnoDB DEFAULT CHARSET=utf8; pt-osc 在线重定义分区表在线重定义普通表转分区表过程和原理：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748pt-online-schema-change -uroot -poRcl_123 -hlocalhost -P3307 D=test,t=p_test \--alter "PARTITION BY RANGE COLUMNS(create_time)( PARTITION p01 VALUES LESS THAN ('2017-01-01 00:00:00'), PARTITION p02 VALUES LESS THAN ('2017-02-01 00:00:00'), PARTITION p03 VALUES LESS THAN ('2017-03-01 00:00:00'), PARTITION p04 VALUES LESS THAN ('2017-04-01 00:00:00'), PARTITION p00 VALUES LESS THAN (MAXVALUE));" \--no-drop-old-table --max-lag=1 --print --dry-runOperation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1Starting a dry run. `test`.`p_test` will not be altered. Specify --execute instead of --dry-run to alter the table.Creating new table...CREATE TABLE `test`.`_p_test_new` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键ID', `user_id` varchar(20) NOT NULL, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY (`id`,`create_time`), UNIQUE KEY `uniq_ui_ct` (`user_id`,`create_time`), KEY `idx_create_time` (`create_time`)) ENGINE=InnoDB AUTO_INCREMENT=2048 DEFAULT CHARSET=utf8Created new table test._p_test_new OK.Altering new table...ALTER TABLE `test`.`_p_test_new` PARTITION BY RANGE COLUMNS(create_time)( PARTITION p01 VALUES LESS THAN ('2017-01-01 00:00:00'), PARTITION p02 VALUES LESS THAN ('2017-02-01 00:00:00'), PARTITION p03 VALUES LESS THAN ('2017-03-01 00:00:00'), PARTITION p04 VALUES LESS THAN ('2017-04-01 00:00:00'), PARTITION p00 VALUES LESS THAN (MAXVALUE));Altered `test`.`_p_test_new` OK.Not creating triggers because this is a dry run.Not copying rows because this is a dry run.INSERT LOW_PRIORITY IGNORE INTO `test`.`_p_test_new` (`id`, `user_id`, `create_time`) SELECT `id`, `user_id`, `create_time` FROM `test`.`p_test` LOCK IN SHARE MODE /*pt-online-schema-change 5211 copy table*/Not swapping tables because this is a dry run.Not dropping old table because --no-drop-old-table was specified.Not dropping triggers because this is a dry run.DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_del`DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_upd`DROP TRIGGER IF EXISTS `test`.`pt_osc_test_p_test_ins`2018-04-18T10:23:47 Dropping new table...DROP TABLE IF EXISTS `test`.`_p_test_new`;2018-04-18T10:23:47 Dropped new table OK.Dry run complete. `test`.`p_test` was not altered. 实现在线重定义分区表：12345678pt-online-schema-change -uroot -poRcl_123 -hlocalhost -P3307 D=test,t=p_test \--alter "PARTITION BY RANGE COLUMNS(create_time)( PARTITION p01 VALUES LESS THAN ('2017-01-01 00:00:00'), PARTITION p02 VALUES LESS THAN ('2017-02-01 00:00:00'), PARTITION p03 VALUES LESS THAN ('2017-03-01 00:00:00'), PARTITION p04 VALUES LESS THAN ('2017-04-01 00:00:00'), PARTITION p00 VALUES LESS THAN (MAXVALUE));" \--no-drop-old-table --max-lag=1 --execute 对比 __p_test_new 和 p_test 表结构，符合预期结果，表被定义为分区表1234567891011121314151617181920212223CREATE TABLE "p_test" ( "id" bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键ID', "user_id" varchar(20) NOT NULL, "create_time" datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY ("id","create_time"), UNIQUE KEY "uniq_ui_ct" ("user_id","create_time"), KEY "idx_create_time" ("create_time")) ENGINE=InnoDB AUTO_INCREMENT=2048 DEFAULT CHARSET=utf8/*!50500 PARTITION BY RANGE COLUMNS(create_time)(PARTITION p01 VALUES LESS THAN ('2017-01-01 00:00:00') ENGINE = InnoDB, PARTITION p02 VALUES LESS THAN ('2017-02-01 00:00:00') ENGINE = InnoDB, PARTITION p03 VALUES LESS THAN ('2017-03-01 00:00:00') ENGINE = InnoDB, PARTITION p04 VALUES LESS THAN ('2017-04-01 00:00:00') ENGINE = InnoDB, PARTITION p00 VALUES LESS THAN (MAXVALUE) ENGINE = InnoDB) */; CREATE TABLE "__p_test_old" ( "id" bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键ID', "user_id" varchar(20) NOT NULL, "create_time" datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '记录创建时间', PRIMARY KEY ("id","create_time"), UNIQUE KEY "uniq_ui_ct" ("user_id","create_time"), KEY "idx_create_time" ("create_time")) ENGINE=InnoDB AUTO_INCREMENT=2048 DEFAULT CHARSET=utf8; 总结pt-osc实现在线重定义普通标转分区表原理：pt-osc 首先创建一个不可见的临时表，然后对临时表修改表结构或者重定义分区表，再后创建更新、删除、插入3个触发器，按一个chunk-size大小拷贝数据，拷贝过程中对chunk块持有s锁，同时对新增的insert、update、delete操作通过触发器写入临时表，因为有唯一索引 uniq_ui_ct 避免了 update 和 delete 操作导致可能对临时表的全表扫描，复制操作完成后，analyze 新表，重新 rename 表名，删除普通表、触发器，锁只会存在对每一个 chunk 复制和 rename 表名的时候。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>pt-tools</tag>
        <tag>MySQL 优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 优化之美：对一条简单 SQL 优化的理解、分析]]></title>
    <url>%2F2018%2F04%2F16%2FSQL%2FMySQL_SQL_4%2F</url>
    <content type="text"><![CDATA[问题 SQL这个SQL其实比较简单，优化难度也不大，我们主要来讲讲在SQL优化中的技巧和常识，而不是一看到多表连接或者长度而吓到SQL执行时间40s,SQL文本如下：12345678910111213141516171819202122232425262728293031323334353637SELECT u.id AS user_id, u.integral_level_rate_id AS integral_level_rate_id, l1.rate AS integral_level_rate, NOW() AS create_time, (CASE WHEN a.total IS NULL THEN 0 ELSE a.total END) AS integral, (CASE WHEN b.total IS NULL THEN 0 ELSE b.total END) AS integralc, '2017-07-01 00:00:00' AS time_statistics FROM user_info u LEFT JOIN (SELECT i1.user_id, (CASE WHEN SUM(i1.integral_value) IS NULL THEN 0 ELSE SUM(i1.integral_value) END ) AS total FROM integral_record_detail i1 WHERE i1.user_type = 1 AND i1.revenue_expenditure_type = 2 AND i1.integral_source = 7 AND i1.STATUS = 1 AND i1.source_type = 1 AND i1.integral_type = 1 AND i1.create_time &gt;= '2017-07-01 00:00:00' AND i1.create_time &lt; '2017-07-07 00:00:00' GROUP BY i1.user_id) a ON u.id = a.user_id LEFT JOIN (SELECT i2.user_id, (CASE WHEN SUM(i2.integral_value) IS NULL THEN 0 ELSE SUM(i2.integral_value) END ) AS total FROM integral_record_detail i2 WHERE i2.user_type = 1 AND i2.revenue_expenditure_type = 1 AND i2.integral_source = 1 AND i2.integral_type = 1 AND i2.STATUS = 1 AND i2.source_type = 2 AND i2.create_time &gt;= '2017-07-01 00:00:00' AND i2.create_time &lt; '2017-08-01 00:00:00' GROUP BY i2.user_id) b ON u.id = b.user_id LEFT JOIN integral_level_rate l1 ON l1.id = u.integral_level_rate_id WHERE u.create_time &lt; '2017-08-01 00:00:00'; 执行计划：12345678 id select_type table partitions type possible_keys key key_len ref rows filtered Extra ------ ----------- ---------- ---------- ------ ---------------------------------------------------- --------------- ------- ----------------------------- ------- -------- --------------------------------------------------------------------- 1 PRIMARY u (NULL) ALL (NULL) (NULL) (NULL) (NULL) 100130 33.33 Using where 1 PRIMARY &lt;derived2&gt; (NULL) ALL (NULL) (NULL) (NULL) (NULL) 2 100.00 Using where; Using join buffer (Block Nested Loop) 1 PRIMARY &lt;derived3&gt; (NULL) ALL (NULL) (NULL) (NULL) (NULL) 2 100.00 Using where; Using join buffer (Block Nested Loop) 1 PRIMARY l1 (NULL) eq_ref PRIMARY PRIMARY 4 test.u.integral_level_rate_id 1 100.00 (NULL) 3 DERIVED i2 (NULL) index idx_user_id,idx_ut_ret_is,idx_create_time,idx_status idx_user_id 5 (NULL) 4036510 0.00 Using where 2 DERIVED i1 (NULL) range idx_user_id,idx_ut_ret_is,idx_create_time,idx_status idx_create_time 6 (NULL) 420024 0.00 Using index condition; Using where; Using temporary; Using filesort 表结构机索引为：12345678910111213141516171819202122232425262728293031CREATE TABLE "integral_level_rate" ( "id" int(11) NOT NULL AUTO_INCREMENT COMMENT '主键ID', "integral_level_rate_id" int(11) DEFAULT NULL, "rate" int(11) DEFAULT NULL, PRIMARY KEY ("id")) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE "integral_record_detail" ( "id" int(11) NOT NULL AUTO_INCREMENT COMMENT '主键ID', "user_id" int(11) DEFAULT NULL COMMENT '用户ID', "source_type" char(1) DEFAULT NULL COMMENT '积分来源类型1个人2商家', "integral_type" char(1) DEFAULT NULL COMMENT '积分类型1E积分2激励E积分3享积分', "revenue_expenditure_type" char(1) DEFAULT NULL COMMENT '收支类型1增加2扣减', "integral_source" char(2) DEFAULT NULL COMMENT '积分来源1直接消费2消费推荐3销售4销售推荐5升级6激励E积分7转化成享积分8升级推荐', "integral_value" decimal(12,2) DEFAULT NULL COMMENT '积分值', "create_time" datetime DEFAULT NULL COMMENT '创建时间', "status" char(1) DEFAULT NULL COMMENT '状态0删除1正常2审核未通过', "user_type" char(1) DEFAULT NULL COMMENT '用户类型', PRIMARY KEY ("id"), KEY "idx_user_id" ("user_id"), KEY "idx_ut_ret_is" ("user_type","revenue_expenditure_type","integral_source"), KEY "idx_create_time" ("create_time"), KEY "idx_status" ("status")) ENGINE=InnoDB DEFAULT CHARSET=utf8 ;CREATE TABLE "user_info" ( "id" int(11) NOT NULL AUTO_INCREMENT COMMENT '主键ID', "create_time" datetime DEFAULT NULL COMMENT '创建时间', "integral_level_rate_id" int(11) DEFAULT NULL COMMENT '分档比例id', PRIMARY KEY ("id")) ENGINE=InnoDB DEFAULT CHARSET=utf8; 优化分析1、通过观察执行计划可知 i2 表最先执行，时间范围跨度也不大，通过时间列检索按道理应该会很快，会不会是 idx_user_id 索引干扰了优化器，进而选择了错误的执行计划。2、再者 integral_record_detail 的 source_type，integral_type，revenue_expenditure_type，integral_source，status，user_type 列值比较少，单列索引的效率必然不高。3、通过表integral_record_detail和SQL文本可知，各状态类型的数据都是字符串，而SQL传值竟然是数值，这明显产生了隐式转换。 将SQL隐式转换去掉后，sql执行时间3s，执行计划如下：12345678 id select_type table partitions type possible_keys key key_len ref rows filtered Extra ------ ----------- ---------- ---------- ----------- ---------------------------------------------------- ------------------------ ------- ----------------------------- ------ -------- ----------------------------------------------------------------------------------------- 1 PRIMARY u (NULL) ALL (NULL) (NULL) (NULL) (NULL) 100130 33.33 Using where 1 PRIMARY &lt;derived2&gt; (NULL) ref &lt;auto_key0&gt; &lt;auto_key0&gt; 5 test.u.id 10 100.00 (NULL) 1 PRIMARY &lt;derived3&gt; (NULL) ref &lt;auto_key0&gt; &lt;auto_key0&gt; 5 test.u.id 10 100.00 (NULL) 1 PRIMARY l1 (NULL) eq_ref PRIMARY PRIMARY 4 test.u.integral_level_rate_id 1 100.00 (NULL) 3 DERIVED i2 (NULL) index_merge idx_user_id,idx_ut_ret_is,idx_create_time,idx_status idx_ut_ret_is,idx_status 15,4 (NULL) 131679 0.37 Using intersect(idx_ut_ret_is,idx_status); Using where; Using temporary; Using filesort 2 DERIVED i1 (NULL) index_merge idx_user_id,idx_ut_ret_is,idx_create_time,idx_status idx_ut_ret_is,idx_status 15,4 (NULL) 129651 0.10 Using intersect(idx_ut_ret_is,idx_status); Using where; Using temporary; Using filesort SQL 优化真的就这么结束了么，明显不会，这不是最优的，计划告诉我们还有更优的执行计划，create_time是一个很好的过滤条件，居然在执行计划中没出现，显然不符合我所期望的，根据过滤条件，我创建了两个索引：idx_iisurc(integral_source, integral_type, status, user_type, source_type, revenue_expenditure_type, create_time)idx_iisuru(integral_source, integral_type, status, user_type, source_type, revenue_expenditure_type, user_id)至于我为何如此建索引，请参考 索引设计原则、使用场景及失效场景：https://cai182081.github.io/2018/04/03/SQL/DB_INDEX_1/第一个索引最后通过 create_time 过滤，而第二个 通过 user_id 消除排序执行时长分别为0.8s，1s，执行计划分别如下：12345678 id select_type table partitions type possible_keys key key_len ref rows filtered Extra ------ ----------- ---------- ---------- ------ --------------------------------------------------------------- ----------- ------- ----------------------------- ------ -------- -------------------------------------------------------- 1 PRIMARY u (NULL) ALL (NULL) (NULL) (NULL) (NULL) 100130 33.33 Using where 1 PRIMARY &lt;derived2&gt; (NULL) ref &lt;auto_key0&gt; &lt;auto_key0&gt; 5 test.u.id 10 100.00 (NULL) 1 PRIMARY &lt;derived3&gt; (NULL) ref &lt;auto_key0&gt; &lt;auto_key0&gt; 5 test.u.id 10 100.00 (NULL) 1 PRIMARY l1 (NULL) eq_ref PRIMARY PRIMARY 4 test.u.integral_level_rate_id 1 100.00 (NULL) 3 DERIVED i2 (NULL) range idx_user_id,idx_ut_ret_is,idx_create_time,idx_status,idx_iisurc idx_iisurc 33 (NULL) 1276 100.00 Using index condition; Using temporary; Using filesort 2 DERIVED i1 (NULL) range idx_user_id,idx_ut_ret_is,idx_create_time,idx_status,idx_iisurc idx_iisurc 33 (NULL) 375 100.00 Using index condition; Using temporary; Using filesort 12345678 id select_type table partitions type possible_keys key key_len ref rows filtered Extra ------ ----------- ---------- ---------- ------ ---------------------- ----------- ------- ----------------------------------- ------ -------- ------------------------------------ 1 PRIMARY u (NULL) ALL (NULL) (NULL) (NULL) (NULL) 100130 33.33 Using where 1 PRIMARY &lt;derived2&gt; (NULL) ref &lt;auto_key0&gt; &lt;auto_key0&gt; 5 test.u.id 10 100.00 (NULL) 1 PRIMARY &lt;derived3&gt; (NULL) ref &lt;auto_key0&gt; &lt;auto_key0&gt; 5 test.u.id 10 100.00 (NULL) 1 PRIMARY l1 (NULL) eq_ref PRIMARY PRIMARY 4 test.u.integral_level_rate_id 1 100.00 (NULL) 3 DERIVED i2 (NULL) ref idx_user_id,idx_iisuru idx_iisuru 27 const,const,const,const,const,const 14970 11.11 Using index condition; Using where 2 DERIVED i1 (NULL) ref idx_user_id,idx_iisuru idx_iisuru 27 const,const,const,const,const,const 14378 11.11 Using index condition; Using where 所以我们选择在生产环境下创建了索引idx_iisurc(integral_source, integral_type, status, user_type, source_type, revenue_expenditure_type, create_time) 以及改写掉隐式转换，消除隐式转换的SQL 文本如下：12345678910111213141516171819202122232425262728293031323334353637SELECT u.id AS user_id, u.integral_level_rate_id AS integral_level_rate_id, l1.rate AS integral_level_rate, NOW() AS create_time, (CASE WHEN a.total IS NULL THEN 0 ELSE a.total END) AS integral, (CASE WHEN b.total IS NULL THEN 0 ELSE b.total END) AS integralc, '2017-07-01 00:00:00' AS time_statistics FROM user_info u LEFT JOIN (SELECT i1.user_id, (CASE WHEN SUM(i1.integral_value) IS NULL THEN 0 ELSE SUM(i1.integral_value) END ) AS total FROM integral_record_detail i1 WHERE i1.user_type = '1' AND i1.revenue_expenditure_type = '2' AND i1.integral_source = '7' AND i1.STATUS = '1' AND i1.source_type = '1' AND i1.integral_type = '1' AND i1.create_time &gt;= '2017-07-01 00:00:00' AND i1.create_time &lt; '2017-07-07 00:00:00' GROUP BY i1.user_id) a ON u.id = a.user_id LEFT JOIN (SELECT i2.user_id, (CASE WHEN SUM(i2.integral_value) IS NULL THEN 0 ELSE SUM(i2.integral_value) END ) AS total FROM integral_record_detail i2 WHERE i2.user_type = '1' AND i2.revenue_expenditure_type = '1' AND i2.integral_source = '1' AND i2.integral_type = '1' AND i2.STATUS = '1' AND i2.source_type = '2' AND i2.create_time &gt;= '2017-07-01 00:00:00' AND i2.create_time &lt; '2017-08-01 00:00:00' GROUP BY i2.user_id) b ON u.id = b.user_id LEFT JOIN integral_level_rate l1 ON l1.id = u.integral_level_rate_id WHERE u.create_time &lt; '2017-08-01 00:00:00';]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库优化</tag>
        <tag>SQL 优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark 2.3.0 on Yarn 集群搭建（生产环境下）]]></title>
    <url>%2F2018%2F04%2F15%2FSpark%2FSpark_Cluster%2F</url>
    <content type="text"><![CDATA[Spark 集群服务器及节点规划12 Hadoop 完全分布式集群安装Hadoop 完全分布式集群搭建参考文章： Spark on Yarn 集群搭建安装ScalaScala下载地址：https://codeload.github.com/scala/scala/tar.gz/v2.12.51234export SCALA_VERSION=scala-2.13.0-M3sudo tar -zxf $SCALA_VERSION.tgz -C /usr/local/sudo ln -sv /usr/local/$SCALA_VERSION /usr/local/scalasudo chown -R hadoop:hadoop /usr/local/$SCALA_VERSION 安装SparkSpark 下载地址：http://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz1234export SPARK_VERSION=spark-2.3.0-bin-hadoop2.7sudo tar -zxf $SPARK_VERSION.tgz -C /usr/local/sudo ln -sv /usr/local/$SPARK_VERSION /usr/local/sparksudo chown -R hadoop:hadoop /usr/local/$SPARK_VERSION 配置Scala、Spark环境变量12345678910cat &gt;&gt; .bash_profile &lt;&lt;EOF# Scalaexport SCALA_HOME=/usr/local/scalaexport PATH=\$PATH:\$SCALA_HOME/bin# Sparkexport SPARK_HOME=/usr/local/sparkexport PATH=\$PATH:\$SPARK_HOME/binEOFsource .bash_profile 配置 Spark 安装目录12sudo mkdir -pv /data/spark/&#123;local,work&#125;sudo chown -R hadoop:hadoop /data/spark 配置 spark-env.sh 文件123456789101112131415161718192021222324252627cat &gt;&gt; /usr/local/spark/conf/spark-env.sh &lt;&lt;EOFexport JAVA_HOME=/usr/local/jdkexport SCALA_HOME=/usr/local/scalaexport HADOOP_HOME=/usr/local/hadoopexport SPARK_HOME=/usr/local/sparkexport LD_LIBARARY_PATH=\$HADOOP_HOME/lib:\$HADOOP_HOME/lib/nativeexport SPARK_LIRBARY_PATH=.:\$JAVA_HOME/lib:\$JAVA_HOME/jre/lib:\$HADOOP_HOME/lib:\$HADOOP_HOME/lib/native# Spark的master地址export SPARK_MASTER_HOST=192.168.1.31# Spark端口export SPARK_MASTER_PORT=7077# Spark的Web端口export SPARK_MASTER_WEBUI_PORT=8080# Worker的cpu核数export SPARK_WORKER_CORES=2# Worker内存大小export SPARK_WORKER_MEMORY=4G# Driver内存大小export SPARK_DRIVER_MEMORY=1G# Spark的log日志目录export SPARK_LOG_DIR=/usr/local/spark/logs# Spark的local目录export SPARK_LOCAL_DIRS=/data/spark/local# Worker目录export SPARK_WORKER_DIR=/data/spark/workexport SPARK_JAVA_OPTS="-Dspark.storage.blockManagerHeartBeatMs=60000-Dspark.local.dir=\$SPARK_LOCAL_DIR -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:\$SPARK_HOME/logs/gc.log -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSInitiatingOccupancyFraction=60" EOF 配置 spark-env.sh 文件1234567891011121314151617181920212223242526272829303132333435hadoop fs -mkdir -p /data/spark/applicationHistorycat &gt;&gt; /usr/local/spark/conf/spark-defaults.conf &lt;&lt;EOF# eventLog是否生效（建议开启，可以对已完成的任务记录其详细日志）spark.eventLog.enabled true # eventLog是否启用压缩（cpu性能好的情况下建议开启，以减少内存等的占用）spark.eventLog.compress true # eventLog的文件存放位置，与spark-env.sh中的history server配置位置一致,这两个位置必须手动创建# hadoop fs -mkdir -p /tmp/spark/applicationHistory,否则spark启动失败 spark.eventLog.dir hdfs://node1:9000/data/spark/applicationHistory # 广播块大小spark.broadcast.blockSize 8m # Executor的cpu核数 spark.executor.cores 1 # Executor的内存大小 spark.executor.memory 512m # Executor心跳交换时间间隔spark.executor.heartbeatInterval 20s # 文件抓取的timeoutspark.files.fetchTimeout 120s # 作业最大失败次数（达到此次数后，该作业不再继续执行，运行失败） spark.task.maxFailures 6 # 设置序列化机制（默认使用java的序列化，但是速度很慢，建议使用Kryo） spark.serializer org.apache.spark.serializer.KryoSerializer # 序列化缓冲大小 spark.kryoserializer.buffer.max 256m # Akka调度帧大小 spark.rpc.message.maxSize 128 # 默认并行数 spark.default.parallelism 20 # 最大网络延时 spark.network.timeout 300s # Spark推测机制（建议开启） spark.speculation true EOF cat &gt;&gt; /usr/local/spark/conf/slaves &lt;&lt;EOFnode2node3EOF]]></content>
      <categories>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 3.0.1 完全分布式集群搭建]]></title>
    <url>%2F2018%2F04%2F14%2FHadoop%2FHadoop_CDH%2F</url>
    <content type="text"></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 3.6.3 (生产环境下)副本集群（复制集群/主从集群）安装配置详解]]></title>
    <url>%2F2018%2F04%2F12%2FMongoDB%2FMongDB_Replication%2F</url>
    <content type="text"><![CDATA[MonogDB 复制集群与单机安装非常类似，只有少数不同之处，但鉴于照顾很多初学者或者接触 MongoDB 不多的技术人员，特详细记录 MongoDB 副本集安装配置，与 MongoDB 单机安装步骤多有重复，特在此说明 下载 MongoDB 安装软件123[root@node1 ~]# yum install -y psmisc* numactl* wget net-snmp*[root@node1 ~]# wget https://downloads.mongodb.com/linux/mongodb-linux-x86_64-enterprise-rhel70-3.6.3.tgz -P /dba/tools[root@node1 ~]# wget https://www.percona.com/downloads/percona-server-mongodb-LATEST/percona-server-mongodb-3.4.13-2.11/binary/tarball/percona-server-mongodb-3.4.13-2.11-centos6-x86_64.tar.gz -P /dba/tools 所有节点创建MongoDB组、用户和目录，并赋权限123456[root@node1 ~]# groupadd mongod [root@node1 ~]# useradd -g mongod mongod[root@node1 ~]# passwd mongod[root@node1 ~]# mkdir -pv /data/mongodb/data[root@node1 ~]# chown -R mongod:mongod /data/mongodb[root@node1 ~]# chmod -R 775 /data/mongodb 所有节点安装，并配置环境变量12345[root@node1 ~]# tar -zxf /dba/tools/mongodb-linux-x86_64-enterprise-rhel70-3.6.3.tgz -C /usr/local/[root@node1 ~]# ln -sv /usr/local/mongodb-linux-x86_64-enterprise-rhel70-3.6.3 /usr/local/mongodb[root@node1 ~]# chown -R mongod:mongod /usr/local/mongodb[root@node1 ~]# echo "export PATH=/usr/local/mongodb/bin:\$PATH" &gt;&gt; /etc/profile[root@node1 ~]# source /etc/profile 所有节点优化操作系统参数关闭透明大页12[root@node1 ~]# echo never &gt;&gt; /sys/kernel/mm/transparent_hugepage/enabled[root@node1 ~]# echo never &gt;&gt; /sys/kernel/mm/transparent_hugepage/defrag 修改磁盘io调度策略1[root@node1 ~]# echo deadline &gt; /sys/block/sda/queue/scheduler 修改文件数限制123456[root@node1 ~]# ulimit -f unlimited[root@node1 ~]# ulimit -t unlimited[root@node1 ~]# ulimit -v unlimited[root@node1 ~]# ulimit -n 65535[root@node1 ~]# ulimit -m unlimited[root@node1 ~]# ulimit -u 65535 修改内存分配策略123[root@node1 ~]# echo 0 &gt; /proc/sys/vm/zone_reclaim_mode[root@node1 ~]# sysctl -w vm.zone_reclaim_mode=0[root@node1 ~]# sysctl vm.overcommit_memory=1 配置 MongoDB 参数文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@node1 ~]# su - mongod[mongod@node1 ~]$ cat &gt;&gt; /home/mongod/mongod.conf &lt;&lt;EOFsystemLog: quiet: false path: "/home/mongod/mongod.log" logAppend: true destination: file timeStampFormat: iso8601-localprocessManagement: fork: true pidFilePath: "/home/mongod/mongod.pid"storage: dbPath: "/data/mongodb/data" indexBuildRetry: true journal: enabled: true directoryPerDB: true syncPeriodSecs: 60 engine: wiredTiger wiredTiger: engineConfig: cacheSizeGB: 12 statisticsLogDelaySecs: 0 journalCompressor: snappy directoryForIndexes: true collectionConfig: blockCompressor: snappy indexConfig: prefixCompression: truenet: bindIp: 192.168.1.10,127.0.0.1 port: 47017 maxIncomingConnections: 52528 wireObjectCheck: true ipv6: false unixDomainSocket: enabled: falseoperationProfiling: slowOpThresholdMs: 200 mode: slowOpsecurity: authorization: disabled #clusterAuthMode: keyFile #keyFile: "/home/mongod/keyfile" javascriptEnabled: truesetParameter: enableLocalhostAuthBypass: true authenticationMechanisms: SCRAM-SHA-1replication: oplogSizeMB: 5120 replSetName: configRS secondaryIndexPrefetch: all#sharding: #clusterRole: configsvr #archiveMovedChunks: trueEOF 配置 .mongorc.js在mongod用户家目创建录.mongorc.js 文件123456789101112131415[mongod@node1 ~]$ cat &gt;&gt; /home/mongod/.mongorc.js &lt;&lt;EOFprompt = function() &#123; if (typeof db == 'undefined') &#123; return '(nodb)&gt; ';&#125; try &#123; db.runCommand(&#123;getLastError:1&#125;); &#125; catch (e) &#123; print(e); &#125; return db+" &gt;";&#125;;EOF 更完整 .mongorc.js 的配置文件下载地址 https://pan.lanzou.com/i0tvfqb 初始化数据库123[mongod@node1 ~]$ numactl --interleave=all mongod -f /home/mongod/mongod.conf [mongod@node2 ~]$ numactl --interleave=all mongod -f /home/mongod/mongod.conf [mongod@node3 ~]$ numactl --interleave=all mongod -f /home/mongod/mongod.conf 配置 MongoDB 副本集12345678[mongod@node1 ~]$ mongo 192.168.1.10:47017/admin192.168.1.10:47017/admin&gt; config = &#123;_id: 'configRS', members: [ &#123;_id: 0, host: '192.168.1.10:47017',priority:3&#125;, &#123;_id: 1, host: '192.168.1.11:47017',priority:0,hidden:true&#125;, &#123;_id: 2, host: '192.168.1.12:47017',arbiterOnly:true&#125;]&#125;192.168.1.10:47017/admin&gt; rs.initiate(config)192.168.1.10:47017/admin&gt; rs.conf()192.168.1.10:47017/admin&gt; rs.status() 添加管理员账号12192.168.1.10:47017/admin&gt; db.createUser(&#123;user:'admin',pwd:'oRcl_123', roles:[&#123;role:'userAdminAnyDatabase', db:'admin'&#125;]&#125;)192.168.1.10:47017/admin&gt; db.auth("admin","oRcl_123") MongoDB 副本集 配置 keyfile 文件1234567[mongod@node1 ~]$ openssl rand -base64 753 &gt; keyfile[mongod@node1 ~]$ scp /home/mongod/keyfile mongod@192.168.1.11:/home/mongod[mongod@node1 ~]$ scp /home/mongod/keyfile mongod@192.168.1.12:/home/mongod[mongod@node1 ~]$ chmod 600 keyfile[mongod@node2 ~]$ chmod 600 keyfile[mongod@node3 ~]$ chmod 600 keyfile 开启用户验证参数1234567891011[mongod@node1 ~]$ sed -i 's/authorization: disabled/authorization: enabled/g' /home/mongod/mongod.conf[mongod@node1 ~]$ sed -i 's/#clusterAuthMode: keyFile/clusterAuthMode: keyFile/g' /home/mongod/mongod.conf[mongod@node1 ~]$ sed -i 's/#keyFile: "\/home\/mongod\/keyfile"/keyFile: "\/home\/mongod\/keyfile"/g' /home/mongod/mongod.conf[mongod@node2 ~]$ sed -i 's/authorization: disabled/authorization: enabled/g' /home/mongod/mongod.conf[mongod@node2 ~]$ sed -i 's/#clusterAuthMode: keyFile/clusterAuthMode: keyFile/g' /home/mongod/mongod.conf[mongod@node2 ~]$ sed -i 's/#keyFile: "\/home\/mongod\/keyfile"/keyFile: "\/home\/mongod\/keyfile"/g' /home/mongod/mongod.conf[mongod@node3 ~]$ sed -i 's/authorization: disabled/authorization: enabled/g' /home/mongod/mongod.conf [mongod@node3 ~]$ sed -i 's/#clusterAuthMode: keyFile/clusterAuthMode: keyFile/g' /home/mongod/mongod.conf[mongod@node3 ~]$ sed -i 's/#keyFile: "\/home\/mongod\/keyfile"/keyFile: "\/home\/mongod\/keyfile"/g' /home/mongod/mongod.conf 重启 MongoDB 数据库，并验证安全验证登录1234567891011[mongod@node1 ~]$ killall mongod[mongod@node1 ~]$ numactl --interleave=all mongod -f /home/mongod/mongod.conf[mongod@node2 ~]$ killall mongod [mongod@node2 ~]$ numactl --interleave=all mongod -f /home/mongod/mongod.conf[mongod@node3 ~]$ killall mongod [mongod@node3 ~]$ numactl --interleave=all mongod -f /home/mongod/mongod.conf[mongod@node1 ~]$ mongo -u admin -poRcl_123 192.168.1.10:47017/admin192.168.1.10:47017/admin&gt; rs.status() 设置MongoDB开机自启动12/etc/rc.d/rc.localnumactl --interleave=all mongod -f /home/mongod/mongod.conf 测试副本集的故障转移功能]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 3.6.3 （生产环境下）二进制单机安装与安全认证配置]]></title>
    <url>%2F2018%2F04%2F12%2FMongoDB%2FMongDB_Install%2F</url>
    <content type="text"><![CDATA[MongoDB 单机安装较为简单，实际应用较少，倒是副本集和分片集群较多。但在实际使用中，很多技术人员在使用中大多只是随便安装配置，很多mongodb参数都是默认值，参数并没设置最优，系统设置也大多为默认值，甚至生产环境下没有打开安全验证登录，性能和安全效果并不佳，特在此记录作者学习和使用过程中的心得、体验 下载 MongoDB 安装软件123[root@node1 ~]# yum install -y psmisc* numactl* wget net-snmp*[root@node1 ~]# wget https://downloads.mongodb.com/linux/mongodb-linux-x86_64-enterprise-rhel70-3.6.3.tgz -P /dba/tools[root@node1 ~]# wget https://www.percona.com/downloads/percona-server-mongodb-LATEST/percona-server-mongodb-3.4.13-2.11/binary/tarball/percona-server-mongodb-3.4.13-2.11-centos6-x86_64.tar.gz -P /dba/tools 创建MongoDB组、用户和目录，并赋权限12345[root@node1 ~]# groupadd mongod [root@node1 ~]# useradd -g mongod mongod[root@node1 ~]# mkdir -pv /data/mongodb/data[root@node1 ~]# chown -R mongod:mongod /data/mongodb[root@node1 ~]# chmod -R 775 /data/mongodb 安装，并配置环境变量12345[root@node1 ~]# tar -zxf /dba/tools/mongodb-linux-x86_64-enterprise-rhel70-3.6.3.tgz -C /usr/local/[root@node1 ~]# ln -sv /usr/local/mongodb-linux-x86_64-enterprise-rhel70-3.6.3 /usr/local/mongodb[root@node1 ~]# chown -R mongod:mongod /usr/local/mongodb[root@node1 ~]# echo "export PATH=/usr/local/mongodb/bin:\$PATH" &gt;&gt; /etc/profile[root@node1 ~]# source /etc/profile 优化操作系统参数关闭透明大页12[root@node1 ~]# echo never &gt;&gt; /sys/kernel/mm/transparent_hugepage/enabled[root@node1 ~]# echo never &gt;&gt; /sys/kernel/mm/transparent_hugepage/defrag 修改磁盘io调度策略1[root@node1 ~]# echo deadline &gt; /sys/block/sda/queue/scheduler 修改文件数限制123456[root@node1 ~]# ulimit -f unlimited[root@node1 ~]# ulimit -t unlimited[root@node1 ~]# ulimit -v unlimited[root@node1 ~]# ulimit -n 65535[root@node1 ~]# ulimit -m unlimited[root@node1 ~]# ulimit -u 65535 修改内存分配策略123[root@node1 ~]# echo 0 &gt; /proc/sys/vm/zone_reclaim_mode[root@node1 ~]# sysctl -w vm.zone_reclaim_mode=0[root@node1 ~]# sysctl vm.overcommit_memory=1 配置 MongoDB 参数文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@node1 ~]# su - mongod[mongod@node1 ~]$ cat &gt;&gt; /home/mongod/mongod.conf &lt;&lt;EOFsystemLog: quiet: false path: "/home/mongod/mongod.log" logAppend: true destination: file timeStampFormat: iso8601-localprocessManagement: fork: true pidFilePath: "/home/mongod/mongod.pid"storage: dbPath: "/data/mongodb/data" indexBuildRetry: true journal: enabled: true directoryPerDB: true syncPeriodSecs: 60 engine: wiredTiger wiredTiger: engineConfig: cacheSizeGB: 12 statisticsLogDelaySecs: 0 journalCompressor: snappy directoryForIndexes: true collectionConfig: blockCompressor: snappy indexConfig: prefixCompression: truenet: bindIp: 192.168.1.10,127.0.0.1 port: 47017 maxIncomingConnections: 65536 wireObjectCheck: true ipv6: false unixDomainSocket: enabled: falseoperationProfiling: slowOpThresholdMs: 200 mode: slowOpsecurity: authorization: disabled #clusterAuthMode: keyFile #keyFile: "/home/mongod/keyfile"setParameter: enableLocalhostAuthBypass: true authenticationMechanisms: SCRAM-SHA-1#replication: #oplogSizeMB: 5120 #replSetName: configRS #secondaryIndexPrefetch: all#sharding: #clusterRole: configsvr #archiveMovedChunks: trueEOF 配置 .mongorc.js123456789101112131415[mongod@node1 ~]$ cat &gt;&gt; /home/mongod/.mongorc.js &lt;&lt;EOFprompt = function() &#123; if (typeof db == 'undefined') &#123; return '(nodb)&gt; ';&#125; try &#123; db.runCommand(&#123;getLastError:1&#125;); &#125; catch (e) &#123; print(e); &#125; return db+" &gt;";&#125;;EOF 在mongod用户家目创建录.mongorc.js 文件，更完整的配置文件下载 https://pan.lanzou.com/i0tvfqb 启动并登录数据库12[mongod@node1 ~]$ numactl --interleave=all mongod -f /home/mongod/mongod.conf [mongod@node1 ~]$ mongo 192.168.1.10:47017/admin 添加管理员账号，并开启用户验证参数12345192.168.1.110:47017/admin&gt; db.createUser(&#123;user:'admin',pwd:'oRcl_123', roles:[&#123;role:'userAdminAnyDatabase', db:'admin'&#125;]&#125;)192.168.1.110:47017/admin&gt; db.auth("admin","oRcl_123")[mongod@node1 ~]$ sed -i 's/authorization: disabled/authorization: enabled/g' /home/mongod/mongod.conf [root@node1 ~]# pkill mongod 重启 MongoDB 数据库，并验证安全验证登录1234[mongod@node1 ~] pkill mongod[mongod@node1 ~] numactl --interleave=all mongod -f /home/mongod/mongod.conf [mongod@node1 ~] mongo -u admin -poRcl_123 192.168.1.10:47017/admin192.168.0.210:47017/admin&gt; show dbs;]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL SQL 优化技巧——巧妙利用伪列实现SQL优化]]></title>
    <url>%2F2018%2F04%2F11%2FSQL%2FMySQL_SQL%20_3%2F</url>
    <content type="text"><![CDATA[问题SQL及执行计划SQL 文本如下：12345678SELECT id, user_id, vote_num FROM vote_record_memory WHERE id &gt; 725152 AND group_id = 0 AND STATUS = 1 AND create_time &lt; '2018-04-11 23:59:59' AND MOD(id, '12') = '5' ORDER BY id ASC LIMIT 5000; 执行计划如下：1234567891011121314*************************** 1. row *************************** id: 1 select_type: SIMPLE table: vote_record_memory partitions: NULL type: index_mergepossible_keys: PRIMARY,idx_status,idx_group_id,idx_create_time,idx_mod_id key: idx_group_id,idx_status key_len: 86,83 ref: NULL rows: 13846 filtered: 5.00 Extra: Using intersect(idx_group_id,idx_status); Using where; Using filesort1 row in set, 1 warning (0.00 sec) SQL性能定位及分析根据看到此SQL 初步定到 r.apply_time LIKE CONCAT(‘2017-11-07’, ‘%’) 日期类型和字符串类型隐式转换，NOT IN子查询语句无法走索引，用NOT EXISTS改写，改写SQL优化后，得到执行计划：12345678910111213141516171819202122SELECT COUNT(*) AS count FROM user.user u INNER JOIN user.token t ON u.id = t.user_id INNER JOIN order.user_history h ON u.id = h.user_id INNER JOIN order.loan_record r ON r.history_id = h.id INNER JOIN admin_domain.ACT_HI_PROCINST act on act.BUSINESS_KEY_ = r.loan_record_id WHERE r.approval_result != 0 AND NOT EXISTS (SELECT n3.id FROM order.loan_record n1 INNER JOIN order.user_history n2 on n1.history_id = n2.id INNER JOIN user.user n3 ON n3.id = n2.user_id WHERE n1.approval_result = 31 AND u.id = n3.id) AND r.apply_time &gt;= '2017-11-07 00:00:00' AND r.apply_time &lt; '2017-11-08 00:00:00' AND t.channel IN (' 201707sudt '); 1234567891011121314151617181920212223SELECT COUNT(*) AS count FROM user.user u INNER JOIN user.token t ON u.id = t.user_id INNER JOIN order.user_history h ON u.id = h.user_id INNER JOIN (SELECT history_id, loan_record_id FROM order.loan_record WHERE approval_result != 0 AND apply_time &gt;= '2017-11-07 00:00:00' AND apply_time &lt; '2017-11-08 00:00:00') r ON r.history_id = h.id INNER JOIN admin_domain.ACT_HI_PROCINST act on act.BUSINESS_KEY_ = r.loan_record_id WHERE NOT EXISTS (SELECT n3.id FROM order.loan_record n1 INNER JOIN order.user_history n2 on n1.history_id = n2.id INNER JOIN user.user n3 ON n3.id = n2.user_id WHERE n1.approval_result = 31 AND u.id = n3.id) AND t.channel IN (' 201707sudt ');]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>SQL 优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 自动化审核工具 Inception、Archer 的安装配置详解]]></title>
    <url>%2F2018%2F04%2F10%2FDevOps%2FMySQL_inception_archer%2F</url>
    <content type="text"><![CDATA[InceptionInception是集审核、执行、回滚于一体的一个自动化运维系统，它可以对提交的所有语句的语法分析，如果语法有问题，都会将相应的错误信息返回给审核者。 还提供SQL语句的执行功能，可执行的语句类型包括常用的DML及DDL语句及truncate table等操作。 Inception在执行 DML时还提供生成回滚语句的功能，对应的操作记录及回滚语句会被存储在备份机器上面，备份机器通过配置Inception参数来指定。 安装编译依赖包1[root@incArcher ~]# yum install -y gcc gcc-c++ make ncurses-devel openssl-devel zlib-devel cmake 安装Bison-2.5.1版本最新Bison版本不兼容，编译无法成功，需卸载重装123456789[root@incArcher ~]# rpm -qa|grep bison | xargs rpm -e --nodeps[root@incArcher ~]# wget http://ftp.gnu.org/gnu/bison/bison-2.5.1.tar.gz -P /dba/tools[root@incArcher ~]# cd /dba/tools[root@incArcher tools]# tar -zxf bison-2.5.1.tar.gz[root@incArcher tools]# cd bison-2.5.1[root@incArcher bison-2.5.1]# ./configure --prefix=/usr/local/bison[root@incArcher bison-2.5.1]# make &amp;&amp; make install[root@incArcher bison-2.5.1]# echo "export PATH=/usr/local/bison/bin:\$PATH" &gt;&gt; /etc/profile[root@incArcher bison-2.5.1]# source /etc/profile 下载 Inception 源码包12[root@incArcher bison-2.5.1]# cd /dba/tools/[root@incArcher tools]# git clone https://github.com/mysql-inception/inception.git 编译安装Inception123456[root@incArcher tools]# cd /dba/tools/inception[root@incArcher inception]# cmake -DWITH_DEBUG=OFF -DCMAKE_INSTALL_PREFIX=/usr/local/inception -DMYSQL_DATADIR=/data/inception/data \-DWITH_SSL=bundled -DCMAKE_BUILD_TYPE=RELEASE -DWITH_ZLIB=bundled \-DMY_MAINTAINER_CXX_WARNINGS="-Wall -Wextra -Wunused -Wno-dev -Wwrite-strings -Wno-strict-aliasing -Wno-unused-parameter -Woverloaded-virtual" \-DMY_MAINTAINER_C_WARNINGS="-Wall -Wextra -Wno-dev -Wunused -Wwrite-strings -Wno-strict-aliasing -Wdeclaration-after-statement"[root@incArcher inception]# make -j6 &amp;&amp; make install 配置Inception 环境变量12[root@incArcher inception]# echo "export PATH=/usr/local/inception/bin:\$PATH" &gt;&gt; /etc/profile[root@incArcher inception]# source /etc/profile 配置Inception 参数文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768[root@incArcher inception]# cat &gt;&gt; /etc/inc.cnf &lt;&lt;EOF[inception]general_log = 1 general_log_file = /usr/local/inception/inception.log port = 6669 socket = /usr/local/inception/inc.socket character-set-server = utf8#Inception 审核规则inception_support_charset = "utf8"inception_check_autoincrement_datatype = 1 inception_check_autoincrement_init_value = 0inception_check_autoincrement_name = 1inception_check_column_comment =1inception_check_column_default_value = 0inception_check_dml_limit = 1inception_check_dml_orderby = 1inception_check_dml_where = 1inception_check_identifier = 1inception_check_index_prefix = 1inception_check_insert_field = 1inception_check_primary_key = 1inception_check_table_comment = 1inception_check_timestamp_default = 1inception_enable_autoincrement_unsigned = 1inception_enable_blob_type = 0inception_enable_column_charset = 1inception_enable_enum_set_bit = 0inception_enable_foreign_key = 0inception_enable_identifer_keyword = 0inception_enable_not_innodb = 1inception_enable_nullable = 0inception_enable_orderby_rand = 1inception_enable_partition_table = 1inception_enable_select_star = 0inception_enable_sql_statistic = 1 inception_max_char_length = 10inception_max_key_parts = 5inception_max_keys = 10inception_max_update_rows = 10000inception_merge_alter_table = 1#inception 支持 OSC 参数inception_osc_bin_dir = /usr/bin/pt-online-schema-changeinception_osc_check_interval = 2inception_osc_chunk_size = 1000inception_osc_chunk_size_limit = 4inception_osc_chunk_time = 0.5inception_osc_critical_thread_connected = 1000inception_osc_critical_thread_running = 80inception_osc_drop_new_table = 1inception_osc_drop_old_table = 1inception_osc_max_lag = 3inception_osc_max_thread_connected = 1000inception_osc_max_thread_running = 80inception_osc_min_table_size = 1inception_osc_on = 1inception_osc_print_none = 1inception_osc_print_sql = 1 inception_read_only = 1 #备份服务器信息#inception_remote_system_password = 123456#inception_remote_system_user = root#inception_remote_backup_port = 3306#inception_remote_backup_host = 192.168.1.54#inception_support_charset = utf8 EOF 启动Inception1[root@incArcher inception]# Inception --defaults-file=/etc/inc.cnf &amp; 测试Inception12[root@incArcher inception]# mysql -uroot -h127.0.0.1 -P66691@127.0.0.1:(none)&gt;inception get variables; Archer安装Python 3.612 ###]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产环境中 MySQL(v5.7.21) for Linux 下二进制安装配置详解]]></title>
    <url>%2F2018%2F04%2F10%2FMySQL%2FMySQL_Install%2F</url>
    <content type="text"><![CDATA[下载最新 MySQL 二进制安装、PXB备份工具及PT-Tools运维工具123[root@PMM ~]# wget https://www.percona.com/downloads/Percona-Server-LATEST/Percona-Server-5.7.21-20/binary/tarball/Percona-Server-5.7.21-20-Linux.x86_64.ssl101.tar.gz -P /dba/tools[root@PMM ~]# yum install -y https://www.percona.com/downloads/percona-toolkit/3.0.8/binary/redhat/7/x86_64/percona-toolkit-3.0.8-1.el7.x86_64.rpm[root@PMM ~]# yum install -y https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.10/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.10-1.el7.x86_64.rpm 卸载系统自带的 MySQL rpm 安装包1[root@PMM ~]# rpm -qa|grep mysql |xargs rpm -e --nodeps 创建 MySQL 用户、组及安装目录123456789[root@PMM ~]# userdel -r mysql[root@PMM ~]# groupadd -g 621 mysql[root@PMM ~]# useradd -u 620 -g mysql mysql[root@PMM ~]# mkdir -p /data/mysql/&#123;data,log&#125;[root@PMM ~]# mkdir -p /data/mysql/log/&#123;binlog,relaylog,undo,redo&#125;[root@PMM ~]# chown -R mysql:mysql /data/mysql[root@PMM ~]# chmod -R 775 /data/mysql 解压 MySQL 二进制文件，并赋予mysql用户权限123[root@PMM ~]# tar -zxf /dba/tools/Percona-Server-5.7.21-20-Linux.x86_64.ssl101.tar.gz -C /usr/local/[root@PMM ~]# ln -sv /usr/local/Percona-Server-5.7.21-20-Linux.x86_64.ssl101 /usr/local/mysql[root@PMM ~]# chown -R mysql:mysql /usr/local/mysql 设置MySQL 环境变量123[root@PMM ~]# cp -r /usr/local/mysql/support-files/mysql.server /etc/rc.d/init.d/mysqld[root@PMM ~]# echo "export PATH=/usr/local/mysql/bin:\$PATH" &gt;&gt; /etc/profile[root@PMM ~]# source /etc/profile 配置 MySQL 参数文件详细my.cnf配置具体参考篇章MySQL生产环境参数文件配置 https://cai182081.github.io/2017/10/15/MySQL/MySQL_my.conf/ 初始化 MySQL 数据库1[root@PMM ~]# su - mysql -c "mysqld --initialize-insecure --user=mysql" 启动 MySQL 数据库1[root@PMM ~]# su - mysql -c "service mysqld restart" 设置 MySQL 数据库‘root‘@’localhost’用户密码1[root@PMM ~]# su - mysql -c "mysqladmin -u root password mysql" 设置 MySQL 开机自启动12[root@PMM ~]# chkconfig --add mysqld[root@PMM ~]# chkconfig mysqld on]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全面解析 MySQL 数据库性能调优]]></title>
    <url>%2F2018%2F04%2F10%2FMySQL%2FMySQL_Tuning%2F</url>
    <content type="text"><![CDATA[MySQL 数据库调优对于每个公司、DBA或者部分开者来讲都是特别关注的，一旦项目数据库的性能出现问题，导致的项目更容易故障、影响顾客体验，这些对公司来说是致命打击。但是优化并不是一蹴而就，这需要综合考虑项目开发过程中的进度，以及硬件成本。DBA 受限成本、项目进度，我们更多只能在有限的条件下，做最好的优化需求。下面我就MySQL 优化技术由浅深入讨论MySQL 调优： 操作系统及硬件优化CPU优化关闭CPU的numanuma的会导致mysqld产生swap，严重影响性能。因为numa架构的CPU和内存是bind的，如果CPU自己node中的内存不够，就会导致swap的产生，即使此时其它node中有大量的空闲内存，它也不会去使用。这就是numa的一个缺陷。numactl –interleave=all 内存优化内存主要是要防止发生 swap。如果发生 swap 的话，从内存访问直接下降为硬盘访问，随机访问的速度下降10的6次方倍，也就是10万倍。顺序访问下降10倍左右。避免 MySQL 发生 swap 在CentOS 6.4及更新版本的内核中设置vm.swappiness=0，有可能会导致MySQL数据库所在的系统出现内存溢出(OOM)，可将vm.swappiness设置成1vm.swappiness = 1 CentOS 7.x中需要查找到存在vm.swappiness参数的配置文件find /usr/lib/tuned -name ‘*.conf’ -type f -exec grep “vm.swappiness” {} + /usr/lib/tuned/latency-performance/tuned.conf:vm.swappiness=10/usr/lib/tuned/throughput-performance/tuned.conf:vm.swappiness=10/usr/lib/tuned/virtual-guest/tuned.conf:vm.swappiness = 30 设置 /proc/$(pidof -s mysqld)/oom_adj为较小的值(-15,-16或者-17)来尽量避免MySQL由于内存不足而被关闭echo -17 &gt; /proc/$(pidof mysqld)/oom_adj IO优化IO调度算法：mysql服务器一定不要使用默认的CFQ调度算法。如果是SSD，那么应该使用NOOP调度算法，如果是磁盘，就应该使用Deadline调度算法。echo deadline &gt; /sys/block/sda/queue/scheduler这是临时修改，重启失效。永久修改，需要修改文件 /boot/grub/menu.lst 中的elevator=deadline 或者noop：vi /boot/grub/menu.lstkernel /boot/vmlinuz-2.6.18-8.el5 ro root=LABEL=/ elevator=deadline rhgb quiet 文件系统优化1、文件系统的选择：在rhel6.4之前ext4性能比xfs好，因为xfs有lock争用的bug。但是6.4开始，xfs的bug被fix了。测试表明xfs性能比ext4好。2、文件挂载选项：文件挂载时启用noatime,nodiratime，可以在 /etc/fstab 中进行修改。man mount 手册中有相关选项的说明。3、文件挂载选项：barrier/nobarrier(如果有电池保护，可以启用nobarrier选项来提供性能)4、文件挂载选项：data={journal|ordered|writeback}，如果有电池保护，启用 data=writeback可能会提升性能。5、XFS挂载选项：inode64，如果采用的是XFS文件系统，并且一个分区容量大于1T时，需要采用inode64选项挂载，不然可能会错误的报”disk full” 打开文件数的限制，可以使用ulimit -a 查看目录的各位闲置，可以修改open files 上被限制 ulimit -n 8192 永久修改，需要修改文件 /etc/security/limits.conf, 加上 soft nofile hard nofile session required pam_limits.so 网络优化MySQL 参数文件优化open_files_limit作用：该参数用于控制MySQL实例能够同时打开使用的文件句柄数目。原因：当数据库中的表（MyISAM 引擎表在被访问的时候需要消耗文件描述符，InnoDB引擎会自己管理已经打开的表—table_open_cache）打开越来越多后，会消耗分配给每个实例的文件句柄数目，在数据库起初初始化实例的时候设置的open_files_limit，当打开的表数目超过该参数则会导致所有的数据库请求报错误。现象：如果参数设置过小可导致应用报错 back_log作用：MySQL每处理一个连接请求的时候都会对应的创建一个新线程与之对应，那么在主线程创建新线程期间，如果前端应用有大量的短连接请求到达数据库，MySQL 会限制此刻新的连接进入请求队列，由参数back_log控制，如果等待的连接数量超过back_log，则将不会接受新的连接请求，所以如果需要MySQL能够处理大量的短连接，需要提高此参数的大小。现象：如果参数过小可能会导致应用报错 query_cache_size作用：该参数用于控制MySQL query cache的内存大小；原因：如果MySQL开启query cache，再执行每一个query的时候会先锁住query cache，然后判断是否存在query cache中，如果存在直接返回结果，如果不存在，则再进行引擎查询等操作；同时insert、update和delete这样的操作都会将query cahce失效掉，这种失效还包括结构或者索引的任何变化，cache失效的维护代价较高，会给MySQL带来较大的压力，所以当我们的数据库不是那么频繁的更新的时候，query cache是个好东西，但是如果反过来，写入非常频繁，并集中在某几张表上的时候，那么query cache lock的锁机制会造成很频繁的锁冲突，对于这一张表的写和读会互相等待query cache lock解锁，导致select的查询效率下降。现象：数据库中有大量的连接状态为checking query cache for query、Waiting for query cache lock、storing result in query cache；建议：MySQL默认是打开query cache功能的，如果您的实例打开了query cache，当出现上述情况后可以关闭query cache；当然有些情况也可以打开query cache，比如：巧用query cache解决数据库性能问题。 innodb_buffer_pool_size作用：表示缓冲池字节大小，InnoDB缓存表和索引数据的内存区域。原因：这个值设置的越大，在不止一次的访问相同的数据表数据时，消耗的磁盘I/O就越少。不过在实际的测试中，发现无限的增大这个值，带来的性能提升也并不显著，对CPU的压力反而增大，设置合理的值才是最优。MySQL 5.7.5版本后，innodb_buffer_pool_size 参数的值可以动态的设置，这意味着你可以在不启动服务器的情况下，重新设置缓冲区的大小。这种调整的操作是按块执行的。建议：在一个专用的数据库服务器，则可能将其设置为高达70%-80%的机器物理内存大小。 innodb_log_buffer_size作用：表示InnoDB写入到磁盘上的日志文件时使用的缓冲区的字节数。原因：一个大的日志缓冲区允许大量的事务在提交之前不写日志到磁盘。因此，如果你有很多事务的更新，插入或删除很操作，通过这个参数会大量的节省了磁盘 I/O。建议： innodb_log_file_size作用：表示在一个日志组每个日志文件的字节大小。原因：该值越大，缓冲池中必要的检查点刷新活动就会越少，节省磁盘 I/O。但是越大的日志文件，MySQL 的崩溃恢复就越慢，尽管在 MySQL 5.5之后改进了恢复性能和日志文件恢复的代价。建议：比较合适的值的范围是从1MB到 1/N 个的缓冲池大小，其中N是该组中的日志文件的数量。 innodb_max_dirty_pages_pct作用：控制Innodb的脏页在缓冲中在那个百分比之下，值在范围1-100，默认为90。原因：当Innodb的内存分配过大，致使 Swap 占用严重时，可以适当的减小调整这个值，使达到 Swap 空间释放出来。建义：这个值最大在90%，最小在15%。太大，缓存中每次更新需要致换数据页太多，太小，放的数据页太小，更新操作太慢。 thread_cache_size作用：线程池，线程缓存原因：这个值表示可以重新利用保存在缓存中线程的数量，当断开连接时如果缓存中还有空间,那么客户端的线程将被放到缓存中,如果线程重新被请求，那么请求将从缓存中读取，如果缓存中是空的或者是新的请求，那么这个线程将被重新创建，如果有很多新的线程，增加这个值可以改善系统性能。每建立一个连接，都需要一个线程来与之匹配，此参数用来缓存空闲的线程，以至不被销毁，如果线程缓存中有空闲线程，这时候如果建立新连接，MYSQL就会很快的响应连接请求。建议：1G ―&gt; 8、2G ―&gt; 16、3G ―&gt; 32、大于3G ―&gt; 64 innodb_io_capacityinnodb_io_capacity_max作用：innodb_io_capacity：InnoDB 用来当刷新脏数据时，控制MySQL每秒执行的写IO量; innodb_io_capacity_max: 在压力下，控制当刷新脏数据时MySQL每秒执行的写IO量。原因：建议： max_connections作用：MySQL的最大连接数，增加mysqld 要求的文件描述符的数量。原因：MySQL的最大连接数，如果服务器的并发连接请求量比较大，建议调高此值。连接数越多占用内存越多现象：数值过小会经常出现ERROR 1040: Too many connections错误 innodb_flush_log_at_trx_commit 作用：InnoDB 将 redo buffer 中的更新记录写入到日志文件以及将日志文件数据刷新到磁盘的操作频率。原因： 0：在事务提交时，InnoDB 不会立即触发将缓存日志写到磁盘文件的操作，而是每秒触发一次缓存日志回写磁盘操作，并调用系统函数 fsync 刷新 IO 缓存。这种方式效率最高，也最不安全。 1：在每个事务提交时，InnoDB 立即将缓存中的 redo 日志回写到日志文件，并调用 fsync 刷新 IO 缓存。 2：在每个事务提交时，InnoDB 立即将缓存中的 redo 日志回写到日志文件，但并不马上调用 fsync 来刷新 IO 缓存，而是每秒只做一次磁盘IO 缓存刷新操作。只要操作系统不发生崩溃，数据就不会丢失，这种方式是对性能和数据安全的折中，其性能和数据安全性介于其他两种方式之间。建议：innodb_flush_log_at_trx_commit 参数的默认值是 1，即每个事务提交时都会从 log buffer 写更新记录到日志文件，而且会实际刷新磁盘缓存，显然，这完全能满足事务的持久化要求，是最安全的，但这样会有较大的性能损失。 sync_binlog作用：MySQL的二进制日志（binary log）同步刷新到磁盘的频率。原因：当sync_binlog = 0，二进制日志从不进行二进制日志同步到磁盘上，而是根据操作系统刷其他文件的机制来刷新二进制日志到磁盘。 query_cache_size查询缓存，对于查询的性能提高有很大帮助，但不宜开得过大，查询缓存的过期可能很频繁，过大查询缓存反而降低性能，增加服务器开销 更多MySQL 参数优化请参考 索引优化尽量避免在索引过的字符数据中，使用非打头字母搜索。这也使得引擎无法利用索引 更多MySQL 索引优化请参考 https://cai182081.github.io/2018/04/03/SQL/DB_INDEX_1/ SQL优化影响结果集是SQL优化的核心。影响结果集不是查询返回的记录数，而是查询所扫描的结果数。通过Explain或Desc分析SQL，rows列的值即为影响结果集（还可以通过慢查询日志的Rows_examined后面的数字得到）。 避免 select ，减少输出的数据量，提高传输速度避免 in/exsits 子查询，尽可能 join 替换避免对索引字段进行计算操作避免在索引字段上使用函数避免建立索引的列中使用空值避免使用 or， 尽可能使用 union all 或者 union 代替避免在索引字段上使用not，&lt;&gt;，!=避免在索引列上使用IS NULL和IS NOT NULL避免在索引列和连接列上出现数据类型/字符集的转换避免 union，在可以允许数据重复的条件下使用union all代替避免查询的无前缀模糊匹配 like ‘%**‘避免not in，尽可能使用not exists和left join代替合理分页合理使用索引和复合索引，建立更高效的复合索引替换单列索引 更多MySQL 参数优化请参考 SQL 调优技巧篇章 https://cai182081.github.io/2018/04/10/SQL/DB_SQL_1/#more 表结构设计优化数据类型优化：12345678910111213141516171819202122232425261、字节占用小。 使用最小的数据类型。——更少的磁盘空间，内存和CPU缓存。而且需要的CPU的周期也更少。使用正确合适的类型，不要将数字存储为字符串。 尽可能地使用最有效(最小)的数据类型。MySQL有很多节省磁盘空间和内存的专业化类型。 尽可能使用较小的整数类型使表更小。例如，MEDIUMINT经常比INT好一些，因为MEDIUMINT列使用的空间要少25%。 如果可能，声明列为NOT NULL。它使任何事情更快而且每列可以节省一位。注意如果在应用程序中确实需要NULL，应该毫无疑问使用它，只是避免 默认地在所有列上有它。2、简单就好。 整数代价小于字符。——因为字符集和排序规则使字符比较更复杂。 1&gt;mysql内建类型（如timestamp,date)优于使用字符串保存。 2&gt;使用整数保存ip地址。 3、避免字段为 NUL L类型——如果计划对列进行索引，尽量避免把列设置为NULL。尽可能把字段定义为NOT NULL。——可以放置一个默认值，如‘’，0，特殊字符串。 原因： 1、MYSQL难以优化NULL列。NULL列会使索引，索引统计和值更加复杂。 2、NULL列需要更多的存储空间，还需要在MYSQL内部进行特殊处理。 3、NULL列加索引，每条记录都需要一个额外的字节，还导致MyISAM中固定大小的索引变成可变大小的索引。 4、如果是一个组合索引，那么这个NULL 类型的字段会极大影响整个索引的效率。 5、NULL 在索引中的处理也是特殊的，也会占用额外的存放空间。4、区分开 TINYINT / INT / BIGINT 的选择，因为三者所占用的存储空间也有很大的差别，能确定不会使用负数的字段，建议添加unsigned定义，当然，如果数据量较小的数据库，也可以不用严格区分三个整数类型。5、非万不得已不要使用 TEXT、BLOB 数据类型，其处理方式决定了他的性能要低于char或者是varchar类型的处理6、定长字段，建议使用 CHAR 类型，不定长字段尽量使用 VARCHAR，且仅仅设定适当的最大长度，而不是非常随意的给一个很大的最大长度限定，因为不同的长度范围，MySQL也会有不一样的存储处理。7、间类型：尽量使用TIMESTAMP类型，因为其存储空间只需要 DATETIME 类型的一半。对于只需要精确到某一天的数据类型，建议使用DATE类型，因为他的存储空间只需要3个字节，比TIMESTAMP还少。8、数字类型：非万不得已不要使用DOUBLE，不仅仅只是存储长度的问题，同时还会存在精确性的问题。同样，固定精度的小数，也不建议使用DECIMAL，建议乘以固定倍数转换成整数存储，可以大大节省存储空间，且不会带来任何附加维护成本。 聚集索引字段类型优化主键的索引结构中，即存储了主键值，又存储了行数据，这种结构称为“聚集索引”。在插入数据时，数据节点会分裂，这个问题比较严重，节点下存储了“行数据”，分裂的时候，还要移动行数据。如果主键是无规律的，则会加速它的数据节点分裂，且效率极低。主键，尽量用整型，而且是递增的整型。如果是无规律的数据，将会产生页的分裂，影响速度。索引长度直接影响索引文件大小，影响增删改的速度，并间接影响查询速度（占用内存多）。因为主键索引在物理存放时是有序的，如果主键的值是无序的，那么主键每次插入时，索引文件都重新进行排序，会产生额外的数据消耗，另外主键的叶子上存放的数据，还会导致叶子数据行的移动和分裂，又会产生一些消耗，所以主键尽量用整型，且自增的类型。 存储引擎优化使用InnoDB引擎 缓存优化读写分离优化MySQL 读写分离基本原理是让 Master 数据库处理写操作，Slave 数据库处理读操作。Master 将写操作的变更同步到各个 Slave 节点。MySQL 读写分离基本原理是让 Master 数据库处理事务性读写操作，而 Slave 数据库处理非事物只读 SELECT 查询。利用 MySQL 数据库复制技术把 Master 节点上事务性操作实时同步到 Slave 节点。降低单台服务器的IO、CPU资源压力。 MySQL读写分离能提高系统性能的原因在于：物理服务器增加，机器处理能力提升。拿硬件换性能。Master-Slave 只负责各自的读和写操作，极大程度缓解X锁和S锁争用。通过多个 Slave 分摊读取。虽然总个集群的 SELECT 操作并没有减少，但降低了单台服务器的IO、CPU和带宽压力。另外，当读取被分摊后，又间接提高了 Master 写入的性能Slave 可以配置 MyISAM 引擎，提升查询性能以及节约系统开销。Master 直接写是并发的，Slave 通过主库发送来的 binlog 恢复数据是异步。Slave 可以单独设置一些参数来提升其读的性能。增加冗余，提高可用性。 分库分表优化数据库中的数据量不一定是可控的，在未进行分库分表的情况下，随着时间和业务的发展，库中的表会越来越多，表中的数据量也会越来越大，相应地，数据操作，增删改查的开销也会越来越大；另外，由于无法进行分布式式部署，而一台服务器的资源（CPU、磁盘、内存、IO等）是有限的，最终数据库所能承载的数据量、数据处理能力都将遭遇性能瓶颈。 说白了，就是分担写负载 数据的垂直切分数据的垂直切分，也可以称之为纵向切分。将数据库想象成为由很多个一大块一大块的“数据块”（表）组成，我们垂直的将这些“数据块”切开，然后将他们分散到多台数据库主机上面。这样的切分方法就是一个垂直（纵向）的数据切分。垂直切分的优点数据库的拆分简单明了，拆分规则明确；应用程序模块清晰明确，整合容易；数据维护方便易行，容易定位； 垂直切分的缺点部分表关联无法在数据库级别完成，需要在程序中完成；对于访问极其频繁且数据量超大的表仍然存在性能平静，不一定能满足要求；事务处理相对更为复杂；切分达到一定程度之后，扩展性会遇到限制；过读切分可能会带来系统过渡复杂而难以维护。 数据的水平切分数据的垂直切分基本上可以简单的理解为按照表按模块来切分数据，而水平切分就不再是按照表或者是功能模块来切分了。一般来说，简单的水平切分主要是将某个访问极其平凡的表再按照某个字段的某种规则来分散到多个表之中，每个表中包含一部分数据。 水平切分的优点表关联基本能够在数据库端全部完成；不会存在某些超大型数据量和高负载的表遇到瓶颈的问题；应用程序端整体架构改动相对较少；事务处理相对简单；只要切分规则能够定义好，基本上较难遇到扩展性限制； 水平切分的缺点切分规则相对更为复杂，很难抽象出一个能够满足整个数据库的切分规则；后期数据的维护难度有所增加，人为手工定位数据更困难；应用系统各模块耦合度较高，可能会对后面数据的迁移拆分造成一定的困难。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL 优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 调优技巧]]></title>
    <url>%2F2018%2F04%2F10%2FSQL%2FDB_SQL_1%2F</url>
    <content type="text"><![CDATA[减少访问数据库的次数去掉不必要的查询和数据检索。其实在项目的实际应用中，很多查询条件是可有可无的，从源头上避免 减少访问的数据量控制高并发业务尽可能通过时间字段对数据冷热隔离，高并发下只针对热数据经行增删改查。冷数据及时归档和隔离，经Hadoop/Spark大数据、ETL、BI等技术对数据处理后，再插入数据库进行展示 尽量避免 SELECT *消除对数据库字典的解析，减少输出的数据量，降低网络流量的耗损，提高传输速度。必要时，可以通过覆盖索引优化 禁止在SQL中对列进行数学运算123低效：SELECT e.ename FROM emp e WHERE e.sal*1.1 &gt; 900;高效：SELECT e.ename FROM emp e WHERE e.sal &gt; 900/1.1; 禁止SQL对列进行函数运算12345678低效：SELECT e.ename FROM emp e WHERE DATE_FORMAT(e.date, ’%Y%m%d’) = '20160516';高效：SELECT e.ename FROM emp e WHERE e.date &gt; = '2016-05-16 00:00:01' AND e.date &lt; '2016-05-17 00:00:00'; 禁止使用反向查询，使用&gt;、&lt;等，避免使用!=和&lt;&gt;命令123低效：select * from emp e where e.salary != 3000;高效：select * from emp e where e.salary &lt; 3000 or e.salary &gt; 3000; 用 &gt;= 替代 &gt;123低效：SELECT loc_id, loc_desc, region FROM location WHERE loc_id &gt; 10 AND loc_desc &gt; 10;高效：SELECT loc_id, loc_desc, region FROM location WHERE loc_id &gt;= 11 AND loc_desc &gt;= 11; 使用 IN 代替 OR，SQL语句中 IN 包含的值不宜过多123低效：SELECT * FROM location WHERE loc_id = 10 OR loc_id = 20 OR loc_id = 30;高效：SELECT * FROM location WHERE loc_id IN (10,20,30); 禁止模糊匹配%前导查询123低效：SELECT e.ename FROM emp e WHERE e.ename LIKE '%abc';高效：SELECT e.ename FROM emp e WHERE e.ename LIKE 'abc%'; 使用 UNION 替换 OR(适用于索引列)1234567891011低效：SELECT loc_id, loc_desc, region FROM location WHERE loc_id = 10 OR region = 'MELBOURNE';高效：SELECT loc_id, loc_desc, region FROM location WHERE loc_id = 10 UNION SELECT loc_id, loc_desc, region FROM location WHERE region = 'MELBOURNE'; 在明显不会存在重复值的查询时，使用 UNION ALL 代替 UNION，避免排序123456789101112131415低效：SELECT ACCT_NUM, BALANCE_AMT FROM DEBIT_TRANSACTIONS WHERE TRAN_DATE = '31 - DEC - 95' UNION SELECT ACCT_NUM, BALANCE_AMT FROM DEBIT_TRANSACTIONS WHERE TRAN_DATE = '31 - DEC - 95';高效：SELECT ACCT_NUM, BALANCE_AMT FROM DEBIT_TRANSACTIONS WHERE TRAN_DATE = '31 - DEC - 95' UNION ALL SELECT ACCT_NUM, BALANCE_AMT FROM DEBIT_TRANSACTIONS WHERE TRAN_DATE = '31 - DEC - 95'; 避免在索引列上进行NULL值的判断123低效: SELECT … FROM department WHERE DEPT_CODE IS NOT NULL;高效: SELECT … FROM department WHERE DEPT_CODE &gt;= 0; 避免 HAVING，用 WHERE 子句替换 HAVING 子句123低效：SELECT job, AVG(sal) FROM emp GROUP BY job HAVING job = 'PRESIDENT' OR job = 'MANAGER';高效：SELECT job, AVG(sal) FROM emp WHERE job = 'PRESIDENT' OR job = 'MANAGER' GROUP BY job; 用 EXISTS 替换 DISTINCT123456低效: SELECT DISTINCT DEPT_NO,DEPT_NAME FROM DEPT D , EMP E WHERE D.DEPT_NO = E.DEPT_NO;高效: SELECT DEPT_NO,DEPT_NAME FROM DEPT D WHERE EXISTS ( SELECT ‘X’ FROM EMP E WHERE E.DEPT_NO = D.DEPT_NO); 合理的分页方式以提高分页效率123低效：SELECT e.ename FROM emp e limit 10000,10;高效：SELECT e.ename FROM emp e WHERE e.id &gt;=10000 limit 10; 禁止order by rand()查询123456789低效：SELECT * FROM emp ORDER BY RAND() LIMIT 1;高效：SELECT * FROM emp AS t1 JOIN (SELECT ROUND(RAND() * ((SELECT MAX(id) FROM EMP) - (SELECT MIN(id) FROM EMP)) + (SELECT MIN(id) FROM emp)) AS id) AS t2 WHERE t1.id &gt;= t2.id ORDER BY t1.id LIMIT 1; 避免使用 in/exists 子查询，用join替换in 是把外表和内表作 hash 连接，而 exists 是对外表作 loop 循环，每次 loop 循环再对内表进行查询，认为 exists 比 in 效率高的说法是不准确的。如果查询的两个表的数据量大小相当，那么用 in 和 exists 子查询效率差别不大；如果两个表中一个较小一个较大，则子查询表大的用 exists 更为效率，子查询表小的用 in 更效率，但对于 join 来说，根据代价来确定表的连接顺序，执行效率总是最高。123456emp 数据量小于 department ：低效：SELECT * FROM emp e WHERE e.name IN (SELECT d.name FROM department d)低效：SELECT * FROM department d WHERE EXISTS (SELECT 1 FROM emp e WHERE e.name = d.name)高效：SELECT * FROM emp e INNER JOIN department d ON e.name = d.name 避免使用 not in 子查询，使用 not exists 或 left join替换查询语句使用了not in，那么对内外表都进行全表扫描，没有用到索引；而 not exists 的子查询依然能用到表上的索引。所以无论哪个表大，用not exists都比not in 要快。注意:NOT EXISTS 与 NOT IN 不能完全互相替换，看具体的需求。如果选择的列可以为空，则不能被替换。12345低效：SELECT * FROM emp e WHERE e.name NOT IN (SELECT d.name FROM department d)高效：SELECT * FROM emp e WHERE NOT EXISTS (SELECT 1 FROM department d WHERE d.name = e.name)高效：SELECT * FROM emp e LEFT JOIN department d ON e.name = d.name WHERE d.name IS NULL; 子查询展开优化123低效：SELECT * FROM t1, (SELECT * FROM t2 WHERE t2.a2 &gt; 10) v_t2 WHERE t1.a1 &lt; 10 AND v_t2.a2 &lt; 20;高效：SELECT * FROM t1, t2 WHERE t2.a2 &gt; 10 AND t1.a1 &lt; 10 AND t2.a2 &lt; 20; 子查询合并优化123456789低效：SELECT * FROM t1 WHERE a1 &lt; 10 AND (EXISTS (SELECT a2 FROM t2 WHERE t2.a2 &lt; 5 AND t2.b2 = 1) OR EXISTS (SELECT a2 FROM t2 WHERE t2.a2 &lt; AND t2.b2 = 2));高效：SELECT * FROM t1 WHERE t2.a2 &lt; 5 AND (t2.b2 = 1 OR t2.b2 = 2); 避免隐式转换1234567891011121314151、varchar与int类型转换低效：SELECT * FROM emp e WHERE e.name = 123;高效：SELECT * FROM emp e WHERE e.name = '123';2、datetime与varchar类型转换低效：SELECT * FROM emp e WHERE e.date LIKE CONCAT('2018-04-10','%');高效：SELECT * FROM emp e WHERE e.date BETWEEN '2018-04-10 00:00:00' AND '2018-04-10 23:59:59';3、varchar与varbinary类型转换4、不通字符集间的隐式转换5、同字符集，不同字符集顺序间的隐式转换]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 3.1.0 完全分布式集群搭建（生产环境下）]]></title>
    <url>%2F2018%2F04%2F06%2FHadoop%2FHadoop_Cluster%2F</url>
    <content type="text"><![CDATA[Hadoop 集群服务器及节点规划12 服务器操作系统设置服务器主机名及hosts文件配置1234567891011# all[root@node1 ~]# echo node$ &gt; /etc/hostname[root@node1 ~]# cat &gt;&gt; /etc/hosts &lt;&lt;EOF192.168.1.10 node1192.168.1.11 node2192.168.1.12 node3192.168.1.13 node4EOF[root@node1 ~]# for a in &#123;2..4&#125;; do scp /etc/hosts root@node$a:/etc ; done 关闭操作系统防火墙123456[root@node1 ~]# systemctl stop firewalld.service[root@node1 ~]# systemctl disable firewalld.service[root@node1 ~]# firewall-cmd --state[root@node1 ~]# setenforce 0[root@node1 ~]# sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config 创建Hadoop目录及环境变量123[root@node1 ~]# groupadd hadoop[root@node1 ~]# useradd hadoop -g hadoop[root@node1 ~]# passwd hadoop 创建Hadoop集群用户组和用户、设置密码1234567[root@node1 ~]# mkdir -pv /data/hadoop/hdfs/&#123;name,data,check&#125;[root@node1 ~]# mkdir -pv /data/hadoop/zookeeper/&#123;data,logs&#125;[root@node1 ~]# chown -R hadoop:hadoop /data/hadoop[root@node1 ~]# chmod -R 775 /data/hadoop[root@node1 ~]# mkdir -pv /var/log/hadoop/yarn[root@node1 ~]# chown -R hadoop:hadoop /var/log/hadoop/yarn 配置hadoop用户 sudo root免密123[root@node1 ~]# chmod u+w /etc/sudoers[root@node1 ~]# sed -i '/Allow root to run any/a\hadoop ALL=(ALL) NOPASSWD: ALL' /etc/sudoers[root@node1 ~]# chmod u-w /etc/sudoers 服务器Hadoop用户SSH免密认证123456789101112131415161718[hadoop@node1 ~]$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa[hadoop@node2 ~]$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa[hadoop@node3 ~]$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa[hadoop@node4 ~]$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa[hadoop@node1 ~]$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys[hadoop@node2 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node1[hadoop@node3 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node1[hadoop@node4 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node1[hadoop@node1 ~]$ chmod 600 ~/.ssh/authorized_keys[hadoop@node1 ~]$ for a in &#123;2..4&#125;; do scp ~/.ssh/authorized_keys hadoop@node$a:~/.ssh/ ; done[hadoop@node1 ~]$ ssh hadoop@node1[hadoop@node1 ~]$ ssh hadoop@node2[hadoop@node1 ~]$ ssh hadoop@node3[hadoop@node1 ~]$ ssh hadoop@node4 Hadoop集群搭建安装JDK及配置JAVA环境变量JDK 下载地址：http://download.oracle.com/otn-pub/java/jdk/8u161-b12/2f38c3b165be4555a1fa6e98c45e0808/jdk-8u161-linux-x64.tar.gz?AuthParam=1523783670_c89245f1738f3a64a4367b3e62873c0f123[root@node1 ~]# rpm -qa | grep java | xargs rpm -e --nodeps[root@node1 ~]# tar -zxf /dba/tools/jdk-8u161-linux-x64.tar.gz -C /usr/local/[root@node1 ~]# ln -sv /usr/local/jdk1.8.0_161 /usr/local/jdk 下载 ZooKeeper，并解压配置 ZooKeeper 下载地址：http://mirror.bit.edu.cn/apache/zookeeper/stable/zookeeper-3.4.10.tar.gz12345[root@node1 tools]# export ZOO_VERSION=zookeeper-3.4.10[root@node1 tools]# tar -zxf /dba/tools/$ZOO_VERSION.tar.gz -C /usr/local/[root@node1 tools]# ln -sv /usr/local/$ZOO_VERSION /usr/local/zookeeper[root@node1 tools]# chown -R hadoop:hadoop /usr/local/$ZOO_VERSION[root@node1 tools]# chown -R hadoop:hadoop /usr/local/zookeeper 下载Hadoop，并解压hadoopHadoop 下载地址：http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-3.1.0/hadoop-3.1.0.tar.gz12345[root@node1 ~]# export HADOOP_VERSION=hadoop-3.1.0[root@node1 ~]# tar -zxf /dba/tools/$HADOOP_VERSION.tar.gz -C /usr/local/[root@node1 ~]# ln -sv /usr/local/$HADOOP_VERSION /usr/local/hadoop[root@node1 ~]# chown -R hadoop:hadoop /usr/local/$HADOOP_VERSION[root@node1 ~]# chown -R hadoop:hadoop /usr/local/hadoop 配置Zookeeper、Hadoop 集群环境变量123456789101112131415161718192021222324252627[root@node1 ~]# cat &gt;&gt; /etc/profile &lt;&lt;EOF# JDKexport JAVA_HOME=/usr/local/jdkexport JRE_HOME=\$JAVA_HOME/jreexport JAVA_LIBRARY_PATH=\$HADOOP_HOME/lib/native export CLASSPATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jarexport PATH=\$PATH:\$JAVA_HOME/bin:\$JRE_HOME/bin# Zookeeperexport ZOO_HOME=/usr/local/zookeeper export ZOO_LOG_DIR=/data/hadoop/zookeeper/logsexport PATH=\$PATH:\$ZOO_HOME/bin# Hadoopexport HADOOP_HOME=/usr/local/hadoopexport HADOOP_PID_DIR=\$HADOOP_HOME/pids export HADOOP_COMMON_LIB_NATIVE_DIR=\$HADOOP_HOME/lib/native export HADOOP_OPTS="\$HADOOP_OPTS-Djava.library.path=\$HADOOP_HOME/lib:\$HADOOP_HOME/lib/native" export HADOOP_MAPRED_HOME=\$HADOOP_HOME export HADOOP_COMMON_HOME=\$HADOOP_HOME export HADOOP_HDFS_HOME=\$HADOOP_HOME export HADOOP_YARN_HOME=\$HADOOP_HOME export HADOOP_CONF_DIR=\$HADOOP_HOME/etc/hadoop export HADOOP_ROOT_LOGGER=INFO,console export PATH=\$PATH:\$HADOOP_HOME/bin:\$HADOOP_HOME/sbinEOF[root@node1 ~]# source ~/.bash_profile 配置 ZooKeeper 参数文件12345678910111213141516[hadoop@node1 ~]$ cat &gt;&gt; /usr/local/zookeeper/conf/zoo.cfg &lt;&lt;EOFtickTime=2000initLimit=10syncLimit=5 dataDir=/data/hadoop/zookeeper/dataclientPort=2181server.1=node1:2888:3888server.2=node2:2888:3888server.3=node3:2888:3888EOF[hadoop@node1 ~]$ echo 1 &gt; /data/hadoop/zookeeper/data/myid[hadoop@node2 ~]$ echo 2 &gt; /data/hadoop/zookeeper/data/myid[hadoop@node3 ~]$ echo 3 &gt; /data/hadoop/zookeeper/data/myid 配置Hadoop集群基本配置文件配置hadoop-env.sh1[hadoop@node1 ~]$ sed -i '/# export JAVA_HOME=/a\export JAVA_HOME=/usr/local/jdk' /usr/local/hadoop/etc/hadoop/hadoop-env.sh 配置works1234567[hadoop@node1 ~]$ cat /dev/null &gt; /usr/local/hadoop/etc/hadoop/workers[hadoop@node1 ~]$ cat &gt;&gt; /usr/local/hadoop/etc/hadoop/workers &lt;&lt;EOFnode1node2node3node4EOF 配置core-site.xml1234567891011121314151617181920212223242526272829303132333435363738[hadoop@node1 ~]$ vi /usr/local/hadoop/etc/hadoop/core-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://node1:9000&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131584&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hadoop.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hadoop.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.native.lib&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node1:2181,node2:2181,node3:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.session-timeout.ms&lt;/name&gt; &lt;value&gt;2000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hdfs-site.xml123456789101112131415161718192021222324252627282930313233343536[hadoop@node1 ~]$ vi /usr/local/hadoop/etc/hadoop/hdfs-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node2:9001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///data/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///data/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.checkpoint.dir&lt;/name&gt; &lt;value&gt;file:///data/hadoop/hdfs/check&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.checkpoint.edits.dir&lt;/name&gt; &lt;value&gt;file:///data/hadoop/hdfs/check&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置mapred-site.xml12345678910111213141516[hadoop@node1 ~]$ vi /usr/local/hadoop/etc/hadoop/mapred-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;node1:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;node1:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置yarn-site.xml123456789101112131415161718192021222324252627282930313233343536373839[hadoop@node1 ~]$ vi /usr/local/hadoop/etc/hadoop/yarn-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;node1:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;node1:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;node1:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;node1:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;node1:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.auxservices.mapreduce_shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 创建ZooKeeper、Hadoop目录，并同步Hadoop、ZooKeeper安装文件1234567891011[hadoop@node2 ~]$ sudo mkdir -p /usr/local/&#123;hadoop,zookeeper&#125;[hadoop@node2 ~]$ sudo chown -R hadoop:hadoop /usr/local/&#123;hadoop,zookeeper&#125;[hadoop@node3 ~]$ sudo mkdir -p /usr/local/&#123;hadoop,zookeeper&#125;[hadoop@node3 ~]$ sudo chown -R hadoop:hadoop /usr/local/&#123;hadoop,zookeeper&#125;[hadoop@node2 ~]$ sudo mkdir -p /usr/local/&#123;hadoop,zookeeper&#125;[hadoop@node2 ~]$ sudo chown -R hadoop:hadoop /usr/local/&#123;hadoop,zookeeper&#125;[hadoop@node1 ~]$ for a in &#123;2..4&#125;; do scp -r /usr/local/hadoop/* hadoop@node$a:/usr/local/hadoop/ ; done[hadoop@node1 ~]$ for a in &#123;2..3&#125;; do scp -r /usr/local/zookeeper/* hadoop@node$a:/usr/local/zookeeper/ ; done 初始化Hdfs1[hadoop@node1 ~]$ hdfs namenode -format 启动ZooKeeper，并查看Zookeeper启动状态查看状态，如果发现每个node当前状态标记为follower或者leader，那么测试通过12345678[hadoop@node1 ~]$ zkServer.sh start[hadoop@node1 ~]$ zkServer.sh status[hadoop@node1 ~]$ zkServer.sh start[hadoop@node1 ~]$ zkServer.sh status[hadoop@node1 ~]$ zkServer.sh start[hadoop@node1 ~]$ zkServer.sh status 启动Hadoop集群，并检查进程123[hadoop@node1 ~]$ start-dfs.sh[hadoop@node1 ~]$ start-yarn.sh[hadoop@node1 ~]$ jps 进入Hadoop 集群Web控制台http://192.168.1.10:8088/ #NameNode图形界面, 任务分配和任务进度信息的查询http://192.168.1.10:9870/ #集群结点(Node Of Cluster)图形界面 Yarn可用测试1234567[hadoop@node1 ~]$ hdfs dfs -mkdir /user[hadoop@node1 ~]$ hdfs dfs -mkdir /user/hadoop[hadoop@node1 ~]$ hdfs dfs -mkdir input[hadoop@node1 ~]$ hdfs dfs -put /usr/local/hadoop/etc/hadoop/*.xml input[hadoop@node1 ~]$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar grep input output 'dfs[a-z.]+'[hadoop@node1 ~]$ hdfs dfs -get output output[hadoop@node1 ~]$ cat output/*]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 常用SQL诊断脚本]]></title>
    <url>%2F2018%2F04%2F04%2FSQL%2FMySQL_SQL_2%2F</url>
    <content type="text"><![CDATA[查看MySQL数据库中无显示主键的表12345678910SELECT t.TABLE_SCHEMA, t.TABLE_NAME FROM information_schema.TABLES t LEFT JOIN information_schema.TABLE_CONSTRAINTS tc ON tc.TABLE_SCHEMA = t.TABLE_SCHEMA AND tc.TABLE_NAME = t.TABLE_NAME AND tc.CONSTRAINT_TYPE = 'PRIMARY KEY' WHERE t.TABLE_TYPE = 'BASE TABLE' AND tc.CONSTRAINT_TYPE IS NULL AND t.TABLE_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test'); 查看MySQL数据库中没有被使用的索引12345678SELECT OBJECT_SCHEMA, OBJECT_NAME, INDEX_NAME FROM performance_schema.TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE WHERE INDEX_NAME IS NOT NULL AND INDEX_NAME != 'PRIMARY' AND COUNT_FETCH = 0 AND COUNT_READ = 0 AND OBJECT_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test') ORDER BY OBJECT_SCHEMA, OBJECT_NAME; 查看MySQL数据库中存在外键约束的表1234567891011121314151617SELECT c.TABLE_SCHEMA, c.REFERENCED_TABLE_NAME, c.REFERENCED_COLUMN_NAME, c.TABLE_NAME, c.COLUMN_NAME, c.CONSTRAINT_NAME, t.TABLE_COMMENT, r.UPDATE_RULE, r.DELETE_RULE FROM information_schema.KEY_COLUMN_USAGE c JOIN information_schema.TABLES t ON t.TABLE_NAME = c.TABLE_NAME JOIN information_schema.REFERENTIAL_CONSTRAINTS r ON r.TABLE_NAME = c.TABLE_NAME AND r.CONSTRAINT_NAME = c.CONSTRAINT_NAME AND r.REFERENCED_TABLE_NAME = c.REFERENCED_TABLE_NAME WHERE c.REFERENCED_TABLE_NAME IS NOT NULL; 查看MySQL数据库中引擎不是InnoDB的表12345SELECT CONCAT('ALTER TABLE ', TABLE_SCHEMA, '.', TABLE_NAME, ' ENGINE = InnoDB;') FROM information_schema.TABLES WHERE TABLE_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test') AND ENGINE != 'InnoDB'; 查看MySQL数据库中主键是复合主键的表123456789SELECT TABLE_SCHEMA, TABLE_NAME, GROUP_CONCAT(COLUMN_NAME ORDER BY SEQ_IN_INDEX SEPARATOR ',') cols, MAX(SEQ_IN_INDEX) len FROM information_schema.STATISTICS WHERE INDEX_NAME = 'PRIMARY' AND TABLE_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test') GROUP BY TABLE_SCHEMA, TABLE_NAMEHAVING len &gt; 1; 查找MySQL数据库中重复索引前缀的索引1234567891011121314151617SELECT a.TABLE_SCHEMA, a.TABLE_NAME, a.INDEX_NAME, a.cols, b.INDEX_NAME, b.cols FROM (SELECT TABLE_SCHEMA, TABLE_NAME, INDEX_NAME, CONCAT('| ', GROUP_CONCAT(COLUMN_NAME ORDER BY SEQ_IN_INDEX SEPARATOR ' | '), ' |') AS cols FROM information_schema.STATISTICS WHERE TABLE_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test') AND INDEX_NAME != 'PRIMARY' GROUP BY TABLE_SCHEMA, TABLE_NAME, INDEX_NAME) a INNER JOIN (SELECT TABLE_SCHEMA, TABLE_NAME, INDEX_NAME, CONCAT('| ', GROUP_CONCAT(COLUMN_NAME ORDER BY SEQ_IN_INDEX SEPARATOR ' | '), ' |') AS cols FROM information_schema.STATISTICS WHERE TABLE_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test') AND INDEX_NAME != 'PRIMARY' GROUP BY TABLE_SCHEMA, TABLE_NAME, INDEX_NAME) b ON a.TABLE_NAME = b.TABLE_NAME AND a.TABLE_SCHEMA = b.TABLE_SCHEMA AND a.cols LIKE CONCAT(b.cols, '%') AND a.INDEX_NAME != b.INDEX_NAME; 查找MySQL数据库中低区分度索引（区分度小于0.1）12345678910111213141516SELECT p.TABLE_SCHEMA, p.TABLE_NAME, c.INDEX_NAME, c.car, p.car total FROM (SELECT TABLE_SCHEMA, TABLE_NAME, INDEX_NAME, MAX(CARDINALITY) car FROM information_schema.STATISTICS WHERE INDEX_NAME != 'PRIMARY' AND TABLE_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test') GROUP BY TABLE_SCHEMA, TABLE_NAME, INDEX_NAME) c INNER JOIN (SELECT TABLE_SCHEMA, TABLE_NAME, MAX(CARDINALITY) car from information_schema.STATISTICS WHERE INDEX_NAME = 'PRIMARY' AND TABLE_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test') GROUP BY TABLE_SCHEMA, TABLE_NAME) p ON c.TABLE_NAME = p.TABLE_NAME AND c.TABLE_SCHEMA = p.TABLE_SCHEMA WHERE p.car &gt; 0 AND c.car / p.car &lt; 0.1 ORDER BY c.car / p.car; 查找MySQL数据库主键不为自增主键的表1234567891011SELECT TABLE_SCHEMA, TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test') AND (TABLE_SCHEMA,TABLE_NAME) NOT IN (SELECT TABLE_SCHEMA, TABLE_NAME FROM information_schema.COLUMNS WHERE TABLE_SCHEMA NOT IN ('sys', 'mysql', 'performance_schema', 'information_schema', 'test') AND IS_NULLABLE = 'NO' AND COLUMN_TYPE LIKE '%int%' AND COLUMN_KEY = 'PRI' AND EXTRA = 'auto_increment'); 查看数据库中的锁请求1234567891011121314151617181920212223242526SELECT r.TRX_ISOLATION_LEVEL, r.TRX_ID WAITING_TRX_ID, r.TRX_MYSQL_THREAD_ID WAITING_TRX_THREAD, r.TRX_STATE WAITING_TRX_STATE, lr.LOCK_MODE WAITING_TRX_LOCK_MODE, lr.LOCK_TYPE WAITING_TRX_LOCK_TYPE, lr.LOCK_TABLE WAITING_TRX_LOCK_TABLE, lr.LOCK_INDEX WAITING_TRX_LOCK_INDEX, r.TRX_QUERY WAITING_TRX_QUERY, b.TRX_ID BLOCKING_TRX_ID, b.TRX_MYSQL_THREAD_ID BLOCKING_TRX_THREAD, b.TRX_STATE BLOCKING_TRX_STATE, lb.LOCK_MODE BLOCKING_TRX_LOCK_MODE, lb.LOCK_TYPE BLOCKING_TRX_LOCK_TYPE, lb.LOCK_TABLE BLOCKING_TRX_LOCK_TABLE, lb.LOCK_INDEX BLOCKING_TRX_LOCK_INDEX, b.TRX_QUERY BLOCKING_QUERY FROM information_schema.INNODB_LOCK_WAITS w INNER JOIN INFORMATION_SCHEMA.INNODB_TRX b ON b.TRX_ID = W.BLOCKING_TRX_ID INNER JOIN information_schema.INNODB_TRX R ON r.TRX_ID = W.REQUESTING_TRX_ID INNER JOIN information_schema.INNODB_LOCKS lb ON lb.LOCK_TRX_ID = W.BLOCKING_TRX_ID INNER JOIN information_schema.INNODB_LOCKS lr ON lr.LOCK_TRX_ID = W.REQUESTING_TRX_ID;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
        <tag>数据库优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 优化之美：由一条MySQL SQL优化案例的引发索引调优、SQL等价改写及业务实现的反思]]></title>
    <url>%2F2018%2F04%2F04%2FSQL%2FMySQL_SQL_1%2F</url>
    <content type="text"><![CDATA[线上MySQL为5.1版本，频繁引发了update语句与select语句的死锁，死锁引发的原因，暂且不论，主要来分析如何优化SQL减轻死锁的发生概率。SQL执行时间13s,SQL文本如下：12345678910111213141516171819202122232425262728293031323334353637SELECT .... FROM weituoanjian WA LEFT JOIN phoneinfo p ON wa.daoruId = p.drId AND wa.subId = p.subId LEFT JOIN employee e ON employeeId = beifenpeizhe LEFT JOIN mst_tuianleibie ON WA.TuiAnCode = mst_tuianleibie.TuiAnCode LEFT JOIN kehutel ON WA.keHuCode = kehutel.keHuId LEFT JOIN mst_anjianstatus ON WA.AnJianStatusCode = mst_anjianstatus.AnJianStatusCode LEFT OUTER JOIN mst_anjianstatus2 ON WA.taCode = mst_anjianstatus2.TAStatusCode LEFT JOIN anjianpici ON anjianpicicode = wa.pcCode WHERE IFNULL(historyFlag, 0) &lt;&gt; 1 AND (REPLACE(ChiKaRenXingMing, ' ', '') LIKE '%13335192949%' OR ckrpinyin LIKE '%13335192949%' OR ckrszm LIKE '%13335192949%' OR ZhengJianHaoMa LIKE '%13335192949%' OR KaHao LIKE '%13335192949%' OR ZhangHao LIKE '%13335192949%' OR email3 LIKE '%13335192949%' OR email2 LIKE '%13335192949%' OR REPLACE(bqContent, ' ', '') LIKE '%13335192949%' OR REPLACE(BeiZhu1, ' ', '') LIKE '%13335192949%' OR REPLACE(BeiZhu2, ' ', '') LIKE '%13335192949%' OR REPLACE(DanWeiMingCheng, ' ', '') LIKE '%13335192949%' OR pNo LIKE '%13335192949%' OR pName LIKE '%13335192949%' OR (wa.daoruId, wa.subId) IN (SELECT DISTINCT drId, subId FROM bgbinfo WHERE bgInfo LIKE '%13335192949%') OR ZhengJianHaoMa IN (SELECT DISTINCT ShenFenZhengID FROM inputlog WHERE REPLACE(inputText, ' ', '') LIKE '%13335192949%')) ORDER BY ZhengJianHaoMa, daoruId, subId LIMIT 0, 40; 一眼看来，此SQL并没有很好的过滤条件字段，无法通过where 谓词的索引来优化此SQL，只希望表连接还有优化的余地，来解决这次死锁的故障问题，查看SQL执行计划如下，表之间的关联都用上了索引，也无法提升，看来在无法通过索引优化来解决问题。执行计划如下： 对SQL分解拆分分析，第一步：1234567891011... WHERE IFNULL(historyFlag, 0) &lt;&gt; 1 AND (REPLACE(ChiKaRenXingMing, ' ', '') LIKE '%13335192949%' OR ckrpinyin LIKE '%13335192949%' OR ckrszm LIKE '%13335192949%' OR ZhengJianHaoMa LIKE '%13335192949%' OR KaHao LIKE '%13335192949%' OR ZhangHao LIKE '%13335192949%' OR email3 LIKE '%13335192949%' OR email2 LIKE '%13335192949%' OR REPLACE(bqContent, ' ', '') LIKE '%13335192949%' OR REPLACE(BeiZhu1, ' ', '') LIKE '%13335192949%' OR REPLACE(BeiZhu2, ' ', '') LIKE '%13335192949%' OR REPLACE(DanWeiMingCheng, ' ', '') LIKE '%13335192949%' OR pNo LIKE '%13335192949%' OR pName LIKE '%13335192949%') 执行这一段，发现SQL在0.5s之内就能返回结果，执行计划也无明显的可优化点，并且在不改动业务实现的情况下，继续优化的代价太高，所以不在继续深入优化。 第二步：分析子查询对于SQL执行计划的影响，并改写123456789... (wa.daoruId, wa.subId) IN (SELECT DISTINCT drId, subId FROM bgbinfo WHERE bgInfo LIKE '%13335192949%') ...... ZhengJianHaoMa IN (SELECT DISTINCT ShenFenZhengID FROM inputlog WHERE REPLACE(inputText, ' ', '') LIKE '%13335192949%') ... 改写为内连接查询123456789101112... INNER JOIN (SELECT drId, subId FROM bgbinfo WHERE bgInfo LIKE '%13335192949%' GROUP BY drId, subId) m ON m.drId = wa.daoruId AND m.subId = wa.subId ...... INNER JOIN (SELECT ShenFenZhengID FROM inputlog WHERE REPLACE(inputText, ' ', '') LIKE '%13335192949%' GROUP BY ShenFenZhengID) n ON wa.ZhengJianHaoMa = n.ShenFenZhengID ... 第一段0.6s，第二段6s，执行计划分别如下：对wa表ZhengJianHaoMa字段加索引后，第二段更新执行计划如下： 整句SQL改写和索引优化基本完成，SQL执行时间由原来的13s提升到7s，执行时间明显减短；剩下的性能瓶颈主要是来inputlog整张表ShenFenZhengID的去重，表数据量150W。SQL无法优化再优化下去，只能通过改变业务的实现方式来优化，由于表inputText是不更新的，所以通过凌晨定时任务来优化对整个表的数据统计。再和当天的数据做合并，这样就大大减轻了频繁调用此SQL全表扫描排序对服务器负载、执行时间和加锁时间，同时也解决了随着数据量的增加对系统的负载影响，后端程序代码也不需做大改动。定时任务统计当天之前的数据，并写入表中：12345678910111213INERT INTO bgbinfo_day SELECT drId, subId FROM bgbinfo WHERE REPLACE(inputText, ' ', '') LIKE '%13335192949%' AND InputDate &lt; DATE_FORMAT(CURRENT_DATE, '%Y-%m-%d 00:00:00') GROUP BY drId, subId;INERT INTO inputlog_day SELECT ShenFenZhengID FROM inputlog WHERE bgInfo LIKE '%13335192949%' AND InputDate &lt; DATE_FORMAT(CURRENT_DATE, '%Y-%m-%d 00:00:00') GROUP BY ShenFenZhengID; 线上并发调用时再将统计数结果与当天的数据合并123456789101112131415SELECT drId, subId from bgbinfo_dayUNIONSELECT drId, subId FROM bgbinfo WHERE REPLACE(inputText, ' ', '') LIKE '%13335192949%' AND InputDate &gt;= DATE_FORMAT(CURRENT_DATE, '%Y-%m-%d 00:00:00') GROUP BY drId, subId;SELECT ShenFenZhengID from inputlog_dayUNIONSELECT ShenFenZhengID FROM inputlog WHERE REPLACE(inputText, ' ', '') LIKE '%13335192949%' AND InputDate &gt;= DATE_FORMAT(CURRENT_DATE, '%Y-%m-%d 00:00:00') GROUP BY ShenFenZhengID; 最终改写后的SQL为0.8s，性能提升18倍，死锁的问题得意解决，改写也不业务的实现影响，只是在数据库里增加了两个临时表。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990SELECT * FROM (SELECT ... FROM weituoanjian WA LEFT JOIN phoneinfo p ON wa.daoruId = p.drId AND wa.subId = p.subId LEFT JOIN employee e ON employeeId = beifenpeizhe LEFT JOIN mst_tuianleibie ON WA.TuiAnCode = mst_tuianleibie.TuiAnCode LEFT JOIN kehutel ON WA.keHuCode = kehutel.keHuId LEFT JOIN mst_anjianstatus ON WA.AnJianStatusCode = mst_anjianstatus.AnJianStatusCode LEFT OUTER JOIN mst_anjianstatus2 ON WA.taCode = mst_anjianstatus2.TAStatusCode LEFT JOIN anjianpici ON anjianpicicode = wa.pcCode WHERE (historyFlag &gt; 1 or historyFlag &lt; 1 or historyFlag is null) AND (REPLACE(ChiKaRenXingMing, ' ', '') LIKE '%13335192949%' OR ckrpinyin LIKE '%13335192949%' OR ckrszm LIKE '%13335192949%' OR ZhengJianHaoMa LIKE '%13335192949%' OR KaHao LIKE '%13335192949%' OR ZhangHao LIKE '%13335192949%' OR email3 LIKE '%13335192949%' OR email2 LIKE '%13335192949%' OR REPLACE(bqContent, ' ', '') LIKE '%13335192949%' OR REPLACE(BeiZhu1, ' ', '') LIKE '%13335192949%' OR REPLACE(BeiZhu2, ' ', '') LIKE '%13335192949%' OR REPLACE(DanWeiMingCheng, ' ', '') LIKE '%13335192949%' OR pNo LIKE '%13335192949%' OR pName LIKE '%13335192949%') UNION SELECT ... FROM weituoanjian WA LEFT JOIN phoneinfo p ON wa.daoruId = p.drId AND wa.subId = p.subId LEFT JOIN employee e ON employeeId = beifenpeizhe LEFT JOIN mst_tuianleibie ON WA.TuiAnCode = mst_tuianleibie.TuiAnCode LEFT JOIN kehutel ON WA.keHuCode = kehutel.keHuId LEFT JOIN mst_anjianstatus ON WA.AnJianStatusCode = mst_anjianstatus.AnJianStatusCode LEFT OUTER JOIN mst_anjianstatus2 ON WA.taCode = mst_anjianstatus2.TAStatusCode LEFT JOIN anjianpici ON anjianpicicode = wa.pcCode INNER JOIN (SELECT drId, subId from bgbinfo_day UNION SELECT drId, subId FROM bgbinfo WHERE REPLACE(inputText, ' ', '') LIKE '%13335192949%' AND InputDate &gt;= DATE_FORMAT(CURRENT_DATE, '%Y-%m-%d 00:00:00') GROUP BY drId, subId) m ON m.drId = wa.daoruId AND m.subId = wa.subId WHERE (historyFlag &gt; 1 or historyFlag &lt; 1 or historyFlag is null) UNION SELECT ... FROM weituoanjian WA LEFT JOIN phoneinfo p ON wa.daoruId = p.drId AND wa.subId = p.subId LEFT JOIN employee e ON employeeId = beifenpeizhe LEFT JOIN mst_tuianleibie ON WA.TuiAnCode = mst_tuianleibie.TuiAnCode LEFT JOIN kehutel ON WA.keHuCode = kehutel.keHuId LEFT JOIN mst_anjianstatus ON WA.AnJianStatusCode = mst_anjianstatus.AnJianStatusCode LEFT OUTER JOIN mst_anjianstatus2 ON WA.taCode = mst_anjianstatus2.TAStatusCode LEFT JOIN anjianpici ON anjianpicicode = wa.pcCode INNER JOIN (SELECT ShenFenZhengID from inputlog_day UNION SELECT ShenFenZhengID FROM inputlog WHERE REPLACE(inputText, ' ', '') LIKE '%13335192949%' AND InputDate &gt;= DATE_FORMAT(CURRENT_DATE, '%Y-%m-%d 00:00:00') GROUP BY ShenFenZhengID) n ON wa.ZhengJianHaoMa = n.ShenFenZhengID WHERE (historyFlag &gt; 1 or historyFlag &lt; 1 or historyFlag is null)) t ORDER BY t.ZhengJianHaoMa, t.daoruId, t.subId LIMIT 0, 40;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[索引设计原则、使用场景及失效场景]]></title>
    <url>%2F2018%2F04%2F03%2FSQL%2FDB_INDEX_1%2F</url>
    <content type="text"><![CDATA[索引对查询的速度有着至关重要的影响，理解索引也是进行数据库性能调优的起点。首先需要明白为什么索引会增加检索效率，DB在执行一条SQL语句的时候，默认的方式是根据搜索条件进行全表扫描，遇到匹配条件的就加入搜索结果集合。如果我们对某一字段增加索引，数据库基于costs优化器，根据系统收集的统计信息，生成执行计划，查询时就会通过索引列表中一次定位到特定值的行数，大大减少遍历匹配的行数，所以能明显增加查询的速度。 索引优点与缺点使用索引的优点123451、加速表和表之间的关接，特别是在实现数据的参考完整性方面特别有意义。2、可以大大加快数据的检索速度，这也是创建索引的最主要的原因。3、通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。4、在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。5、通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 索引存在的缺陷123451、数据内容的变更（增、删、改）都需要修订索引，索引存在而外的维护成本2、创建、维护索引要耗费时间和系统资源，维护时间随着数据量的增加而增加。3、查找翻阅索引系统需要消耗时间，索引存在而外的访问成本。4、索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。5、数据的备份和恢复时间，会因为过多的索引消耗系统更多的维护时间。 如何建立理想的索引12345SQL查询频率过滤谓词选择性（cardinality/selectivity）索引长度覆盖字段索引排序 索引设计和使用原则在进行索引设计和索引优化时，请参考如下的索引使用原则：1234567891、通过创建唯一性索引，保证数据库表中数据的唯一性。2、对任何将要用于连接表的谓词连接列(on)创建索引3、对预计会频繁运行的SQL中WHERE子句引用的谓词过滤列创建索引4、对用于分组、分组等操作（进行GROUP BY或ORDER BY操作）的谓词分组、排序列创建索引5、过滤效果（选择性要高）要好（索引列的基数要大），不宜对status、sex等低基数列，使用单列索引检索数据，而尽可能与其他过滤条件建立复合索引，增加数据选择性6、对于那些在查询中很少使用或频繁更新的列，不宜使用索引7、字段顺序要佳，字段顺序对复合索引的效率有至关重要的作用，选择性高的的字段需要更靠前8、索引长度尽量小，对于定义为text，blob数据类型的大字段列不宜创建索引，而尽可能考虑前缀索引9、不宜过度索引，建立多个SQL能同时使用的高效复合索引，而不是多个索引 索引失效场景以a,b 两列复合索引idx_a_b(a,b)为例说明 索引全失效场景idx_a_b(a,b) 索引完全不被SQL使用 谓词列或关联谓词列使用了普通或函数运算12SELECT * FROM t WHERE DATE_FORMAT(a,'%Y%m%d') = '20180408';SELECT * FROM t WHERE a + 2 = 10; 谓词上的索引列或关联谓词列数据类型出现隐式转换（包括不同数据类型、字符集的转换等【字节长度不影响】）123a、字符类型转换（int/varchar、varchar/datetime、varchar/varbinary等数据类型的转换）b、字符集转换（utf8与utf8mb4字符集等）c、同字符集排序规则不同（utf8_general_ci与utf8_bin等） 谓词上使用了负向查询（not, not in, not like, &lt;&gt;, != , !&gt;, !&lt; ）不会使用索引12SELECT * FROM t WHERE a != 8;SELECT * FROM t WHERE a NOT IN (1,2,3); 以%开头的like查询或者正则匹配的regexp模糊查询12SELECT * FROM t WHERE a LIKE '%c';SELECT * FROM t WHERE a REGEXP '...'; 谓词上的索引列上对null运算（is null,is not null）12SELECT * FROM WHERE a IS NULL;SELECT * FROM WHERE a IS NOT NULL; 子查询使用了not in导致关联谓词列索引失效1SELECT * FROM t WHERE a.id NOT IN (SELECT b.id FROM b); 检索小表高水位、表空间碎片过多、统计信息错误及优化器缺陷等，导致索引不可用或低效低基数的查询过滤列（基于CBO的优化器）数据检索或询的数量是大表的大部分，30%左右（值不确定、以计算代价为准），导致索引失效索引部分失效场景复合索引idx_a_b_c，b字段或c字段索引失效的情况 复合索引中，以（&gt; 、&lt;、&lt;=）的范围查询导致索引低效（不含in 、between and 、&gt;= &lt;= 、&gt;= &lt;）12SELECT * FROM t WHERE a &gt; 1 AND b &gt;= 1;SELECT * FROM t WHERE a &lt;= 1 AND b &gt;= 1; 复合索引中，以or为关键词的范围查询导致索引失效1SELECT * FROM t WHERE a = 1 AND (b = 1 OR c = 1); 复合索引中，范围检索导致之后的分组、排序 GROUP BY/ORDER BY 列索引失效12SELECT * FROM t WHERE a &gt;= 1 GROUP BY b;SELECT * FROM t WHERE a &gt;= 1 ORDER BY b; 在非连续的索引键部分上做 GROUP BY/ORDER BY 分组或排序，无法利用索引来实现GROUP BY/ORDER BY的优化12SELECT * FROM t WHERE a IN (1,2,3) GROUP BY b;SELECT * FROM t WHERE a IN (1,2,3) ORDER BY b; 如果在 WHERE 和 ORDER BY 的栏位上应用表达式(函数)时，则无法利用索引来实现GROUP BY/ORDER BY的优化1SELECT * FROM WHERE a IN (1,2,3) GROUP BY DATE_FORMAT(b,'%Y%m%d'); 分组后，对不同字段排序，导致排序字段索引不可用1SELECT * FROM t GROUP BY a ORDER BY b; 更具体的索引失效场景请参考如下表格：]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL 优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL mysqldump 和 innobackupex 物理备份脚本]]></title>
    <url>%2F2018%2F04%2F03%2FMySQL%2FMySQL_Backup%2F</url>
    <content type="text"><![CDATA[Xtrabackup 备份脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#!/bin/bash#----------------------------------#User -------------MySQL备份用户#Passwd -----------MySQL备份密码#Port -------------MySQL备份#BackupDir --------备份存放目录#Weekly -----------全备份时间，以星期为时间单位#Mycnf ------------MySQL参数位置路径# ---------------------------------User=Passwd=Port=BackupDir=/data/backupWeekly=Mycnf=/etc/my.cnfXtrabackup=/usr/bin/innobackupexNext=$(expr "$Weekly" + 1)Today=`date +%Y-%m-%d`Yesterday=`date -d"yesterday" +%Y-%m-%d`Full_Backup_File="$BackupDir"/"$Today"Inc_Backup_File="$BackupDir"/"$Today"Base_Backup_File="$BackupDir"/"$Yesterday"LogFile="$BackupDir"/"$Today".logecho "---------------------------------------------------------" &gt;&gt; $LogFileecho " $(date +"%y-%m-%d %H:%M:%S") Start " &gt;&gt; $LogFileecho "---------------------------------------------------------" &gt;&gt; $LogFile# Database All Backupif [ ! -d "$BackupDir"$(date -d"yesterday" +%Y-%m-%d) ]; then $Xtrabackup --defaults-file=$Mycnf -u$User -p$Passwd -P$Port --slave-info --no-timestamp $Full_Backup_File &gt;&gt; /dev/null 2&gt;&amp;1fiif [ -f "$BackupDir"$(date +%Y-%m-%d)_full.tar.gz ] || [ -f "$BackupDir"$(date +%Y-%m-%d)_inc.tar.gz ];then echo "["$BackupDir"$(date +%Y-%m-%d)_full.tar.gz] || ["$BackupDir"$(date +%Y-%m-%d)_inc.tar.gz] The Backup File is exists,Can't Backup!" &gt;&gt; $LogFileelse #full backup if [ $(date +%u) == $Weekly ];then $Xtrabackup --defaults-file=$Mycnf -u$User -p$Passwd -P$Port --slave-info --no-timestamp $Full_Backup_File &gt;&gt; /dev/null 2&gt;&amp;1 cd $BackupDir; if [ -d $(date +%Y-%m-%d --date='1 days ago') ];then rm -rf $(date +%Y-%m-%d --date='1 days ago') echo "[rm -rf $(date +%Y-%m-%d --date='1 days ago')] Delete Success!" &gt;&gt; $LogFile eles echo "[rm -rf $(date +%Y-%m-%d --date='1 days ago')] is not exist" &gt;&gt; $LogFile fi tar -zcf "$Today"_full.tar.gz $Today &gt;&gt; /dev/null 2&gt;&amp;1 #incremental backup elif [ $(date +%u) == $Next ];then $Xtrabackup --defaults-file=$Mycnf -u$User -p$Passwd -P$Port --slave-info --no-timestamp --incremental --incremental-basedir=$Base_Backup_File $Inc_Backup_File &gt;&gt; /dev/null 2&gt;&amp;1 cd $BackupDir; if [ -d $(date +%Y-%m-%d --date='1 days ago') ];then rm -rf $(date +%Y-%m-%d --date='1 days ago') echo "[rm -rf $(date +%Y-%m-%d --date='1 days ago')] Delete Success!" &gt;&gt; $LogFile eles echo "[rm -rf $(date +%Y-%m-%d --date='1 days ago')] is not exist" &gt;&gt; $LogFile fi tar -zcf "$Today"_inc.tar.gz $Today &gt;&gt; /dev/null 2&gt;&amp;1 else $Xtrabackup --defaults-file=$Mycnf -u$User -p$Passwd -P$Port --slave-info --no-timestamp --incremental --incremental-basedir=$Base_Backup_File $Inc_Backup_File &gt;&gt; /dev/null 2&gt;&amp;1 cd $BackupDir; if [ -d $(date +%Y-%m-%d --date='1 days ago') ];then rm -rf $(date +%Y-%m-%d --date='1 days ago') echo "[rm -rf $(date +%Y-%m-%d --date='1 days ago')] Delete Success!" &gt;&gt; $LogFile eles echo "[rm -rf $(date +%Y-%m-%d --date='1 days ago')] is not exist" &gt;&gt; $LogFile fi tar -zcf "$Today"_inc.tar.gz $Today &gt;&gt; /dev/null 2&gt;&amp;1 fifiecho "---------------------------------------------------------" &gt;&gt; $LogFileecho " $(date +"%y-%m-%d %H:%M:%S") End " &gt;&gt; $LogFileecho "---------------------------------------------------------" &gt;&gt; $LogFile#Backup retention timefind $BackupDir -mtime +16 -name "*.*" -exec rm -rf &#123;&#125; \; mysqldump 备份脚本1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bash#----------------------------------#User -------------MySQL备份用户#Passwd -----------MySQL备份密码#Passwd -----------MySQL备份主机#Port -------------MySQL备份#BackupDir --------备份存放目录# ---------------------------------User=Passwd=Host=Port=3306BackupDir=Today=`date +%Y-%m-%d`MysqlDump=/usr/local/mysql/bin/mysqldumpLogFile="$BackupDir"/"$Host"_"$Today".logecho "---------------------------------------------------------" &gt;&gt; $LogFileecho " $(date +"%Y-%m-%d %H:%M:%S") Start " &gt;&gt; $LogFileecho "---------------------------------------------------------" &gt;&gt; $LogFileif [ -f "$BackupDir"/"$Host"_"$Today".tar.gz]; then rm -rf "$BackupDir"/"$Host"_"$Today".tar.gzfiDatabases=`mysql -e "show databases;" -u$User -p$Passwd -h$Host -P$Port | grep -Ev "Database|information_schema|performance_schema|test|sys"`$MysqlDump -h"$Host" -u$User -p$Passwd -P$Port --single-transaction --master-data=2 --flush-logs --triggers -E -R -B "$Databases" |gzip&gt; "$BackupDir"/"$Host"_"$Today".tar.gzecho "---------------------------------------------------------" &gt;&gt; $LogFileecho " $(date +"%Y-%m-%d %H:%M:%S") End " &gt;&gt; $LogFileecho "---------------------------------------------------------" &gt;&gt; $LogFile#Backup retention timefind $BackupDir -mtime +7 -name ""$Host"*" -exec rm -rf &#123;&#125; \;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>MySQL 备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL SQL 技巧——通过存储过程对一个表生成大量测试数据]]></title>
    <url>%2F2018%2F04%2F02%2FSQL%2FDB_SQL%2F</url>
    <content type="text"><![CDATA[建立字符串随机生成存储过程1234567891011121314DELIMITER // DROP FUNCTION IF EXISTS `rand_string` //SET NAMES utf8 //CREATE FUNCTION `rand_string` (n INT) RETURNS VARCHAR(255) CHARSET 'utf8'BEGIN DECLARE char_str varchar(100) DEFAULT 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'; DECLARE return_str varchar(255) DEFAULT ''; DECLARE i INT DEFAULT 0; WHILE i &lt; n DO SET return_str = concat(return_str, substring(char_str, FLOOR(1 + RAND()*62), 1)); SET i = i+1; END WHILE; RETURN return_str;END // 建立需要生成数据的测试表结构建议生成数据后在建立所需的索引结构，否则影响插入效率，这里的测试表结构如下123456789CREATE TABLE `user` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `user_id` varchar(32) NOT NULL, `his_user_id` varchar(32) NOT NULL DEFAULT '', `vote_num` int(10) unsigned NOT NULL DEFAULT 0, `status` tinyint(4) unsigned NOT NULL DEFAULT 0, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 建立批量插入数据的函数123456789101112131415161718DELIMITER //DROP PROCEDURE IF EXISTS `p_bulk_insert` //CREATE PROCEDURE `p_bulk_insert`(IN n INT)BEGIN DECLARE i INT DEFAULT 1; DECLARE vote_num INT DEFAULT 0; DECLARE status TINYINT DEFAULT 0; DECLARE time_num_1 TINYINT DEFAULT 0; DECLARE time_num_2 TINYINT DEFAULT 0; WHILE i &lt; n DO SET vote_num = FLOOR(1 + RAND() * 1000); SET status = FLOOR(0 + RAND() * 2); SET time_num_1 = FLOOR(0 + RAND() * 2); SET time_num_2 = FLOOR(1 + RAND() * 7); INSERT INTO `user` VALUES (NULL, rand_string(24), rand_string(24), vote_num, status, CONCAT('2017-0', time_num_2, '-', time_num_1, time_num_2,' ', time_num_1, time_num_2,':00:01')); SET i = i + 1; END WHILE;END // 调用存储过程生成数据1CALL p_bulk_insert(100);]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全面解析 MySQL、MongoDB 数据库监控工具 PMM]]></title>
    <url>%2F2017%2F11%2F12%2FMySQL%2FMySQL_PMM%2F</url>
    <content type="text"><![CDATA[PMM 架构组成及实现原理 PMM Server 端安装过程及注意事项Docker 安装在低版本Docker中，安装PMM，SQL慢日志页面可能加载不出来，固推荐以安装较高版本 Docker。安装 Docker 后，默认Docker镜像路径在/usr/lib/docker目录，为防止根目录在使用过程中被撑爆，需修改默认存储路径 安装 Docker方法一：12[root@PMM ~]# rpm -qa|grep docker | xargs rpm -e --nodeps[root@PMM ~]# curl -sSL https://get.docker.com/ | sh 方法二：123456789[root@PMM ~]# cat &gt;&gt; /etc/yum.repos.d/docker.repo &lt;&lt;EOF[dockerrepo]name=Docker Repositorybaseurl=http://yum.dockerproject.org/repo/main/centos/7/enabled=1gpgcheck=0EOF[root@PMM ~]# yum install -y docker-engine 设置云镜像库加速与修改默认存储路径123456[root@PMM ~]# mkdir -p /data/docker[root@PMM ~]# mkdir -p /etc/docker/[root@PMM ~]# cat &gt;&gt; /etc/docker/daemon.json &lt;&lt;EOF &#123;"registry-mirrors": ["https://apg1cbea.mirror.aliyuncs.com"], "graph": "/data/docker"&#125;EOF 启动 Docker，并设置开机自启动12[root@PMM ~]# systemctl start docker[root@PMM ~]# systemctl enable docker 拉取 PMM 镜像安装 Server 端拉取PMM最新容器镜像123456[root@PMM ~]# docker pull percona/pmm-server:latestlatest: Pulling from percona/pmm-server469cfcc7a4b3: Pull complete fa45d21b9629: Pull complete Digest: sha256:1c088ceb2d3b2c32c6abfb11b30e555356473b559b7dbb8f07efc78520995fadStatus: Downloaded newer image for percona/pmm-server:latest 建立 PMM-Server 数据卷容器12345678[root@PMM ~]# docker create \ -v /opt/prometheus/data \ -v /opt/consul-data \ -v /var/lib/mysql \ -v /var/lib/grafana \ --name pmm-data \ percona/pmm-server:latest /bin/true77746794afa669677389cdfb2490917e711334a98bffef0d1915c514b9e16604 运行PMM Server（同时设置登录用户名(SERVER_USER)和密码(SERVER_PASSWORD), 根据需要进行修改.如果80端口被占用或者修改为自己想使用的端口，以如下方式启动PMM 镜像123456789[root@PMM ~]# docker run -d -p 8082:80 \ --volumes-from pmm-data \ --name pmm-server \ -e SERVER_USER=pmm \ -e SERVER_PASSWORD=pmm_passwd \ -e ORCHESTRATOR_ENABLED=true \ --restart always \ percona/pmm-server:latest285e395000dbd24adcf3d5cf6e59fa5aada3820f3798cf172888fc499ff0675e 更改面板数据sqlite3库存储类型为MYSQL(容器自带)123456789[root@PMM ~]# docker exec -i -t pmm-server /bin/bash[root@285e395000db opt]# sed -i 's/;type = sqlite3/type=mysql/g' /etc/grafana/grafana.ini[root@285e395000db opt]# sed -i 's/;host = 127.0.0.1:3306/host = 127.0.0.1:3306/g' /etc/grafana/grafana.ini[root@285e395000db opt]# sed -i 's/;name = grafana/name = grafana/g' /etc/grafana/grafana.ini[root@285e395000db opt]# sed -i 's/;user = root/user = root/g' /etc/grafana/grafana.ini[root@285e395000db opt]# sed -i 's/;password =/password =/g' /etc/grafana/grafana.ini[root@285e395000db opt]# mysql -e "create database grafana;" 退出Docker容器，重启PMM Server1[root@PMM ~]# docker restart pmm-server PMM Client 端搭建过程及监控注意事项到官网下载安装最新版本PMM Client客户端以及pt-toolkit，并开通各PMM Client到 PMM Serevr 42000和42002端口 安装 PMM-Client12[root@node1 ~]# yum install -y https://www.percona.com/downloads/pmm/1.10.0/binary/redhat/7/x86_64/pmm-client-1.10.0-1.el7.x86_64.rpm[root@node1 ~]# yum install -y https://www.percona.com/downloads/percona-toolkit/3.0.9/binary/redhat/7/x86_64/percona-toolkit-3.0.9-1.el7.x86_64.rpm 被监控端创建 MySQL 账号，并控制权限被监控的MySQL创建相关监控账号，并控制权限123root@localhost:(none)&gt; GRANT SELECT, PROCESS, SUPER, REPLICATION CLIENT, REPLICATION SLAVE, RELOAD ON *.* TO 'pmm_monitor'@'localhost' IDENTIFIED BY 'pmm_passwd' WITH MAX_USER_CONNECTIONS 10;root@localhost:(none)&gt; GRANT SELECT, UPDATE, DELETE, DROP ON performance_schema.* TO 'pmm_monitor'@'localhost';root@localhost:(none)&gt; FLUSH PRIVILEGES; 配置服务端连接123456[root@node1 ~]# pmm-admin config --server 192.168.1.14:8082 --server-user pmm --server-password pmm_passwd --client-address 192.168.1.10 --client-name master_192.168.1.10OK, PMM server is alive.PMM Server | 192.168.1.14:8082 (password-protected)Client Name | master_192.168.1.10Client Address | 192.168.1.10 采集MySQL监控数据1234[root@node1 ~]# pmm-admin add mysql --query-source perfschema --user pmm_monitor --password pmm_passwd --host localhost --port 3306[linux:metrics] OK, already monitoring this system.[mysql:metrics] OK, now monitoring MySQL metrics using DSN pmm_monitor:***@unix(/tmp/mysql.sock)[mysql:queries] OK, now monitoring MySQL queries from perfschema using DSN pmm_monitor:***@unix(/tmp/mysql.sock) 检查PMM连接、监控连接状态如果不能获取数据需要打开端口42002、420001234567891011121314[root@node1 ~]# pmm-admin listpmm-admin 1.10.0PMM Server | 192.168.1.14:8082 (password-protected)Client Name | master_192.168.1.10Client Address | 192.168.1.10 Service Manager | linux-systemd-------------- -------------------- ----------- -------- -------------------------------------- ---------------------------------------------SERVICE TYPE NAME LOCAL PORT RUNNING DATA SOURCE OPTIONS -------------- -------------------- ----------- -------- -------------------------------------- ---------------------------------------------mysql:queries master_192.168.1.10 - YES pmm_monitor:***@unix(/tmp/mysql.sock) query_source=perfschema, query_examples=true linux:metrics master_192.168.1.10 42000 YES - mysql:metrics master_192.168.1.10 42002 YES pmm_monitor:***@unix(/tmp/mysql.sock) 123456789101112131415161718192021222324252627282930313233[root@node1 ~]# pmm-admin check-networkPMM Network StatusServer Address | 192.168.1.14:8082Client Address | 192.168.1.10 * System TimeNTP Server (0.pool.ntp.org) | 2018-04-22 18:15:54 +0800 CSTPMM Server | 2018-04-22 10:15:51 +0000 GMTPMM Client | 2018-04-22 18:15:51 +0800 CSTPMM Server Time Drift | OKPMM Client Time Drift | OKPMM Client to PMM Server Time Drift | OK* Connection: Client --&gt; Server-------------------- ------- SERVER SERVICE STATUS -------------------- ------- Consul API OKPrometheus API OKQuery Analytics API OKConnection duration | 508.744µsRequest duration | 5.462146msFull round trip | 5.97089ms* Connection: Client &lt;-- Server-------------- -------------------- ------------------- ------- ---------- ---------SERVICE TYPE NAME REMOTE ENDPOINT STATUS HTTPS/TLS PASSWORD -------------- -------------------- ------------------- ------- ---------- ---------linux:metrics master_192.168.1.10 192.168.1.10:42000 OK YES YESmysql:metrics master_192.168.1.10 192.168.1.10:42002 OK YES YES]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>MongoDB</tag>
        <tag>Percona</tag>
        <tag>数据库监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL优化之美：对隐式转换、not in子查询诊断和改写]]></title>
    <url>%2F2017%2F11%2F11%2FSQL%2FMySQL_SQL%2F</url>
    <content type="text"><![CDATA[MySQL 执行计划问题 SQL 文本如下：1234567891011121314151617181920SELECT COUNT(*) AS count FROM user u INNER JOIN token t ON u.user_id = t.user_id INNER JOIN user_history h ON u.user_id = h.user_id INNER JOIN loan_record r ON r.history_id = h.user_id INNER JOIN ACT_HI_PROCINST AHP on AHP.BUSINESS_KEY_ = r.loan_record_id WHERE r.approval_result != 0 AND u.id NOT IN (SELECT n3.id FROM loan_record n1 INNER JOIN user_history n2 on n1.history_id = n2.user_id INNER JOIN user n3 ON n3.user_id = n2.user_id WHERE n1.approval_result = 1) AND r.apply_time LIKE CONCAT('2017-11-07', '%') AND t.channel IN (2，3); 执行计划如下： 执行时间2.1s，结果集0条。 SQL性能定位及分析对于此执行计划相信很多SQL开发人员和部分DBA会说，r 表已经创建了 apply_time 字段索引，其他表都是通过索引来检索数据的，已经无法从很难从SQL及索引层面着手优化，然而这都只是表象。SQL 虽然用到了索引，然而并没有将索引用到最优，表之间连接也并不优，下面我将对此SQL的优化展开详细的讨论： 1、我们都知道 r.approval_result != 0 是无法使用索引的，当然就算改写后，也不一定会用到索引，这和数据量、过滤条件有着很深的关系。有时候对于DBA来说，可能会使用索引，并不一定使用索引，但有时候通过复合索引的方式，通过复合索引可以少扫描大量数据，对SQL改写优化有着奇效。这里根据业务规则，改写成 r.approval_result in (1,2,3)（思考下为什么我不改写为 r.approval_result &gt; 0），果然执行计划没有变化 2、not in 对于子查询来说是最差的选择，是无法走任何索引的，不要仅仅只看执行计划，在此执行计划中n3表走idx_user_id索引，但表也不是通过表关联嵌套驱动，对其改写为not exists或者left join连接查询 3、对于 r 表来说按时间 apply_time LIKE CONCAT(‘2017-11-06’, ‘%’) 字段过滤，apply_time 字段建有索引，本应该相当高效的，然而 SQL 并没有走时间字段索引，而是通过全表扫描来检索数据，此时对索引字段也没有进行函数、计算运算，猜测其中可能发生了时间与字符串类型的隐式转换，导致SQL不能通过索引扫描数据。 4、字符集的隐式转换，具体分析请根据下例分析 此时MySQL 优化器对其SQL的改写为如下：123456789101112131415161718192021222324252627/* select#1 */select count(0) AS "count" from "test"."user" "u" join "test"."token" "t" join "test"."user_history" "h" join "test"."loan_record" "r" join "test"."ACT_HI_PROCINST" "AHP" where (("test"."h"."user_id" = "test"."r"."history_id") and ("test"."u"."user_id" = "test"."r"."history_id") and ("test"."t"."user_id" = "test"."r"."history_id") and ("test"."r"."approval_result" &lt;&gt; 0) and (not (&lt; in_optimizer &gt; ("test"."u"."user_id", &lt; exists &gt; ( /* select#2 */ select 1 from "test"."loan_record" "n1" join "test"."user_history" "n2" join "test"."user" "n3" where (("test"."n3"."user_id" = "test"."n2"."user_id") and ("test"."n1"."history_id" = "test"."n2"."user_id") and ("test"."n1"."approval_result" = 1) and (&lt; cache &gt; ("test"."u"."user_id") = "test"."n2"."user_id")))))) and ("test"."r"."apply_time" like &lt; cache &gt; (concat('2017-11-07', '%'))) and ("test"."t"."channel" in (2, 3)) and ("test"."AHP"."BUSINESS_KEY_" = convert("test"."r"."loan_record_id" using utf8mb4))) 从这里可以看出MySQL 优化器将 not in 子查询自动优化为了not exists 子查询，对 not in做了优化，而时间字段无法确认是否做了隐式转换，这个需实验验证，还可以看出 AHP 表 BUSINESS_KEY_ 与 r 表 loan_record_id 字段之间存在不同字符集的隐式转换。 对此我最终 SQL 改写，并为 r 表添加了approval_result，apply_time复合索引，将AHP表的 BUSINESS_KEY_ 字段字符集改为utf8，最终SQL执行执行时间优化为0.26s返回数据。 最终 SQL 文本：123456789101112131415161718192021222324SELECT COUNT(*) AS count FROM user u INNER JOIN token t ON u.user_id = t.user_id INNER JOIN user_history h ON u.user_id = h.user_id INNER JOIN (SELECT history_id, loan_record_id FROM loan_record WHERE approval_result IN (1,2,3) AND apply_time BETWEEN '2017-11-07 00:00:00' AND '2017-11-07 23:59:59') r ON r.history_id = h.user_id AND t.channel IN (2, 3) INNER JOIN ACT_HI_PROCINST AHP on AHP.BUSINESS_KEY_ = r.loan_record_id LEFT JOIN (SELECT n3.user_id FROM loan_record n1 INNER JOIN user_history n2 on n1.history_id = n2.user_id INNER JOIN user n3 ON n3.user_id = n2.user_id WHERE n1.approval_result = 1) a ON u.user_id = a.user_id WHERE a.user_id IS NULL; 最终执行计划为： MySQL 优化器对起的改写 SQL 优化解析为：123456789101112131415161718192021/* select#1 */select count(0) AS "count" from "test"."user" "u" join "test"."token" "t" join "test"."user_history" "h" join "test"."loan_record" join "test"."ACT_HI_PROCINST" "AHP" left join("test"."loan_record" "n1" join "test"."user_history" "n2" join "test"."user" "n3") on ((("test"."n1"."approval_result" = 1) and ("test"."n2"."user_id" = "test"."loan_record"."history_id") and ("test"."n3"."user_id" = "test"."loan_record"."history_id") and ("test"."n1"."history_id" = "test"."loan_record"."history_id"))) where (("test"."h"."user_id" = "test"."loan_record"."history_id") and ("test"."u"."user_id" = "test"."loan_record"."history_id") and ("test"."t"."user_id" = "test"."loan_record"."history_id") and ("test"."AHP"."BUSINESS_KEY_" = "test"."loan_record"."loan_record_id") and isnull("test"."n3"."user_id") and ("test"."t"."channel" in (2, 3)) and ("test"."loan_record"."approval_result" in (1, 2, 3)) and ("test"."loan_record"."apply_time" between '2017-11-07 00:00:00' and '2017-11-07 23:59:59'))]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>SQL 优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL Percona Xtrabackup 物理备份详解]]></title>
    <url>%2F2017%2F11%2F11%2FMySQL%2FMySQL_PXB%2F</url>
    <content type="text"><![CDATA[MySQL PXB 备份恢复原理MySQL PXB 重要备份参数详解12 MySQL PXB 全量、增量备份还原MySQL PXB 流备份、远程备份说明]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>MySQL 备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 主从复制延时原理、诊断与解决方案]]></title>
    <url>%2F2017%2F10%2F19%2FMySQL%2FMySQL_Replication_Delay%2F</url>
    <content type="text"><![CDATA[MySQL 主从复制延时原理MySQL 主从复制为单线程操作，Master后台IO线程对所有DDL和DML写binlog，binlog为顺序写，效率较高；Slave的Slave_IO_Running线程到主库取binlog日志，效率会比较高（受网络延迟影响），Slave的Slave_SQL_Running线程将主库的DDL和DML操作从Relay Log获取重做。Slave重做DML和DDL的IO操作为随机IO，效率低，还存在可能Slave上的其他查询产生lock争用，由于Slave_SQL_Running也是单线程的，所有DDL或者DML都是串行执行的，当一个DDL或者DDL存在延迟，之后产生的DDL和DML都将延时 MySQL 主从复制延时诊断12 MySQL 主从复制延时解决]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>故障诊断</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于 MySQL 数据库的 MHA 集群原理及搭建过程]]></title>
    <url>%2F2017%2F10%2F19%2FMySQL%2FMySQL_MHA%2F</url>
    <content type="text"><![CDATA[MHA 背景MHA算是业内比较成熟的MySQL高可用解决方案，在MySQL故障切换过程中，MHA能做到自动完成数据库的故障切换操作，并且在进行故障切换的过程中，MHA能在最大程度上保证数据的一致性，以达到真正意义上的高可用。软件主要有MHA Manager（管理节点）和MHA Node（数据节点）两部分组成，在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。 目前MHA主要支持一主多从的架构，搭建MHA集群，要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因此至少需要三台数据库服务器。 MHA是被广泛使用MySQL HA组件，MHA 0.56以后支持基于GTID的复制。 MHA在failover时会自动判断是否是GTID based failover，需要满足下面3个条件即为GTID based failover。 MHA 高可用实现原理MHA 高可用集群搭建过程配置 MySQL 主从同步配置 SSH 免密认证1234567891011121314151617181920212223[mysql@node1 ~]$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa[mysql@node2 ~]$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa[mysql@node3 ~]$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa[mysql@node1 ~]$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys[mysql@node2 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub mysql@node1[mysql@node3 ~]$ ssh-copy-id -i ~/.ssh/id_rsa.pub mysql@node1[mysql@node1 ~]$ chmod 600 ~/.ssh/authorized_keys[mysql@node1 ~]$ for a in &#123;2..3&#125;; do scp ~/.ssh/authorized_keys mysql@node$a:~/.ssh/ ; done[mysql@node1 ~]$ ssh mysql@node1[mysql@node1 ~]$ ssh mysql@node2[mysql@node1 ~]$ ssh mysql@node3[mysql@node2 ~]$ ssh mysql@node1[mysql@node2 ~]$ ssh mysql@node2[mysql@node2 ~]$ ssh mysql@node3[mysql@node3 ~]$ ssh mysql@node1[mysql@node3 ~]$ ssh mysql@node2[mysql@node3 ~]$ ssh mysql@node3 设置 mysql 用户 sudo 权限1234567891011[root@node1 ~]# chmod u+w /etc/sudoers[root@node1 ~]# sed -i '/Allow root to run any/a\mysql ALL=(ALL) NOPASSWD: ALL' /etc/sudoers[root@node1 ~]# chmod u-w /etc/sudoers[root@node2 ~]# chmod u+w /etc/sudoers[root@node2 ~]# sed -i '/Allow root to run any/a\mysql ALL=(ALL) NOPASSWD: ALL' /etc/sudoers[root@node2 ~]# chmod u-w /etc/sudoers[root@node3 ~]# chmod u+w /etc/sudoers[root@node3 ~]# sed -i '/Allow root to run any/a\mysql ALL=(ALL) NOPASSWD: ALL' /etc/sudoers[root@node3 ~]# chmod u-w /etc/sudoers 安装 MHA 依赖包123[root@node1 ~]# yum install -y http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm[root@node1 ~]# yum install -y perl-MIME-Lite perl-Params-Validate perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes \perl-Mail-Sender perl-Mail-Sendmail perl-rrdtool rrdtool-devel perl-CPAN perl-devel net-tools Centos 6版本使用安装Perl依赖包：yum install -y http://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm 安装 arping下载地址：http://www.habets.pp.se/synscan/files/arping-2.19.tar.gz12345[root@node3 ~]# yum install -y libnet-devel libpcap-devel[root@node3 ~]# wget http://www.habets.pp.se/synscan/files/arping-2.19.tar.gz -P /dba/tools[root@node3 ~]# tar -zxf /dba/tools/arping-2.19.tar.gz -C /dba/tools[root@node3 ~]# cd /dba/tools/arping-2.19[root@node3 arping-2.19]# ./configure &amp;&amp; make &amp;&amp; make install 安装 MHAMHA 0.56 下载地址：https://pan.lanzou.com/i0vft4jMHA 0.57 下载地址：https://pan.lanzou.com/i0vft5a第一种 MHA 安装方式1[root@node1 ~]# rpm -Uvih /dba/tools/mha4mysql-*-0.57-0.el7.noarch.rpm 第二种 MHA 安装方式123456789[root@node3 ~]# tar -zxf /dba/tools/mha4mysql-manager-0.57.tar.gz -C /dba/tools[root@node3 ~]# cd /dba/tools/mha4mysql-manager-0.57[root@node3 mha4mysql-manager-0.57]# perl Makefile.PL[root@node3 mha4mysql-manager-0.57]# make &amp;&amp; make install[root@node3 ~]# tar -zxf /dba/tools/tar -zxf mha4mysql-node-0.57.tar.gz -C /dba/tools[root@node3 ~]# cd /dba/tools/mha4mysql-node-0.57[root@node3 mha4mysql-manager-0.57]# perl Makefile.PL[root@node3 mha4mysql-manager-0.57]# make &amp;&amp; make install 配置 MHA 参数文件1234567891011121314151617181920212223242526272829303132333435363738394041cat &gt;&gt; /etc/mha.cnf &lt;&lt;EOF[server default]manager_workdir=/dba/mha/manager_log=/dba/mha/logs/manager.logmaster_binlog_dir=/data/mysql/log/binlogremote_workdir=/dba/mha/binlogsssh_user=mysqlssh_port=22user=mhapassword=oRcl_123repl_user=replrepl_password=oRcl_123ping_interval=3 # 设置监控主库,发送ping包的时间间隔,默认是3秒,尝试三次没有回应的时候自动进行failover;#master_ip_failover_script= /dba/mha/scripts/master_ip_failover.sh --interface=enp0s3 --vip=192.168.1.9/24 --gateway=192.168.1.1#master_ip_online_change_script= /dba/mha/scripts/master_ip_failover.sh --interface=enp0s3 --vip=192.168.1.9/24 --gateway=192.168.1.1secondary_check_script= /usr/bin/masterha_secondary_check -s node3 -s node2 --user=root --master_host=node2 --master_ip=192.168.1.10 --master_port=3306 #一旦MHA到node2的监控之间出现问题，MHA Manager将会尝试从node3登录到node2shutdown_script=""#report_script=/dbs/mha/scripts/send_report //设置发生切换后发送的报警的脚本[server1]hostname=192.168.1.10port=3306candidate_master=1 #置为候选master，如果设置该参数以后，发生主从切换以后将会将此从库提升为主库，即使这个主库不是集群中事件最新的slavecheck_repl_delay=0 #默认情况下如果一个slave落后master 100M的relay logs的话，MHA将不会选择该slave作为一个新的master，因为对于这个slave的恢复需要花费很长时间，通过设置check_repl_delay=0, #MHA触发切换在选择一个新的master的时候将会忽略复制延时，这个参数对于设置了candidate_master=1的主机非常有用，因为这个候选主在切换的过程中一定是新的master[server2]hostname=192.168.1.11port=3306candidate_master=1check_repl_delay=0[server3]hostname=192.168.1.12port=3306no_master=1EOF 检查 SSH 免密认证masterha_check_ssh –conf=/etc/mha.cnf123456789101112131415161718192021[mysql@node3 ~]$ masterha_check_ssh --conf=/etc/mha.cnfSat Apr 21 16:35:37 2018 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Sat Apr 21 16:35:37 2018 - [info] Reading application default configuration from /etc/mha.cnf..Sat Apr 21 16:35:37 2018 - [info] Reading server configuration from /etc/mha.cnf..Sat Apr 21 16:35:37 2018 - [info] Starting SSH connection tests..Sat Apr 21 16:35:38 2018 - [debug] Sat Apr 21 16:35:37 2018 - [debug] Connecting via SSH from mysql@192.168.1.10(192.168.1.10:22) to mysql@192.168.1.11(192.168.1.11:22)..Sat Apr 21 16:35:38 2018 - [debug] ok.Sat Apr 21 16:35:38 2018 - [debug] Connecting via SSH from mysql@192.168.1.10(192.168.1.10:22) to mysql@192.168.1.12(192.168.1.12:22)..Sat Apr 21 16:35:38 2018 - [debug] ok.Sat Apr 21 16:35:39 2018 - [debug] Sat Apr 21 16:35:38 2018 - [debug] Connecting via SSH from mysql@192.168.1.11(192.168.1.11:22) to mysql@192.168.1.10(192.168.1.10:22)..Sat Apr 21 16:35:38 2018 - [debug] ok.Sat Apr 21 16:35:38 2018 - [debug] Connecting via SSH from mysql@192.168.1.11(192.168.1.11:22) to mysql@192.168.1.12(192.168.1.12:22)..Sat Apr 21 16:35:38 2018 - [debug] ok.Sat Apr 21 16:35:40 2018 - [debug] Sat Apr 21 16:35:38 2018 - [debug] Connecting via SSH from mysql@192.168.1.12(192.168.1.12:22) to mysql@192.168.1.10(192.168.1.10:22)..Sat Apr 21 16:35:39 2018 - [debug] ok.Sat Apr 21 16:35:39 2018 - [debug] Connecting via SSH from mysql@192.168.1.12(192.168.1.12:22) to mysql@192.168.1.11(192.168.1.11:22)..Sat Apr 21 16:35:39 2018 - [debug] ok.Sat Apr 21 16:35:40 2018 - [info] All SSH connection tests passed successfully. 检查集群同步复制masterha_check_repl –conf=/etc/mha.cnf1234567891011121314151617181920212223242526272829303132333435363738394041424344[mysql@node3 ~]$ masterha_check_repl --conf=/etc/mha.cnfSat Apr 21 17:15:46 2018 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Sat Apr 21 17:15:46 2018 - [info] Reading application default configuration from /etc/mha.cnf..Sat Apr 21 17:15:46 2018 - [info] Reading server configuration from /etc/mha.cnf..Sat Apr 21 17:15:46 2018 - [info] MHA::MasterMonitor version 0.57.Sat Apr 21 17:15:48 2018 - [info] GTID failover mode = 1Sat Apr 21 17:15:48 2018 - [info] Dead Servers:Sat Apr 21 17:15:48 2018 - [info] Alive Servers:Sat Apr 21 17:15:48 2018 - [info] 192.168.1.10(192.168.1.10:3306)Sat Apr 21 17:15:48 2018 - [info] 192.168.1.11(192.168.1.11:3306)Sat Apr 21 17:15:48 2018 - [info] 192.168.1.12(192.168.1.12:3306)Sat Apr 21 17:15:48 2018 - [info] Alive Slaves:Sat Apr 21 17:15:48 2018 - [info] 192.168.1.11(192.168.1.11:3306) Version=5.7.21-20-log (oldest major version between slaves) log-bin:enabledSat Apr 21 17:15:48 2018 - [info] GTID ONSat Apr 21 17:15:48 2018 - [info] Replicating from 192.168.1.10(192.168.1.10:3306)Sat Apr 21 17:15:48 2018 - [info] Primary candidate for the new Master (candidate_master is set)Sat Apr 21 17:15:48 2018 - [info] 192.168.1.12(192.168.1.12:3306) Version=5.7.21-20-log (oldest major version between slaves) log-bin:enabledSat Apr 21 17:15:48 2018 - [info] GTID ONSat Apr 21 17:15:48 2018 - [info] Replicating from 192.168.1.10(192.168.1.10:3306)Sat Apr 21 17:15:48 2018 - [info] Not candidate for the new Master (no_master is set)Sat Apr 21 17:15:48 2018 - [info] Current Alive Master: 192.168.1.10(192.168.1.10:3306)Sat Apr 21 17:15:48 2018 - [info] Checking slave configurations..Sat Apr 21 17:15:48 2018 - [info] read_only=1 is not set on slave 192.168.1.11(192.168.1.11:3306).Sat Apr 21 17:15:48 2018 - [info] read_only=1 is not set on slave 192.168.1.12(192.168.1.12:3306).Sat Apr 21 17:15:48 2018 - [info] Checking replication filtering settings..Sat Apr 21 17:15:48 2018 - [info] binlog_do_db= , binlog_ignore_db= Sat Apr 21 17:15:48 2018 - [info] Replication filtering check ok.Sat Apr 21 17:15:48 2018 - [info] GTID (with auto-pos) is supported. Skipping all SSH and Node package checking.Sat Apr 21 17:15:48 2018 - [info] Checking SSH publickey authentication settings on the current master..Sat Apr 21 17:15:48 2018 - [info] HealthCheck: SSH to 192.168.1.10 is reachable.Sat Apr 21 17:15:48 2018 - [info] 192.168.1.10(192.168.1.10:3306) (current master) +--192.168.1.11(192.168.1.11:3306) +--192.168.1.12(192.168.1.12:3306)Sat Apr 21 17:15:48 2018 - [info] Checking replication health on 192.168.1.11..Sat Apr 21 17:15:48 2018 - [info] ok.Sat Apr 21 17:15:48 2018 - [info] Checking replication health on 192.168.1.12..Sat Apr 21 17:15:48 2018 - [info] ok.Sat Apr 21 17:15:48 2018 - [warning] master_ip_failover_script is not defined.Sat Apr 21 17:15:48 2018 - [warning] shutdown_script is not defined.Sat Apr 21 17:15:48 2018 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK. 启动 MHA 集群nohup masterha_manager –conf=/etc/mha.cnf –remove_dead_master_conf –ignore_last_failover &amp;123[mysql@node3 ~]$ nohup masterha_manager --conf=/etc/mha.cnf --remove_dead_master_conf --ignore_last_failover &amp;[1] 7629[mysql@node3 ~]$ nohup: ignoring input and appending output to ‘nohup.out’ 检查 MHA 启动状态masterha_check_status –conf=/etc/mha.cnf12[mysql@node3 ~]$ masterha_check_status --conf=/etc/mha.cnfmha (pid:7629) is running(0:PING_OK), master:192.168.1.10 关闭 MHA 集群masterha_stop –conf=/etc/mha.cnf123[mysql@node3 ~]$ masterha_stop --conf=/etc/mha.cnfStopped mha successfully.[1]+ Exit 1 nohup masterha_manager --conf=/etc/mha.cnf --remove_dead_master_conf --ignore_last_failover MHA VIP配置和切换MHA 支持两种VIP的管理方式，一种通过keepalived的方式管理虚拟ip的浮动；另外一种通过脚本方式启动虚拟ip的方式（即不需要keepalived或者heartbeat类似的软件）。keepalived的管理方式比较简单就是主节点和备用节点两台机器，监控MySQL进程，存在脑裂问题和keepalived+MySQL双主并没有太大区别在配置方面。一旦有了VIP，所以也就需要给master_ip_failover_script与master_ip_online_change_script提供脚本了。为了防止脑裂发生，推荐生产环境采用脚本的方式来管理虚拟ip，而不是使用keepalived来完成。但是当我们有了VIP之后，在切换时还有一个问题，网络模型OSI中二层数据链路是靠MAC地址通信的，所以上层无论三层或二层交换机是缓存有VIP的ARP（MAC和IP对应关系）表，交换机靠这个表来进行数据包的转换转发。所以当我们VIP切换后，上层交换机并不会立马刷新自己的ARP缓存表，这就需要我们人工干预了。其实就是在我们进行切换时，可以通过使用一个arping命令实现。arping是在局域网中使用ARP请求判断目标主机是否在线的工具。你可以使用IP地址或MAC地址作为它的测试目标（因为APRING程序工作于OSI模型中的第二层，ARP协议的数据包无法通过路由器和网关，所以它只能用来检测局域网中的主机）。 master_ip_failover切换脚本为：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394[root@node3 scripts]# cat master_ip_failover.sh#!/usr/bin/env perluse strict;use warnings FATAL =&gt; 'all';use Getopt::Long;use MHA::DBHelper;my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port, $new_master_user, $new_master_password, $vip, $interface, $gateway);GetOptions( 'command=s' =&gt; \$command, 'ssh_user=s' =&gt; \$ssh_user, 'orig_master_host=s' =&gt; \$orig_master_host, 'orig_master_ip=s' =&gt; \$orig_master_ip, 'orig_master_port=i' =&gt; \$orig_master_port, 'new_master_host=s' =&gt; \$new_master_host, 'new_master_ip=s' =&gt; \$new_master_ip, 'new_master_port=i' =&gt; \$new_master_port, 'new_master_user=s' =&gt; \$new_master_user, 'new_master_password=s' =&gt; \$new_master_password, 'vip=s' =&gt; \$vip, 'gateway=s' =&gt; \$gateway, 'interface=s' =&gt; \$interface,);my $key = '1';my @vipnomask=(split(/\//,$vip))[0];my $ssh_start_vip = "sudo /sbin/ifconfig $interface:$key $vip &amp;&amp; sudo /sbin/arping -I $interface -c 1 -s @vipnomask $gateway";my $ssh_stop_vip = "sudo /sbin/ifconfig $interface:$key down";exit &amp;main();sub main &#123; print "\n\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\n\n"; if ( $command eq "stop" || $command eq "stopssh" ) &#123; my $exit_code = 1; eval &#123; print "Disabling the VIP on old master: $orig_master_host \n"; &amp;stop_vip(); $exit_code = 0; &#125;; if ($@) &#123; warn "Got Error: $@\n"; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq "start" ) &#123; my $exit_code = 10; eval &#123; print "Enabling the VIP - $vip on the new master - $new_master_host \n"; &amp;start_vip(); $exit_code = 0; &#125;; if ($@) &#123; warn $@; exit $exit_code; &#125; exit $exit_code; &#125; elsif ( $command eq "status" ) &#123; print "Checking the Status of the script.. OK \n"; `ssh $ssh_user\@$orig_master_host \" $ssh_start_vip \"`; exit 0; &#125; else &#123; &amp;usage(); exit 1; &#125;&#125;sub start_vip() &#123; `ssh $ssh_user\@$new_master_host \" $ssh_start_vip \"`;&#125;sub stop_vip() &#123; `ssh $ssh_user\@$orig_master_host \" $ssh_stop_vip \"`;&#125;sub usage &#123; print"Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\n";&#125; 并将 mha.cnf 修改注释去除master_ip_failover_script= /dba/mha/scripts/master_ip_failover.sh –interface=enp0s3 –vip=192.168.1.9/24 –gateway=192.168.1.1master_ip_online_change_script= /dba/mha/scripts/master_ip_failover.sh –interface=enp0s3 –vip=192.168.1.9/24 –gateway=192.168.1.1 再次检测 masterha_check_status –conf=/etc/mha.cnf 的状态如下：12[mysql@node3 ~]$ masterha_check_status --conf=/etc/mha.cnfmha (pid:7629) is running(0:PING_OK), master:192.168.1.10 MHA 高可用测试故障切换测试手动切换测试masterha_master_switch --master_state=dead --conf=/etc/mha.cnf --dead_master_host=192.168.1.10 --dead_master_port=3306 --interactive=1 --new_master_host=192.168.1.11 masterha_master_switch –master_state=alive –conf=/etc/masterha/app1/app1.cnf –orig_master_is_new_slave –running_updates_limit=3600 –interactive=0–new_master_host=10.1.5.9 –new_master_port=3306]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
        <tag>MySQL 集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 3.x 生产环境下参数文件优化配置及核心参数说明详解]]></title>
    <url>%2F2017%2F10%2F15%2FMongoDB%2FMongDB_mongod.conf%2F</url>
    <content type="text"><![CDATA[MongoDB 核心参数文件配置及说明 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556systemLog: destination: file //指定是一个文件 path: "/usr/local/mongodb/mongod.log" //日志存放位置 logAppend: true //产生日志内容追加到文件 quiet: false //在quite模式下会限制输出信息 timeStampFormat: iso8601-utc //默认是iso8601-local，日志信息中还有其他时间戳格式：ctime,iso8601-utc,iso8601-localstorage: dbPath: "/data/mongodb/data" //数据文件存放路径 indexBuildRetry: true //当构建索引时mongod意外关闭，那么再次启动是否重新构建索引；索引构建失败，mongod重启后将会删除尚未完成的索引，但是否重建由此参数决定。 journal: enabled: true //开启journal日志持久存储，防止数据丢失 directoryPerDB: true //指定存储每个数据库文件到单独的数据目录。如果在一个已存在的系统使用该选项，需要事先把存在的数据文件移动到目录。 syncPeriodSecs: 60 //mongod调用fsync操作将数据flush到磁盘的时间间隔，默认值为60 wiredTiger: engineConfig: cacheSizeGB: 12 //wiredTiger缓存工作集（working set）数据的内存大小 statisticsLogDelaySecs: 0 // journalCompressor: snappy //journal日志的压缩算法，可选值为“none”、“snappy”、“zlib” directoryForIndexes: true //将索引和collections数据分别存储在单独的目录中 collectionConfig: blockCompressor: snappy //collection数据压缩算法，可选值“none”、“snappy”、“zlib” indexConfig: prefixCompression: true //对索引数据使用前缀压缩算法，对那些经过排序的值存储，有很大帮助，可以有效的减少索引数据的内存使用量processManagement: fork: true //以守护进程的方式运行MongoDB，创建服务器进程 pidFilePath: "/usr/local/mongodb/mongod.pid" //pid文件路径net: bindIp: 192.168.1.110,127.0.0.1 //mongod/monogs进程绑定的IP，application通过此IP、port建立链接。 port: 47017 //mongod/mongos侦听端口，默认为27017 maxIncomingConnections: 65536 //mongod/mongos进程允许的最大连接数，如果此值超过操作系统配置的连接数阀值，将不会生效(ulimit)；默认值为65536。 wireObjectCheck: true //当客户端写入数据时，mongos/mongod是否检测数据的有效性(BSON)，如果数据格式不良，此insert、update操作将会被拒绝 ipv6: false //是否支持mongos/mongod多个实例之间使用IPV6网络，默认值为false。此值需要在整个cluster中保持一致。 http: enabled: true unixDomainSocket: enabled: false //停止UNIX domain socket监听operationProfiling: slowOpThresholdMs: 200 //指定慢查询时间，单位毫秒，如果打开功能，则向system.profile集合写入数据 mode: "slowOp" //off、slowOp、all，分别对应关闭，仅打开慢查询，记录所有操作。security: authorization: enabled //访问数据库和进行操作的用户角色认证 clusterAuthMode: keyFile //集群认证模式，默认是keyFile keyFile: "/home/mongod/keyfile" //指定分片集或副本集成员之间身份验证的key文件存储位置replication: oplogSizeMB: 5120 //默认为磁盘的5%,指定oplog的最大尺寸。对于已经建立过oplog.rs的数据库，指定无效 replSetName: configRS //指定副本集的名称 secondaryIndexPrefetch: all //指定副本集成员在接受oplog之前是否加载索引到内存。默认会加载所有的索引到内存。none不加载;all加载所有;_id_only仅加载_idsharding: clusterRole: configsvr //在sharding集群中，此mongod实例的角色，可选值：configsvr，shardsvr archiveMovedChunks: true //当chunks因“负载平衡”而迁移到其他节点时，mongod将这些chunks归档，并保存在dbPath下“moveChunk”目录下，mongod不会删除moveChunk下的文件。setParameter: enableLocalhostAuthBypass: true //对mongod/mongos有效；表示是否开启“localhost exception”，对于sharding cluster而言，我们倾向于在mongos上开启，在shard节点的mongod上关闭。 authenticationMechanisms: SCRAM-SHA-1 //认证机制，可选值为“SCRAM-SHA-1”、“MONGODB-CR”、“PLAN”等，建议为“SCRAM-SHA-1”，对mongod/mongos有效；一旦选定了认证机制，客户端访问databases时需要与其匹配才能有效。 connPoolMaxShardedConnsPerHost: 200 //对mongod/mongos有效；表示当前mongos或者shard与集群中其他shards链接的链接池的最大容量 connPoolMaxConnsPerHost: 200 //表示mongos或者mongod与其他mongod实例之间的连接池的容量 notablescan: 0]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 5.7 最新 my.conf参数文件配置]]></title>
    <url>%2F2017%2F10%2F15%2FMySQL%2FMySQL_my.conf%2F</url>
    <content type="text"><![CDATA[MySQL 参数文件配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190[client]port = 3306socket = /tmp/mysql.sockdefault-character-set = utf8mb4[mysqld]# ---------------- Basic ----------------port = 3306socket = /tmp/mysql.sockbasedir = /usr/local/mysql datadir = /data/mysql/datapid-file = /data/mysql/data/mysql.piduser = mysqltmpdir = /data/mysql/datacharacter_set_server = utf8mb4transaction_isolation = READ-COMMITTEDdefault-storage-engine = InnoDBexplicit_defaults_for_timestamp = 1lower_case_table_names = 1event_scheduler = 1skip-external-lockingsql_mode = 'NO_AUTO_VALUE_ON_ZERO,STRICT_TRANS_TABLES,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,PIPES_AS_CONCAT,ANSI_QUOTES'plugin_dir=/usr/local/mysql/lib/mysql/plugin#replicate-ignore-db = mysql# ---------------- Connection/File/Table ----------------interactive_timeout = 1800wait_timeout = 1800lock_wait_timeout = 1800skip_name_resolve = 1max_connections = 1000max_user_connections = 256max_connect_errors = 20000back_log = 600open_files_limit = 8192table_open_cache = 4096table_definition_cache = 4096table_open_cache_instances = 128# ---------------- Session Buffer Cache ----------------query_cache_size = 0query_cache_type = 0max_allowed_packet = 64Mread_buffer_size = 16Mread_rnd_buffer_size = 16Msort_buffer_size = 16Mtmp_table_size = 64Mjoin_buffer_size = 32Mthread_cache_size = 64thread_stack = 256K# ---------------- Logfile ----------------log-error = /data/mysql/log/error.logslow_query_log = 1slow_query_log_file = /data/mysql/log/slow.loglog_queries_not_using_indexes = 1log_slow_admin_statements = 1log_slow_slave_statements = 1log_throttle_queries_not_using_indexes = 10min_examined_row_limit = 100binlog-rows-query-log-events = 1log-bin-trust-function-creators = 1long_query_time = 0.1# ---------------- Binlog ----------------log-bin = /data/mysql/log/binlog/mysql-binlog-bin-index = /data/mysql/log/binlog/mysql-bin.indexbinlog_format = rowexpire_logs_days = 7sync_binlog = 1binlog_cache_size = 8Mmax_binlog_cache_size = 2048Mmax_binlog_size = 1024Mbinlog_rows_query_log_events = 1# ---------------- InnoDB ----------------innodb_buffer_pool_size = 12Ginnodb_buffer_pool_instances = 8innodb_online_alter_log_max_size = 1024Minnodb_thread_concurrency = 8innodb_io_capacity = 4000innodb_io_capacity_max = 8000innodb_sort_buffer_size = 64Minnodb_page_size = 16Kinnodb_open_files = 4096innodb_flush_log_at_trx_commit = 1innodb_read_io_threads = 8innodb_write_io_threads = 8innodb_purge_threads = 4innodb_max_dirty_pages_pct = 80innodb_buffer_pool_load_at_startup = 1innodb_buffer_pool_dump_at_shutdown = 1innodb_lock_wait_timeout = 10innodb_rollback_on_timeout = 1innodb_lru_scan_depth = 4096innodb_flush_method = O_DIRECTinnodb_checksum_algorithm = CRC32innodb_file_per_table = 1innodb_file_format = Barracudainnodb_file_format_max = Barracudainnodb_flush_neighbors = 0innodb_large_prefix = 1innodb_print_all_deadlocks = 1innodb_stats_persistent_sample_pages = 64innodb_autoinc_lock_mode = 2innodb_sync_spin_loops = 100innodb_spin_wait_delay = 30innodb_stats_on_metadata = 0# ---------------- Redo/Undo ----------------innodb_log_buffer_size = 16Minnodb_log_file_size = 1024Minnodb_log_files_in_group = 3innodb_log_group_home_dir = /data/mysql/log/redoinnodb_undo_logs = 128innodb_undo_tablespaces = 3innodb_undo_directory = /data/mysql/log/undo# ---------------- Replication ----------------server-id = 101master_info_repository = TABLErelay_log_info_repository = TABLEgtid_mode = onenforce_gtid_consistency = 1log_slave_updates = 1relay_log = /data/mysql/log/relay/relay.logrelay_log_recovery = 1slave_skip_errors = ddl_exist_errorsslave-rows-search-algorithms = 'INDEX_SCAN,HASH_SCAN'# ---------------- Semi Sync Replication ----------------#plugin_load = "rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so"#loose_rpl_semi_sync_master_enabled = 1#loose_rpl_semi_sync_slave_enabled = 1#loose_rpl_semi_sync_master_timeout = 5000# ---------------- perforamnce_schema ----------------performance-schema-instrument = 'memory/%=COUNTED'performance_schema_digests_size = 40000performance_schema_max_table_instances = 40000performance_schema_max_sql_text_length = 4096performance_schema_max_digest_length = 4096[mysqld-5.6]metadata_locks_hash_instances = 64[mysqld-5.7]loose_innodb_numa_interleave = 1innodb_buffer_pool_dump_pct = 40innodb_page_cleaners = 4innodb_undo_log_truncate = 1innodb_max_undo_log_size = 2Ginnodb_purge_rseg_truncate_frequency = 128slave-parallel-type = LOGICAL_CLOCKslave-parallel-workers = 16slave_preserve_commit_order = 1slave_transaction_retries = 128binlog_gtid_simple_recovery = 1log_timestamps = systemshow_compatibility_56 = 1# ---------------- MySQL Group Replication ----------------#plugin_load = "group_replication.so"#binlog_checksum = NONEtransaction_write_set_extraction = MURMUR32#transaction_write_set_extraction = XXHASH64#report_host = 127.0.0.1#loose_group_replication_group_name = "aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa"#loose_group_replication_start_on_boot = 0#loose_group_replication_local_address = "127.0.0.1:33060"#loose_group_replication_group_seeds = "127.0.0.1:33060,127.0.0.1:33060,127.0.0.1:33060"#loose_group_replication_compression_threshold = 100#loose_group_replication_flow_control_mode = 0#loose_group_replication_single_primary_mode = 1#loose_group_replication_enforce_update_everywhere_checks = 0#loose_group_replication_transaction_size_limit = 10485760#loose_group_replication_unreachable_majority_timeout = 120[mysqldump]quickmax_allowed_packet = 64Msingle-transaction[mysqld_safe]#malloc-lib = tcmallocmalloc-lib = /usr/lib64/libjemalloc.so.1[mysql]no-auto-rehashprompt="\\u@\\h:\\d&gt;" MySQL 核心参数选择及说明对于 MySQL 的不同应用场景，MySQL 参数优化也不尽相同，下面就 MySQL 核心优化配置参数做简要说明：12]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 索引原理详解]]></title>
    <url>%2F2017%2F10%2F14%2FMySQL%2FMySQL_Index%2F</url>
    <content type="text"><![CDATA[MySQL 索引实现在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎(MySQL数据库MyISAM和InnoDB存储引擎的比较)的索引实现方式。MyISAM属于对堆组织表，InnoDB属于索引组织表。 MySQL 索引类型Hash 索引基于哈希表实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列的值计算一个哈希码，哈希码是一个较小的值，并且不同键值的行计算出来的哈希码不一样，哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。Hash 索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。hash相当于把key通过hash函数计算，得到key的hash值,再用这个hash值做指针，查找hash表中是否存在key，如果存在就返回 key所对应的value，选定一个好的hash函数很重要，好的hash函数可以使计算出的hash值分布均匀，降低冲突，只有冲突减小了，才会降低 hash表的查找时间Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。在MySQL中，只有HEAP/MEMORY引擎表才能显式支持哈希索引（NDB也支持，但这个不常用），而且支持非唯一的哈希索引。在数据库世界里是比较与众不同，如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中。InnoDB引擎的自适应哈希索引（adaptive hash index）不在此列。InnoDB具有一个特别的特性被称为自适应性hash索引。InnoDB发现比较频繁访问的索引值，会为其在B-Tree索引之上建立Hash索引，这使得B-Tree索引具有一定的hash特性，这个特性是自动的，无法控制和配置,只能开启和关闭此特性。虽然 hash 索引效率高，但是 hash 索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些：12345678910a、hash 索引仅仅能满足=，&lt;=&gt;，IN，IS NULL或者IS NOT NULL查询，不能使用范围查询。 由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。b、Hash 索引无法被用来避免数据的排序操作。 由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；c、Hash 索引不能利用部分索引键查询。 对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。d、Hash 索引在任何时候都不能避免表扫描。 Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。e、Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。 对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下 B+ 树索引12 R 树索引12 Fulltext 索引MySQL 5.6.4版本之前只有MyISAM引擎支持fulltext全文索引，InnoDB在5.6.4版本以后就开始支持fulltext全文索引，从MySQL 5.7.6开始，MySQL内置了ngram全文检索插件，开始支持中文全文索引，并且对MyISAM和InnoDB引擎有效。 InnoDB和MyISAM引擎索引实现原理MyISAM 与 InnoDB 区别 MyISAM中的表是以堆表的方式进行存储，堆表没有主键，因此没有聚集索引，辅助索引叶节点不是返回主键值，而是返回行标志符（ROWID），通过ROWID再去查找相应的行。很显然，对于堆表来说，通过辅助索引访问更快(IO更少)，但是如果在OLTP应用下，表中数据经常被修改，辅助索引中的ROWID可能需要经常更新，如果更新影响到物理地址的更改，这种开销比索引组织表要大得多。因此，索引组织表还是堆表，这取决于你的应用，如果你的应用是OLAP，数据更新很少，堆表更好一些。12345InnoDB支持事务，MyisAM不支持；MyisAM顺序储存数据，索引叶子节点保存对应数据行地址，辅助索引很主键索引相差无几；InnoDB主键节点同时保存数据行，其他辅助索引保存的是主键索引的值；MyisAM键值分离，索引载入内存（key_buffer_size），数据缓存依赖操作系统；InnoDB键值一起保存，索引与数据一起载入InnoDB缓冲池；MyisAM主键（唯一）索引按升序来存数据，InnoDB则不一定MyisAM索引的基数值（Cardinality，show index 命令可以看见）是精确的，InnoDB则是估计值。这里涉及到信息统计的知识，MyisAM统计信息是保存磁盘中，在alter表或Analyze table操作更新此信息，而InnoDB则是在表第一次打开的时候估计值保存在缓存区内；MyisAM处理字符串索引时用增量保存的方式，如第一个索引是‘preform’，第二个是‘preformence’，则第二个保存是‘7，ance’，这个明显的好处是缩短索引，但是缺陷就是不支持倒序提取索引，必须顺序遍历获取索引 MyISAM 索引实现原理在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。对于非聚簇索引表来说，表数据和索引是分成两部分存储的，主键索引和二级索引存储上没有任何区别。使用的是B+树作为索引的存储结构，所有的节点都是索引，叶子节点存储的是索引+索引对应的记录的地址。对于聚簇索引表来说，表数据是和主键一起存储的，主键索引的叶结点存储行数据(包含了主键值)，二级索引的叶结点存储行的主键值。使用的是B+树作为索引的存储结构，非叶子节点都是索引关键字，但非叶子节点中的关键字中不存储对应记录的具体内容或内容地址。叶子节点上的数据是主键与具体记录(数据内容)。 InnoDB 索引实现原理聚集索引聚集索引并不是一种单独的索引类型，而是一种数据存储方式（不是数据结构，而是存储结构），具体细节依赖于其实现方式，但InnoDB的聚集索引实际上是在同一个结构中保存了B-Tree索引和数据行。当表有索引时，它的数据行实际上存放在索引的叶子页中，属于聚集表示数据行和相邻的键值紧凑地存储在一起，因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚集索引。因为是存储引擎负责实现索引，因此不是所有的存储引擎都支持聚集索引。下面主要介绍InnoDB，但下面讨论的原理对于任何支持聚集索引（TokuDB可以有多个聚集索引）的引擎都适用：叶子页包含了行的全部数据，但是节点页只包含了索引列（或者可以说非叶子节点的节点页包含的是索引值的索引，因为这些节点页包含的值是从索引列中提取出来的）。InnoDB将通过主键聚集数据，如果没有定义主键，InnoDB会选择第一个非空的唯一索引代替，如果没有非空唯一索引，InnoDB会隐式定义一个6字节的rowid主键来作为聚集索引。InnoDB只聚集在同一个页面中的记录，包含相邻键值的页面可能会相距甚远。要注意：聚集主键可能对性能有帮助，但也可能导致严重的性能问题，尤其是将表的存储引擎从InnoDB转换成其他引擎的时候。聚集的数据有一些重要的优点：123A：可以把相关数据保存在一起，如：实现电子邮箱时，可以根据用户ID来聚集数据，这样只需要从磁盘读取少量的数据页就能获取某个用户全部邮件，如果没有使用聚集索引，则每封邮件都可能导致一次磁盘IOB：数据访问更快，聚集索引将索引和数据保存在同一个B-Tree中，因此从聚集索引中获取数据通常比在非聚集索引中查找要快C：使用覆盖索引扫描的查询可以直接使用页节点中的主键值 聚集索引的缺点：1234567A：聚集数据最大限度地提高了IO密集型应用的性能，但如果数据全部放在内存中，则访问的顺序就没有那么重要了，聚集索引也没有什么优势了B：插入速度严重依赖于插入顺序，按照主键的顺序插入是加载数据到InnoDB表中速度最快的方式，但如果不是按照主键顺序加载数据，那么在加载完成后最好使用optimize table命令重新组织一下表C：更新聚集索引列的代价很高，因为会强制InnoDB将每个被更新的行移动到新的位置D：基于聚集索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临页分裂的问题，当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作，页分裂会导致表占用更多的磁盘空间E：聚集索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候F：二级索引可能比想象的更大，因为在二级索引的叶子节点包含了引用行的主键列。G：二级索引访问需要两次索引查找，而不是一次 InnoDB的主键选择与优化如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择主键作为聚集索引、如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引，如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的)。数据记录本身被存于主键索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页；如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。综上总结，如果InnoDB表的数据写入顺序能和B+树索引的叶子节点顺序一致的话，这时候存取效率是最高的，也就是下面这几种情况的存取效率最高：123A、使用自增列(INT/BIGINT类型)做主键，这时候写入顺序是自增的，和B+数叶子节点分裂顺序一致；B、该表不指定自增列做主键，同时也没有可以被选为主键的唯一索引(上面的条件)，这时候InnoDB会选择内置的ROWID作为主键，写入顺序和ROWID增长顺序一致；除此以外，如果一个InnoDB表又没有显示主键，又有可以被选择为主键的唯一索引，但该唯一索引可能不是递增关系时(例如字符串、UUID、多字段联合唯一索引的情况)，该表的存取效率就会比较差。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
        <tag>数据库优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 体系结构详解]]></title>
    <url>%2F2017%2F10%2F13%2FMySQL%2FMySQL_%20Architecture%2F</url>
    <content type="text"><![CDATA[MySQL 体系结构概述MySQL 由数据库和数据库实例组成，是单进程多线程架构。数据库实例：由数据库后台进程/线程以及一个共享内存区组成，共享内存可以被运行的后台进程/线程所共享。数据库：物理操作系统文件或者其它文件的集合，在 MySQL 中，数据库文件可以是frm、myd、myi、ibd等结尾的文件，当使用ndb存储引擎时候，不是os文件，是存放于内存中的文件。 MySQL 体系结构组成 Connectors：外部语言与SQL交互的入口Management Serveices &amp; Utilities：系统管理和控制工具1日常的 MySQL 管理工具。包括备份恢复、MySQL复制、集群等。 Connection Pool：连接池12管理缓冲用户连接、用户名、密码、权限校验,线程处理等需要缓存的需求。生成线程，验证用户是否正确，保持连接会话队列。 SQL Interface：SQL 接口1接受处理SQL语句接口。返回查询或执行结果。 Parser：解析器1将 SQL 进行验证和解析以便MySQL优化器可以识别的数据结构或返回 SQL 语句的错误。 Optimizer：查询优化器1234使用查询优化器对查询进行优化，同时会验证用户是否有权限进行查询，缓存中是否有可用的最新数据。使用的是“选取-投影- 联接”策略进行查询。选取：根据Where条件选定特定的行。投影：提取Select查询的列。连接：多表连接策略。根据Where筛选数据，然后取出列，最后组合。 Cache 和 Buffer：查询缓存1高速缓冲区。(Innodb buffer pool_size)。缓存数据、索引、数据字典、自适应HASH等数据。如果查询缓存有命中的查询结果,查询语句就可以直接去查询缓存中取数据。通过 LRU算法将数据的冷端溢出,未来得及刷新到磁盘的数据页,叫脏页。 Pluggable Storage Engine：插件式存储引擎1MySQL 是数据库环境框架，其引擎采用插件方式实现。引擎是与文件打交道的子系统,它负责将数据是以某 种数据结构放到磁盘,某种算法来提取数据等(包括MVCC、锁实现,crash recovery等)。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 执行计划详细解读]]></title>
    <url>%2F2017%2F10%2F13%2FMySQL%2FMySQL_explain%2F</url>
    <content type="text"><![CDATA[EXPLAIN/DESC 用法EXPLAIN/DESC SELECT …EXPLAIN/DESC PARTITIONS SELECT …EXPLAIN/DESC EXTENTS SELECT …EXPLAIN/DESC FORMAT=JSON SELECT … EXPLAIN 输出列名词解释idselect 查询的序列号：如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 select_typeselect 查询的类型，主要是区别普通查询和联合查询、子查询之类的复杂查询：1234567891011simple：表示不需要union操作或者不包含子查询的简单select查询。有连接查询时，外层的查询为simple，且只有一个。primary：一个需要union操作或者含有子查询的select，位于最外层的单位查询的select_type即为primary。且只有一个。union：union连接的select查询，除了第一个表外，第二个及以后的表select_type都是union。dependent union：与union一样，出现在union 或union all语句中，但是这个查询要受到外部查询的影响union result：包含union的结果集，在union和union all语句中,因为它不需要参与查询，所以id字段为nullsubquery：除了from字句中包含的子查询外，其他地方出现的子查询都可能是subquerydependent subquery：与dependent union类似，表示这个subquery的查询要受到外部表查询的影响derived：from字句中出现的子查询。materialized：被物化的子查询UNCACHEABLE SUBQUERY：对于外层的主表，子查询不可被物化，每次都需要计算（耗时操作）UNCACHEABLE UNION：UNION操作中，内层的不可被物化的子查询（类似于UNCACHEABLE SUBQUERY） table表示查询涉及的表或衍生表： 如果查询使用了别名，那么这里显示的是别名，如果不涉及对数据表的操作，那么这显示为null，如果显示为尖括号括起来的就表示这个是临时表，后边的N就是执行计划中的id，表示结果来自于这个查询产生。如果是尖括号括起来的，与类似，也是一个临时表，表示这个结果来自于union查询的id为M,N的结果集 partitions针对MySQL内置分区表，表示当前使用了哪些子分区：用于确认查询对分区的过滤效率 type显示的是访问类型，是较为重要的一个指标，结果值从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; unique_subquery &gt; index_subquery &gt; range &gt; index_merge &gt; index &gt; ALL ，一般来说，得保证查询至少达到range级别，最好能达到ref：123456789101112system：表中只有一行数据或者是空表，且只能用于myisam和memory表。如果是Innodb引擎表，type列在这个情况通常都是all或者indexconst：使用唯一索引或者主键，返回记录一定是1行记录的等值where条件时，通常type是const。其他数据库也叫做唯一索引扫描eq_ref：出现在要连接过个表的查询计划中，驱动表只返回一行数据，且这行数据是第二个表的主键或者唯一索引，且必须为not null，唯一索引和主键是多列时，只有所有的列都用作比较时才会出现eq_refref：不像eq_ref那样要求连接顺序，也没有主键和唯一索引的要求，只要使用相等条件检索时就可能出现，常见与辅助索引的等值查找。或者多列主键、唯一索引中，使用第一个列之外的列作为等值查找也会出现，总之，返回数据不唯一的等值查找就可能出现。fulltext：全文索引检索，要注意，全文索引的优先级很高，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引ref_or_null：与ref方法类似，只是增加了null值的比较。实际用的不多。unique_subquery：用于where中的in形式子查询，子查询返回不重复值唯一值index_subquery：用于in形式子查询使用到了辅助索引或者in常数列表，子查询可能返回重复值，可以使用索引将子查询去重。range：索引范围扫描，常见于使用&gt;,&lt;,is null,between ,in ,like等运算符的查询中。index_merge：表示查询使用了两个以上的索引，最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取所个索引，性能可能大部分时间都不如rangeindex：索引全表扫描，把索引从头到尾扫一遍，常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询。ALL：这个就是全表扫描数据文件，然后再在server层进行过滤返回符合要求的记录。 possible_keys指出MySQL能使用哪个索引在该表中找到行，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用。如果是空的，没有相关的索引。这时要提高性能，可通过检验WHERE子句，看是否引用某些字段，或者检查字段不是适合索引。 表示MySQL查询优化器发现当前查询可能被使用地索引，但不一定能会利用，如果possible_key的列举的索引越多，往往说明索引创建不合理，查询效率不是最高效；因为优化器会分析尽可能多的索引，评估哪个索引的“成本”消耗局部最低，这个评估过程消耗时间和资源的。 key显示MySQL实际决定使用的键。如果没有索引被选择，键是NULL： 表示查询优化器真正使用的索引(可能多个，如前index_merge), 如果是索引覆盖，那么索引不会在possible_keys中出现的; 注意：对于组合索引，查询可能只使用其部分字段，详细见下面key_len计算分析 key_len显示MySQL决定使用的键长度。表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。如果键是NULL，长度就是NULL。文档提示特别注意这个值可以得出一个多重主键里mysql实际使用了哪一部分。注：key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。注意，MySQL 的ICP特性使用到的索引不会计入其中。另外，key_len只计算where条件用到的索引长度，而排序和分组就算用到了索引，也不会计算到key_len中。key_len：表示查询优化器使用了索引的字节数，可以评估组合索引是否完全被使用，或只有最左部分字段使用。key_len字节的计算规则：123456789101112字符串：char(n) - n字节， varchar(n)- n字节 + 2字节(变长), 多字节charset * [1~4]字节（latin1为1字节，gbk为2字节，utf8为3字节，utf8mb4为4字节计算）；数值类型： TINYINT-1字节，SMALLINT-2字节， MEDIUMINT-3字节， INT-4字节，BIGINT-8字节；时间类型：DATE-3字节， TIMESTAMP-4字节， DATETIME-8字节；字段属性：NULL属性+ 1字节；Decimal:可以为空,则在数据类型占用字节的基础上加1,但是,decimal本身所占用字节数,计算就比较复杂，Decimal定义为decimal(M,D),其中,M是总的位数,D是小数点后保留的位数。小数点前与小数点后的数字分开存储,且以9位数为1组,用4个字节保存,如果低于9位数,需要的字节数如下：Leftover Digits Number of Bytes0 01-2 13-4 25-6 37-9 4 ref显示哪个字段或常数与key一起被使用： 如果是使用的常数等值查询，这里会显示const，如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段，如果是条件使用了表达式或者函数，或者条件列发生了内部隐式转换，这里可能显示为func rows这个数表示mysql要遍历多少数据才能找到，表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数，在innodb上可能是不准确的。 MySQL 查询优化器根据统计信息，估算SQL要查找到结果集需要扫描读取的数据行数; 这个值非常直观显示SQL的效率好坏，原则 rows 越少越好。 filtered使用explain extended时会出现这个列，MySQL 5.7之后的版本默认就有这个字段，不需要使用explain extended了。这个字段表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数 extraextra列返回的描述的意义：12345678910111213141516171819Distinct ：一旦 MySQL 找到了与行相联合匹配的行，就不再搜索了。Not exists ：MySQL 优化了 LEFT JOIN，一旦它找到了匹配 LEFT JOIN 标准的行，就不再搜索了。Range checked for each Record（index map:#) ：没有找到理想的索引，因此对从前面表中来的每一个行组合，MySQL 检查使用哪个索引，并用它来从表中返回行。这是使用索引的最慢的连接之一。Using filesort ：看到这个的时候，查询就需要优化了。MySQL 需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行。Using index ：列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候。Using temporary ：看到这个的时候，查询需要优化了。这里，MySQL 需要创建一个临时表来存储结果，这通常发生在对不同的列集进行 ORDER BY上，而不是 GROUP BY 上。Where used ：使用了 WHERE 从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行，并且连接类型 ALL 或 index，这就会发生，或者是查询有问题。Using join buffer：该值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。Impossible where：这个值强调了 where 语句会导致没有符合条件的行。Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行。Using where:列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示 MySQL 服务器将在存储引擎检索行后再进行过滤。Using sort_union(...), Using union(...), Using intersect(...):这些函数说明如何为 index_merge 联接类型合并索引扫描。注释：Using sort_union：用两个或者两个以上的 key 提取数据，但优化器无法确保每个 key 会提取到一个自然排好序的结果，所以为了排除多余的数据，需要额外的处理。 例如，customer的state，（lname，fname）是 key，但 lname 不是key，SELECT COUNT(*) FROM customer WHERE (lname = ‘Jones') OR (state = ‘UT')，由于lname上面没有key，所以使用（lname，fname），使得结果可能不按照顺序，优化器需要额外的一些工作。Using union：用两个或者两个以上的key提取数据，分别取得结果是已排序，通过合并就可以获得正确结果。 例如，customer中的state和（lname，fname）是 key，SELECT COUNT(state) FROM customer WHERE (lname = ‘Jones' AND fname='John') OR (state = ‘UT')。Using intersect：用两个或者两个以上的 key 提取数据，分别取得结果是已排序，通过求交就可以获得正确结果。 例如，customer中的state和（lname，fname）是 key，SELECT COUNT(state) FROM customer WHERE (lname = ‘Jones' AND fname='John') AND (state = ‘UT')]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
        <tag>数据库优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库开发与设计规范]]></title>
    <url>%2F2017%2F10%2F12%2FMySQL%2FMySQL_Design_Specifications%2F</url>
    <content type="text"><![CDATA[命名规范库名、表名、字段名必须统一使用小写或者大写字母，禁止混合使用，并采用下划线分割1234MySQL 配置参数 lower_case_table_names=1，即库表名以小写存储，大小写不敏感。如果是0，则库表名以实际情况存储，大小写敏感；如果是2，以实际情况存储，但以小写比较；如果大小写混合使用，可能存在abc，Abc，ABC等多个表共存，容易导致混乱；字段名显示区分大小写，但实际使⽤时不区分，即不可以建立两个名字一样但大小写不一样的字段；为了统一规范， 库名、表名、字段名使用小写字母。 库名以d开头，表名以t开头，字段名以f_开头（只作为参考，但必须统一命名标准）123比如表 t_crm_relation，中间的 crm 代表业务模块名；视图以view_开头，事件以event_开头，触发器以trig_开头，存储过程以proc_开头，函数以func_开头；普通索引以 idx_col1_col2 命名，唯一索引以uk_col1_col2命名（可去掉f_公共部分）。如 idx_companyid_corpid_contacttime(f_company_id,f_corp_id,f_contact_time)。 库名、表名、字段名必须见名知意。命名与业务、产品线等相关联，禁止使用MySQL保留字禁止在MySQL中进行数学运算和函数运算1当库名、表名、字段名等属性含有保留字时，SQL语句必须用反引号引用属性名称，这将使得SQL语句书写、SHELL脚本中变量的转义等变得非常复杂。 库名、表名、字段名禁止超过32个字符1库名、表名、字段名支持最多64个字符，但为了统一规范、易于辨识以及减少传输量，禁止超过20个字符。 临时库、表名必须以tmp为前缀，并以日期为后缀备份库、表必须以bak为前缀，并以日期为后缀12这也是为将来有可能分表做准备的，比如 t_crm_ec_record_201403，但像 t_crm_contact_at201506 就打破了这种规范。不具有时间特性的，直接以 t_tbname_001 这样的方式命名。 按日期时间分表须符合_YYYY[MM][DD]格式1如 t_crm_relation_tmp0425。备份表也类似，形如 _bak20160425。 库表基础规范表使用InnoDB存储引擎1MySQL 5.5版本开始MySQL默认存储引擎就是InnoDB，MySQL 5.7版本开始，系统表开始弃用 MyISAM 引擎。 库、表字符集统一使用UTF8，必要时遇 EMOJ 等表情字符需求使用 UTF8MB41234UTF8字符集存储汉字占用3个字节，存储英文字符占用一个字节；校对字符集使用默认的 utf8_general_ci；连接的客户端也使用 UTF8，建立连接时指定 charset 或 SET NAMES UTF8;如果遇到EMOJ等表情符号的存储需求，可申请使用 UTF8MB4 字符集。 所有表、列都需要添加注释1尽量给字段也添加注释。类 status 型需指明主要值的含义，如“0-离线，1-在线”。 控制单表字段数量，单表字段数上限2012单表字段数上限20左右，再多的话考虑垂直分表。1、冷热数据分离；2、大字段分离；3、常在一起做条件和返回列的不分离。表字段控制少而精，可以提高IO效率，内存缓存更多有效数据，从而提高响应速度和并发能力，后续 alter table 也更快。 所有 InooDB 表都必须显式指定主键，推荐使用 UNSIGNED 自增列作为主键，禁止使用 UUID、MD5、HASH、字符串列作为主键以及多字段复合主键1234主键尽量采用自增方式，InnoDB 表实际是一棵索引组织表，顺序存储可以提高存取效率，充分利用磁盘空间。还有对一些复杂查询可能需要自连接来优化时需要用到。需要全局唯一主键时，使用外部发号器 ticket server（建设中）。如果没有主键或唯一索引，update/delete 是通过所有字段来定位操作的行，相当于每行就是一次全表扫描。少数情况可以使用联合唯一主键，需与DBA协商。 避免使用存储过程、视图，禁止使用触发器以及事件123456存储过程（procedure）虽然可以简化业务端代码，在传统企业写复杂逻辑时可能会用到，而在互联网企业变更是很频繁的，在分库分表的情况下要升级一个存储过程相当麻烦。又因为它是不记录log的，所以也不方便debug性能问题。如果使用过程，一定考虑如果执行失败的情况； 使用视图一定程度上也是为了降低代码里SQL的复杂度，但有时候为了视图的通用性会损失性能（比如返回不必要的字段）； 触发器（trigger）也是同样，但也不应该通过它去约束数据的强一致性，MySQL只支持“基于行的触发”，也就是说，触发器始终是针对一条记录的，而不是针对整个sql语句的，如果变更的数据集非常大的话，效率会很低。掩盖一条SQL背后的工作，一旦出现问题将是灾难性的，但又很难快速分析和定位。再者需要ddl时无法使用 PT-OSC 工具。放在 transaction 执行；事件（event）也是一种偷懒的表现，目前已经遇到数次由于定时任务执行失败影响业务的情况，而且MySQL无法对它做失败预警。建立专门的 job scheduler 平台。 禁止使用外键参考12即使2个表的字段有明确的外键参考关系，也不使用 FOREIGN KEY ，因为新纪录会去主键表做校验，影响性能。外键会导致父表和子表之间耦合，十分影响SQL性能，出现过多的锁等待，甚至会造成死锁。 单表数据量控制在1500w范围以内，超过1500w考虑表分区等优化措施1做好数据评估，建议纯INT数据不超过1500万，含有 CHAR 或者 VARCHAR 数据的不要超过1000万。字段类型在满足需求条件下越小越好，尽量使用 UNSIGNED 存储非负整数，因为实际使用时候存储负数的场景不多。 字段规范优先选择符合存储需要的最小的数据类型123456TINYINT(4)：带符号的范围是-128到127。无符号的范围是0到255SMALLINT(6)：带符号的范围是-32768到32767。无符号的范围是0到65535MEDIUMINT(9)：带符号的范围是 -8388608到8388607。无符号的范围是0到 16777215INT(11)：带符号的范围是 -2147483648 到 2147483647。无符号的范围是0到 4294967295BIGINT(20)：带符号的范围是 -9223372036854775808 到 9223372036854775807。无符号的范围是0到 18446744073709551615TINYINT(1) 和 TINYINT(4) 中的1和4并不表示存储长度，只有字段指定zerofill是有用，如tinyint(4)，如果实际值是2，如果列指定了zerofill，查询结果就是0002，左边用0来填充 对于非负型的数据来说，要有限使用无符号整型来存储1同样的字节数，非负存储的数值范围更大。如TINYINT有符号为 -128-127，无符号为0-255 char、varchar、text等字符串类型定义12345678对于长度基本固定的列，如果该列恰好更新又特别频繁，适合 charvarchar 虽然存储变长字符串，但不可太小也不可太大。UTF8 最多能存21844个汉字，或65532个英文varbinary(M) 保存的是二进制字符串，它保存的是字节而不是字符，所以没有字符集的概念，M长度0-255（字节）。只用于排序或比较时大小写敏感的类型，不包括密码存储TEXT类型与VARCHAR都类似，存储可变长度，最大限制也是2^16，但是它20bytes以后的内容是在数据页以外的空间存储（row_format=dynamic），对它的使用需要多一次寻址，没有默认值。一般用于存放容量平均都很大、操作没有其它字段那样频繁的值。网上部分文章说要避免使用text和blob，要知道如果纯用varchar可能会导致行溢出，效果差不多，但因为每行占用字节数过多，会导致 buffer_pool能 缓存的数据行、页下降。另外text和blob上面一般不会去建索引，而是利用 sphinx 之类的第三方全文搜索引擎，如果确实要创建（前缀）索引，那就会影响性能。凡事看具体场景。另外尽可能把 text/blob 拆到另一个表中BLOB可以看出 varbinary 的扩展版本，内容以二进制字符串存储，无字符集，区分大小写，有一种经常提但不用的场景：不要在数据库里存储图片。 尽可能把所有列定义为NOT NULL1234对表的每一行，每个为 NULL 的列都需要额外的空间来标识。B树索引时不会存储 NULL 值，所以如果索引字段可以为NULL，索引效率会下降。建议用0、特殊值或空串代替NULL值。如果是索引字段，一定要定义为 NOT NULL 。因为 NULL 值会影响 CORDINATE 统计，影响优化器对索引的选择如果不能保证INSERT时一定有值过来，定义时使用 DEFAULT ' '，或0。 使用 TIMESTAMP 或 DATETIME 类型存储时间123456789DATETIME 和 TIMESTAMP 都是精确到秒，优先选择 TIMESTAMP，因为 TIMESTAMP 只有4个字节，而DATETIME占用8个字节。同时 TIMESTAMP 具有自动赋值以及自动更新的特性：创建新记录和修改记录修改现有记录的时候都对这个数据列刷新：TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP创建新记录的时候把这个字段设置为当前时间，但以后修改时，不再刷新它：TIMESTAMP DEFAULT CURRENT_TIMESTAMP创建新记录的时候把这个字段设置为0，以后修改时刷新它：TIMESTAMP ON UPDATE CURRENT_TIMESTAMP创建新记录的时候把这个字段设置为给定值，以后修改时刷新它：TIMESTAMP DEFAULT 'yyyy-mm-dd hh:mm:ss' ON UPDATE CURRENT_TIMESTAMP 使用INT UNSIGNED存储IPV41通常使用 VARCHAR(15) 或者 CHAR(15) 保存IP地址，其实IP地址是无符号的32位整数，不是字符串，小数点仅仅为了可读性。MySQL提供了 INET_ATON() 、NET_NTOA()用于IP地址和整数之前转换 强烈建议使用 TINYINT 来代替枚举 ENUM 类型1ENUM 类型在需要修改或增加枚举值时，需要在线 DDL，成本较高；ENUM列值如果含有数字类型，可能会引起默认值混淆。 使用 VARBINARY 存储大小写敏感的变长字符串或二进制内容1VARBINARY 默认不区分大小写，没有字符集概念，速度快 同一意义的字段定义必须相同1比如不同表中都有 user_id 字段，那么它的类型、字段长度、字符集、字符集顺序要设计成一样 禁止在数据库中存储明文密码尽可能不使用TEXT、BLOB类型用 DECIMAL 代替 FLOAT 和 DOUBLE 存储精确浮点数，同财务相关的金额类型数据必须使用DECIMAL类型123可以保证在浮点计算时，不丢失精度；decimal 占用空间有定义的宽度决定，（每4个字节可以存储9位数字，并且小数点也占用一个字节）；可用于存储比 BIGINT 更大的整数数据。 索引规范任何新上线的 SELECT、UPDATE、DELETE，都需要 EXPLAIN，查看 SQL 的索引使用情况单表索引建议控制在5个以内，单复合索引字段数不允许超过5个123字段超过5个时，实际已经起不到有效过滤数据的作用了。索引是双刃剑，会增加维护负担，增大IO压力，索引占用空间是成倍增加的单张表的索引数量控制在5个以内，或不超过表字段个数的20%。若单张表多个字段在查询需求上都要单独用到索引，需要经过DBA评估。 禁止索引的字段有 NULL值InnoDB 单个索引中的字节数不超过 767（ MyISAM 引擎下为 1000）非唯一索引按照“IDX_字段名称[字段名称]”进用行命名。唯一索引按照“UK字段名称[_字段名称]”进用行命名避免建立冗余索引和重复索引123InnoDB表是一棵索引组织表，主键是和数据放在一起的聚集索引，普通索引最终指向的是主键地址，所以把主键做最后一列是多余的。如f_crm_id作为主键，联合索引(f_user_id,f_crm_id)上的f_crm_id就完全多余(a,b,c)、(a,b)，后者为冗余索引。可以利用前缀索引来达到加速目的，减轻维护负担组合索引建议包含所有字段名，过长的字段名可以采用缩写形式 唯一键由3个以下字段组成，并且字段都是整形时，可使用唯一键作为主键。其他情况下，建议使用自增列或发号器作主键合理创建联合索引选择区分度大的列建立索引。组合索引中，区分度大的字段放在最前123不在低基数列上建立索引，例如性别、类型。但有一种情况，idx_feedbackid_type (f_feedback_id,f_type)，如果经常用 f_type=1 比较，而且能过滤掉90%行，那这个组合索引就值得创建。有时候同样的查询语句，由于条件取值不同导致使用不同的索引，也是这个道理。索引选择性计算方法（基数/数据行数）Selectivity = Cardinality / Total Rows = select count(distinct col1)/count(*) from tbname，越接近1说明col1上使用索引的过滤效果越好。走索引扫描行数超过30%时，改全表扫描。 对于频繁的查询优先考虑使用覆盖索引，避免Innodb表进行索引的二次查找尽量不要在频繁更新的列上创建索引1如不在定义了 ON UPDATE CURRENT_STAMP 的列上创建索引，维护成本太高（好在 MySQL 有 insert buffer，会合并索引的插入） 联表查询时，JOIN列的数据类型必须相同，并且要建立索引不在低基数列上建立索引，比如性别列建立索引对字符串使用前缀索引，前缀索引长度不超过8个字符123对超过30个字符长度的列创建索引时，考虑使用前缀索引，如 idx_cs_guid2 (f_cs_guid(26)) 表示截取前26个字符做索引，既可以提高查找效率，也可以节省空间；前缀索引也有它的缺点是，如果在该列上 ORDER BY 或 GROUP BY 时无法使用索引，也不能把它们用作覆盖索引(Covering Index)；如果在 varbinary 或 blob 这种以二进制存储的列上建立前缀索引，要考虑字符集，括号里表示的是字节数。 不对过长的 VARCHAR 或者 TXET 字段建立索引。建议优先考虑前缀索引，或添加 CRC32 或 MD5 伪列并建立索引最左前缀原则1234mysql使用联合索引时，从左向右匹配，遇到断开或者范围查询时，无法用到后续的索引列比如索引 idx_c1_c2_c3 (c1,c2,c3)，相当于创建了(c1)、(c1,c2)、(c1,c2,c3)三个索引，where条件包含上面三种情况的字段比较则可以用到索引，但像 where c1=a and c3=c 只能用到c1列的索引，像 c2=b and c3=c等情况就完全用不到这个索引遇到范围查询(&gt;、&lt;、between、like)也会停止索引匹配，比如 c1=a and c2 &gt; 2 and c3=c，只有c1,c2列上的比较能用到索引，(c1,c2,c3)排列的索引才可能会都用上where条件里面字段的顺序与索引顺序无关，mysql优化器会自动调整顺序 合理使用覆盖索引减少IO，避免排序123INNODB存储引擎中，secondary index(非主键索引，又称为辅助索引、二级索引)没有直接存储行地址，而是存储主键值。如果用户需要查询 secondary index 中所不包含的数据列，则需要先通过 secondary index 查找到主键值，然后再通过主键查询到其他数据列，因此需要查询两次。覆盖索引则可以在一个索引中获取所有需要的数据列，从而避免回表进行二次查找，节省IO因此效率较高。例如 SELECT email，uid FROM user_email WHERE uid=xx，如果uid不是主键，适当时候可以将索引添加为 index(uid，email)，以获得性能提升 可以把随机I/O变为顺序I/O加快查询效率SQL编码规范使用 prepared statement，可以提升性能并避免SQL注入禁止隐式转换。数值类型禁止加引号；字符串类型必须加引号1234567两个参数至少有一个是 NULL 时，比较的结果也是 NULL，例外是使用 &lt;=&gt; 对两个 NULL 做比较时会返回 1，这两种情况都不需要做类型转换；两个参数都是字符串，会按照字符串来比较，不做类型转换；两个参数都是整数，按照整数来比较，不做类型转换；十六进制的值和非数字做比较时，会被当做二进制串；有一个参数是 TIMESTAMP 或 DATETIME，并且另外一个参数是常量，常量会被转换为 TIMESTAMP；有一个参数是 decimal 类型，如果另外一个参数是 decimal 或者整数，会将整数转换为 decimal 后进行比较，如果另外一个参数是浮点数，则会把 decimal 转换为浮点数进行比较；所有其他情况下，两个参数都会被转换为浮点数再进行比较。如果一个索引建立在string类型上，如果这个字段和一个int类型的值比较。如f_phone定义的类型是varchar，但where使用f_phone in (098890)，两个参数都会被当成成浮点型。发生这个隐式转换并不是最糟的，最糟的是string转换后的float，MySQL无法使用索引，这才导致了性能问题。如果是 f_user_id = ‘1234567’ 的情况,直接把数字当字符串比较。 减少与数据库交互次数，尽量采用批量SQL语句拆分复杂SQL为多个小SQL，避免大事务获取大量数据时，建议分批次获取数据，每次获取数据少于2000条，结果集应小于1M统计表中记录数时使用 COUNT(*)，而不是 COUNT(primary_key) 和 COUNT(1) 备注：仅针对 MyiSAMSELECT只获取必要的字段，杜绝直接 SELECT * 读取全部字段1即使需要所有字段，减少网络带宽消耗，能有效利用覆盖索引，表结构变更对程序基本无影响 SQL中避免出现 now()、rand()、sysdate()、current_user()等不确定结果的函数1语句级复制场景下，引起主从数据不一致；不确定值的函数，产⽣生的SQL语句无法利用QUERY CACHE。 INSERT语句必须指定字段列表，禁止使用 INSERT INTO TABLE()禁止从库上执行后台管理和统计类功能的查询，必要时申请统计类从库禁止UPDATE、DELETE语句使用LIMIT程序应有捕获SQL异常的处理机制，必要时通过rollback显式回滚禁止使用反向查询，例如 not in、not like、not exisits禁止使用order by rand()12345678低效：SELECT * FROM EMP ORDER BY RAND() LIMIT 1;高效：SELECT * FROM EMP AS t1 JOIN (SELECT ROUND(RAND() * ((SELECT MAX(id) FROM EMP) - (SELECT MIN(id) FROM EMP)) + (SELECT MIN(id) FROM EMP)) AS id) AS t2 WHERE t1.id &gt;= t2.id ORDER BY t1.id LIMIT 1; 禁止使用%前导查询，例如：like ‘%abc’，无法利用到索引12低效：SELECT e.ename FROM emp e WHERE e.ename LIKE '%abc';高效：SELECT e.ename FROM emp e WHERE e.ename LIKE 'abc%'; 避免使用JOIN和子查询。必要时推荐用JOIN代替子查询使用 IN 代替 OR；SQL语句中IN包含的值不应过多，应少于300个，否则使用转为字符串LIKE12低效：SELECT * FROM location WHERE loc_id = 10 OR loc_id = 20 OR loc_id = 30;高效：SELECT * FROM location WHERE loc_id IN (10,20,30); 使用&gt;、&lt;等，避免使用!=和&lt;&gt;命令12低效：select * from employee where salary &lt;&gt; 3000;高效：select * from employee where salary &lt; 3000 or salary &gt; 3000; 使用 UNION 替换 OR(适用于索引列)12345678910低效：SELECT loc_id, loc_desc, region FROM location WHERE loc_id = 10 OR region = 'MELBOURNE';高效：SELECT loc_id, loc_desc, region FROM location WHERE loc_id = 10 UNION SELECT loc_id, loc_desc, region FROM location WHERE region = 'MELBOURNE'; 在明显不会有重复值时使用UNION ALL 代替UNION1234567891011121314低效：SELECT ACCT_NUM, BALANCE_AMT FROM DEBIT_TRANSACTIONS WHERE TRAN_DATE = '31 - DEC - 95' UNION SELECT ACCT_NUM, BALANCE_AMT FROM DEBIT_TRANSACTIONS WHERE TRAN_DATE = '31 - DEC - 95';高效：SELECT ACCT_NUM, BALANCE_AMT FROM DEBIT_TRANSACTIONS WHERE TRAN_DATE = '31 - DEC - 95' UNION ALL SELECT ACCT_NUM, BALANCE_AMT FROM DEBIT_TRANSACTIONS WHERE TRAN_DATE = '31 - DEC - 95'; 禁止在MySQL中对列进行数学运算12低效：SELECT e.ename FROM emp e WHERE e.sal*1.1 &gt; 900;高效：SELECT e.ename FROM emp e WHERE e.sal &gt; 900/1.1; 禁止在MySQL中对列进行函数运算1234567低效：SELECT e.ename FROM emp e WHERE DATE_FORMAT(e.date, ’%Y%m%d’) = '20160516';高效：SELECT e.ename FROM emp e WHERE e.date &gt; = '2016-05-16 00:00:01' AND e.date &lt; '2016-05-17 00:00:00'; 建议使用合理的分页方式以提高分页效率12低效：SELECT e.ename FROM emp e limit 10000,10;高效：SELECT e.ename FROM emp e WHERE e.id &gt;=10000 limit 10; 用EXISTS替换DISTINCT12345低效: SELECT DISTINCT DEPT_NO,DEPT_NAME FROM DEPT D , EMP E WHERE D.DEPT_NO = E.DEPT_NO高效: SELECT DEPT_NO,DEPT_NAME FROM DEPT D WHERE EXISTS ( SELECT ‘X’ FROM EMP E WHERE E.DEPT_NO = D.DEPT_NO); 避免在索引列上使用 IS NULL和 IS NOT NULL12低效: SELECT … FROM DEPARTMENT WHERE DEPT_CODE IS NOT NULL;高效: SELECT … FROM DEPARTMENT WHERE DEPT_CODE &gt;=0; 数据库操作规范12345678910111213141516171819不允许在 DBA 不知情的情况下在线上数据库导数据，对数据库增、删、改以及操作一些复杂的查询；对于大表上线，需要 DBA 做详细的评估；大批量更新，如修复数据，避开高峰期，并通知DBA。直接执行 SQL 由DBA同事操作；及时处理已下线业务的 SQL、数据库和表；重要项目的数据库方案选型和设计必须提前通知 DBA 参与；提交线上的所有 DDL 需求，所有 SQL 语句都需要备注说明；所有新上线的表和 SQL 确定走索引后才能上线；表结构变更必须通知 DBA 进行审核；禁止有 DDL、DCL 权限的应用程序账号存在；批量导入、导出数据必须通过 DBA 审核，并在执行过程中观察服务；批量更新数据，如 UPDATE、DELETE 操作，必须 DBA 进行审核，并在执行过程中观察服务；产品出现非数据库导致的故障时，如被攻击，必须及时通 DBA，便于维护服务稳定；业务部门程序出现 BUG 等影响数据库服务的问题，必须及时通知 DBA，便于维护服务稳定；业务部门推广活动或上线新功能，必须提前通知 DBA 进行服务和访问量评估，并留出必要时间以便 DBA 完成扩容；出现业务部门人为误操作导致数据丢失，需要恢复数据的，必须第一时间通知 DBA，并提供准确时间点、 误操作语句等重要线索；提交线上建表改表需求，必须详细注明涉及到的所有 SQL 语句(包括INSERT、DELETE、UPDATE)，便于 DBA 进行审核和优化；对同一个表的多次 ALTER 操作必须合并为一次操作；禁止在 MySQL 数据库中存放业务逻辑；禁止在线上做数据库压力测试。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
        <tag>数据库优化</tag>
      </tags>
  </entry>
</search>
